{
  "best_metric": 1.829906702041626,
  "best_model_checkpoint": "saves/LLaMA3-8B/lora/TheBigSix_7/checkpoint-2900",
  "epoch": 33.74233128834356,
  "eval_steps": 100,
  "global_step": 16500,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.02044989775051125,
      "grad_norm": 0.9960099458694458,
      "learning_rate": 9e-05,
      "loss": 2.9964,
      "step": 10
    },
    {
      "epoch": 0.0408997955010225,
      "grad_norm": 1.036993384361267,
      "learning_rate": 9.999079660496984e-05,
      "loss": 2.8906,
      "step": 20
    },
    {
      "epoch": 0.06134969325153374,
      "grad_norm": 1.0678989887237549,
      "learning_rate": 9.998057061049187e-05,
      "loss": 2.8054,
      "step": 30
    },
    {
      "epoch": 0.081799591002045,
      "grad_norm": 1.6508984565734863,
      "learning_rate": 9.997034461601391e-05,
      "loss": 2.6737,
      "step": 40
    },
    {
      "epoch": 0.10224948875255624,
      "grad_norm": 1.173967957496643,
      "learning_rate": 9.996011862153595e-05,
      "loss": 2.6576,
      "step": 50
    },
    {
      "epoch": 0.12269938650306748,
      "grad_norm": 0.7374882698059082,
      "learning_rate": 9.994989262705798e-05,
      "loss": 2.5164,
      "step": 60
    },
    {
      "epoch": 0.14314928425357873,
      "grad_norm": 1.2488057613372803,
      "learning_rate": 9.993966663258002e-05,
      "loss": 2.4604,
      "step": 70
    },
    {
      "epoch": 0.16359918200409,
      "grad_norm": 1.0932644605636597,
      "learning_rate": 9.992944063810205e-05,
      "loss": 2.5943,
      "step": 80
    },
    {
      "epoch": 0.18404907975460122,
      "grad_norm": 1.0476759672164917,
      "learning_rate": 9.99192146436241e-05,
      "loss": 2.5273,
      "step": 90
    },
    {
      "epoch": 0.20449897750511248,
      "grad_norm": 1.0404610633850098,
      "learning_rate": 9.990898864914613e-05,
      "loss": 2.5169,
      "step": 100
    },
    {
      "epoch": 0.20449897750511248,
      "eval_loss": 2.2542457580566406,
      "eval_runtime": 28.8228,
      "eval_samples_per_second": 11.172,
      "eval_steps_per_second": 0.937,
      "step": 100
    },
    {
      "epoch": 0.2249488752556237,
      "grad_norm": 0.8460189700126648,
      "learning_rate": 9.989876265466818e-05,
      "loss": 2.4957,
      "step": 110
    },
    {
      "epoch": 0.24539877300613497,
      "grad_norm": 0.9106820821762085,
      "learning_rate": 9.988853666019021e-05,
      "loss": 2.6032,
      "step": 120
    },
    {
      "epoch": 0.2658486707566462,
      "grad_norm": 0.8821091651916504,
      "learning_rate": 9.987831066571225e-05,
      "loss": 2.5117,
      "step": 130
    },
    {
      "epoch": 0.28629856850715746,
      "grad_norm": 1.0985620021820068,
      "learning_rate": 9.986808467123428e-05,
      "loss": 2.3571,
      "step": 140
    },
    {
      "epoch": 0.3067484662576687,
      "grad_norm": 0.9582553505897522,
      "learning_rate": 9.985785867675632e-05,
      "loss": 2.4267,
      "step": 150
    },
    {
      "epoch": 0.32719836400818,
      "grad_norm": 0.9183560013771057,
      "learning_rate": 9.984763268227836e-05,
      "loss": 2.5051,
      "step": 160
    },
    {
      "epoch": 0.3476482617586912,
      "grad_norm": 0.9993289113044739,
      "learning_rate": 9.983740668780039e-05,
      "loss": 2.4575,
      "step": 170
    },
    {
      "epoch": 0.36809815950920244,
      "grad_norm": 1.2483714818954468,
      "learning_rate": 9.982718069332242e-05,
      "loss": 2.408,
      "step": 180
    },
    {
      "epoch": 0.3885480572597137,
      "grad_norm": 1.0768924951553345,
      "learning_rate": 9.981695469884447e-05,
      "loss": 2.3023,
      "step": 190
    },
    {
      "epoch": 0.40899795501022496,
      "grad_norm": 0.8049486875534058,
      "learning_rate": 9.98067287043665e-05,
      "loss": 2.4333,
      "step": 200
    },
    {
      "epoch": 0.40899795501022496,
      "eval_loss": 2.144530773162842,
      "eval_runtime": 28.7347,
      "eval_samples_per_second": 11.206,
      "eval_steps_per_second": 0.94,
      "step": 200
    },
    {
      "epoch": 0.4294478527607362,
      "grad_norm": 0.9489029049873352,
      "learning_rate": 9.979650270988855e-05,
      "loss": 2.4681,
      "step": 210
    },
    {
      "epoch": 0.4498977505112474,
      "grad_norm": 1.2246956825256348,
      "learning_rate": 9.978627671541058e-05,
      "loss": 2.5039,
      "step": 220
    },
    {
      "epoch": 0.4703476482617587,
      "grad_norm": 1.0706502199172974,
      "learning_rate": 9.977605072093261e-05,
      "loss": 2.4199,
      "step": 230
    },
    {
      "epoch": 0.49079754601226994,
      "grad_norm": 1.6051338911056519,
      "learning_rate": 9.976582472645465e-05,
      "loss": 2.4319,
      "step": 240
    },
    {
      "epoch": 0.5112474437627812,
      "grad_norm": 0.8593259453773499,
      "learning_rate": 9.975559873197669e-05,
      "loss": 2.4189,
      "step": 250
    },
    {
      "epoch": 0.5316973415132924,
      "grad_norm": 1.0966291427612305,
      "learning_rate": 9.974537273749872e-05,
      "loss": 2.3609,
      "step": 260
    },
    {
      "epoch": 0.5521472392638037,
      "grad_norm": 0.9696713089942932,
      "learning_rate": 9.973514674302076e-05,
      "loss": 2.3747,
      "step": 270
    },
    {
      "epoch": 0.5725971370143149,
      "grad_norm": 1.3769052028656006,
      "learning_rate": 9.972492074854281e-05,
      "loss": 2.3196,
      "step": 280
    },
    {
      "epoch": 0.5930470347648262,
      "grad_norm": 1.3339502811431885,
      "learning_rate": 9.971469475406484e-05,
      "loss": 2.4012,
      "step": 290
    },
    {
      "epoch": 0.6134969325153374,
      "grad_norm": 0.7414674758911133,
      "learning_rate": 9.970446875958687e-05,
      "loss": 2.4853,
      "step": 300
    },
    {
      "epoch": 0.6134969325153374,
      "eval_loss": 2.089454412460327,
      "eval_runtime": 28.8981,
      "eval_samples_per_second": 11.143,
      "eval_steps_per_second": 0.934,
      "step": 300
    },
    {
      "epoch": 0.6339468302658486,
      "grad_norm": 1.24136221408844,
      "learning_rate": 9.969424276510892e-05,
      "loss": 2.4389,
      "step": 310
    },
    {
      "epoch": 0.65439672801636,
      "grad_norm": 1.1413204669952393,
      "learning_rate": 9.968401677063095e-05,
      "loss": 2.3412,
      "step": 320
    },
    {
      "epoch": 0.6748466257668712,
      "grad_norm": 1.1485222578048706,
      "learning_rate": 9.967379077615298e-05,
      "loss": 2.484,
      "step": 330
    },
    {
      "epoch": 0.6952965235173824,
      "grad_norm": 1.3430607318878174,
      "learning_rate": 9.966356478167503e-05,
      "loss": 2.2947,
      "step": 340
    },
    {
      "epoch": 0.7157464212678937,
      "grad_norm": 0.8888974785804749,
      "learning_rate": 9.965333878719706e-05,
      "loss": 2.2092,
      "step": 350
    },
    {
      "epoch": 0.7361963190184049,
      "grad_norm": 0.908489465713501,
      "learning_rate": 9.96431127927191e-05,
      "loss": 2.2937,
      "step": 360
    },
    {
      "epoch": 0.7566462167689162,
      "grad_norm": 1.2458089590072632,
      "learning_rate": 9.963288679824113e-05,
      "loss": 2.3434,
      "step": 370
    },
    {
      "epoch": 0.7770961145194274,
      "grad_norm": 1.5688724517822266,
      "learning_rate": 9.962266080376316e-05,
      "loss": 2.3111,
      "step": 380
    },
    {
      "epoch": 0.7975460122699386,
      "grad_norm": 2.249199390411377,
      "learning_rate": 9.961243480928521e-05,
      "loss": 2.3021,
      "step": 390
    },
    {
      "epoch": 0.8179959100204499,
      "grad_norm": 1.2782564163208008,
      "learning_rate": 9.960220881480724e-05,
      "loss": 2.37,
      "step": 400
    },
    {
      "epoch": 0.8179959100204499,
      "eval_loss": 2.067573308944702,
      "eval_runtime": 28.8473,
      "eval_samples_per_second": 11.162,
      "eval_steps_per_second": 0.936,
      "step": 400
    },
    {
      "epoch": 0.8384458077709611,
      "grad_norm": 1.2313226461410522,
      "learning_rate": 9.959198282032927e-05,
      "loss": 2.3496,
      "step": 410
    },
    {
      "epoch": 0.8588957055214724,
      "grad_norm": 0.9957808256149292,
      "learning_rate": 9.958175682585132e-05,
      "loss": 2.4233,
      "step": 420
    },
    {
      "epoch": 0.8793456032719836,
      "grad_norm": 1.444008469581604,
      "learning_rate": 9.957153083137336e-05,
      "loss": 2.3576,
      "step": 430
    },
    {
      "epoch": 0.8997955010224948,
      "grad_norm": 1.222464919090271,
      "learning_rate": 9.95613048368954e-05,
      "loss": 2.2921,
      "step": 440
    },
    {
      "epoch": 0.9202453987730062,
      "grad_norm": 1.098302960395813,
      "learning_rate": 9.955107884241743e-05,
      "loss": 2.4469,
      "step": 450
    },
    {
      "epoch": 0.9406952965235174,
      "grad_norm": 0.8071065545082092,
      "learning_rate": 9.954085284793947e-05,
      "loss": 2.3159,
      "step": 460
    },
    {
      "epoch": 0.9611451942740287,
      "grad_norm": 1.979356050491333,
      "learning_rate": 9.95306268534615e-05,
      "loss": 2.2714,
      "step": 470
    },
    {
      "epoch": 0.9815950920245399,
      "grad_norm": 1.270779013633728,
      "learning_rate": 9.952040085898355e-05,
      "loss": 2.3239,
      "step": 480
    },
    {
      "epoch": 1.0020449897750512,
      "grad_norm": 1.4982227087020874,
      "learning_rate": 9.951017486450558e-05,
      "loss": 2.3526,
      "step": 490
    },
    {
      "epoch": 1.0224948875255624,
      "grad_norm": 1.571495532989502,
      "learning_rate": 9.949994887002761e-05,
      "loss": 2.2422,
      "step": 500
    },
    {
      "epoch": 1.0224948875255624,
      "eval_loss": 2.052884817123413,
      "eval_runtime": 28.7533,
      "eval_samples_per_second": 11.199,
      "eval_steps_per_second": 0.939,
      "step": 500
    },
    {
      "epoch": 1.0429447852760736,
      "grad_norm": 1.2737607955932617,
      "learning_rate": 9.948972287554966e-05,
      "loss": 2.2665,
      "step": 510
    },
    {
      "epoch": 1.0633946830265848,
      "grad_norm": 1.3214244842529297,
      "learning_rate": 9.947949688107169e-05,
      "loss": 2.2216,
      "step": 520
    },
    {
      "epoch": 1.0838445807770962,
      "grad_norm": 1.3470746278762817,
      "learning_rate": 9.946927088659372e-05,
      "loss": 2.2995,
      "step": 530
    },
    {
      "epoch": 1.1042944785276074,
      "grad_norm": 1.638139247894287,
      "learning_rate": 9.945904489211577e-05,
      "loss": 2.2532,
      "step": 540
    },
    {
      "epoch": 1.1247443762781186,
      "grad_norm": 1.3032636642456055,
      "learning_rate": 9.94488188976378e-05,
      "loss": 2.1422,
      "step": 550
    },
    {
      "epoch": 1.1451942740286298,
      "grad_norm": 0.9407117962837219,
      "learning_rate": 9.943859290315983e-05,
      "loss": 2.1583,
      "step": 560
    },
    {
      "epoch": 1.165644171779141,
      "grad_norm": 1.068668246269226,
      "learning_rate": 9.942836690868187e-05,
      "loss": 2.1919,
      "step": 570
    },
    {
      "epoch": 1.1860940695296525,
      "grad_norm": 1.7681397199630737,
      "learning_rate": 9.941814091420392e-05,
      "loss": 2.1889,
      "step": 580
    },
    {
      "epoch": 1.2065439672801637,
      "grad_norm": 0.8144485354423523,
      "learning_rate": 9.940791491972595e-05,
      "loss": 2.274,
      "step": 590
    },
    {
      "epoch": 1.2269938650306749,
      "grad_norm": 1.2503876686096191,
      "learning_rate": 9.9397688925248e-05,
      "loss": 2.0863,
      "step": 600
    },
    {
      "epoch": 1.2269938650306749,
      "eval_loss": 2.026681900024414,
      "eval_runtime": 28.8682,
      "eval_samples_per_second": 11.154,
      "eval_steps_per_second": 0.935,
      "step": 600
    },
    {
      "epoch": 1.247443762781186,
      "grad_norm": 1.5692569017410278,
      "learning_rate": 9.938746293077003e-05,
      "loss": 2.1646,
      "step": 610
    },
    {
      "epoch": 1.2678936605316973,
      "grad_norm": 1.04200279712677,
      "learning_rate": 9.937723693629206e-05,
      "loss": 2.2323,
      "step": 620
    },
    {
      "epoch": 1.2883435582822087,
      "grad_norm": 1.5947626829147339,
      "learning_rate": 9.93670109418141e-05,
      "loss": 2.1897,
      "step": 630
    },
    {
      "epoch": 1.30879345603272,
      "grad_norm": 1.326324462890625,
      "learning_rate": 9.935678494733614e-05,
      "loss": 2.1106,
      "step": 640
    },
    {
      "epoch": 1.329243353783231,
      "grad_norm": 1.2878518104553223,
      "learning_rate": 9.934655895285817e-05,
      "loss": 2.0994,
      "step": 650
    },
    {
      "epoch": 1.3496932515337423,
      "grad_norm": 1.1814556121826172,
      "learning_rate": 9.933633295838021e-05,
      "loss": 2.1686,
      "step": 660
    },
    {
      "epoch": 1.3701431492842535,
      "grad_norm": 1.549282431602478,
      "learning_rate": 9.932610696390224e-05,
      "loss": 2.2071,
      "step": 670
    },
    {
      "epoch": 1.390593047034765,
      "grad_norm": 1.313368797302246,
      "learning_rate": 9.931588096942428e-05,
      "loss": 2.1695,
      "step": 680
    },
    {
      "epoch": 1.4110429447852761,
      "grad_norm": 1.6572281122207642,
      "learning_rate": 9.930565497494632e-05,
      "loss": 2.155,
      "step": 690
    },
    {
      "epoch": 1.4314928425357873,
      "grad_norm": 1.1751587390899658,
      "learning_rate": 9.929542898046835e-05,
      "loss": 2.129,
      "step": 700
    },
    {
      "epoch": 1.4314928425357873,
      "eval_loss": 1.9984972476959229,
      "eval_runtime": 28.8213,
      "eval_samples_per_second": 11.172,
      "eval_steps_per_second": 0.937,
      "step": 700
    },
    {
      "epoch": 1.4519427402862985,
      "grad_norm": 1.9571043252944946,
      "learning_rate": 9.928520298599038e-05,
      "loss": 2.1334,
      "step": 710
    },
    {
      "epoch": 1.4723926380368098,
      "grad_norm": 1.1977447271347046,
      "learning_rate": 9.927497699151243e-05,
      "loss": 2.2236,
      "step": 720
    },
    {
      "epoch": 1.4928425357873212,
      "grad_norm": 1.2631152868270874,
      "learning_rate": 9.926475099703446e-05,
      "loss": 2.118,
      "step": 730
    },
    {
      "epoch": 1.5132924335378322,
      "grad_norm": 1.437031865119934,
      "learning_rate": 9.92545250025565e-05,
      "loss": 2.1583,
      "step": 740
    },
    {
      "epoch": 1.5337423312883436,
      "grad_norm": 1.3560070991516113,
      "learning_rate": 9.924429900807855e-05,
      "loss": 2.0801,
      "step": 750
    },
    {
      "epoch": 1.5541922290388548,
      "grad_norm": 1.7069015502929688,
      "learning_rate": 9.923407301360058e-05,
      "loss": 2.2278,
      "step": 760
    },
    {
      "epoch": 1.574642126789366,
      "grad_norm": 1.0153536796569824,
      "learning_rate": 9.922384701912261e-05,
      "loss": 2.2722,
      "step": 770
    },
    {
      "epoch": 1.5950920245398774,
      "grad_norm": 2.05710768699646,
      "learning_rate": 9.921362102464466e-05,
      "loss": 2.1399,
      "step": 780
    },
    {
      "epoch": 1.6155419222903884,
      "grad_norm": 1.1466492414474487,
      "learning_rate": 9.920339503016669e-05,
      "loss": 2.0802,
      "step": 790
    },
    {
      "epoch": 1.6359918200408998,
      "grad_norm": 1.1669660806655884,
      "learning_rate": 9.919316903568872e-05,
      "loss": 2.1199,
      "step": 800
    },
    {
      "epoch": 1.6359918200408998,
      "eval_loss": 1.9856953620910645,
      "eval_runtime": 28.8414,
      "eval_samples_per_second": 11.164,
      "eval_steps_per_second": 0.936,
      "step": 800
    },
    {
      "epoch": 1.656441717791411,
      "grad_norm": 1.6089328527450562,
      "learning_rate": 9.918294304121077e-05,
      "loss": 2.2002,
      "step": 810
    },
    {
      "epoch": 1.6768916155419222,
      "grad_norm": 1.4631223678588867,
      "learning_rate": 9.91727170467328e-05,
      "loss": 2.0587,
      "step": 820
    },
    {
      "epoch": 1.6973415132924337,
      "grad_norm": 1.1534019708633423,
      "learning_rate": 9.916249105225483e-05,
      "loss": 2.2727,
      "step": 830
    },
    {
      "epoch": 1.7177914110429446,
      "grad_norm": 1.7527397871017456,
      "learning_rate": 9.915226505777688e-05,
      "loss": 2.2504,
      "step": 840
    },
    {
      "epoch": 1.738241308793456,
      "grad_norm": 1.129593014717102,
      "learning_rate": 9.914203906329891e-05,
      "loss": 2.2214,
      "step": 850
    },
    {
      "epoch": 1.7586912065439673,
      "grad_norm": 1.5337038040161133,
      "learning_rate": 9.913181306882094e-05,
      "loss": 2.1468,
      "step": 860
    },
    {
      "epoch": 1.7791411042944785,
      "grad_norm": 1.3303712606430054,
      "learning_rate": 9.912158707434298e-05,
      "loss": 2.2007,
      "step": 870
    },
    {
      "epoch": 1.79959100204499,
      "grad_norm": 1.0972062349319458,
      "learning_rate": 9.911136107986502e-05,
      "loss": 2.224,
      "step": 880
    },
    {
      "epoch": 1.8200408997955009,
      "grad_norm": 1.624241590499878,
      "learning_rate": 9.910113508538705e-05,
      "loss": 2.1322,
      "step": 890
    },
    {
      "epoch": 1.8404907975460123,
      "grad_norm": 1.746472716331482,
      "learning_rate": 9.909090909090911e-05,
      "loss": 2.0565,
      "step": 900
    },
    {
      "epoch": 1.8404907975460123,
      "eval_loss": 1.971807837486267,
      "eval_runtime": 28.8745,
      "eval_samples_per_second": 11.152,
      "eval_steps_per_second": 0.935,
      "step": 900
    },
    {
      "epoch": 1.8609406952965235,
      "grad_norm": 1.6384341716766357,
      "learning_rate": 9.908068309643114e-05,
      "loss": 2.0933,
      "step": 910
    },
    {
      "epoch": 1.8813905930470347,
      "grad_norm": 1.3010215759277344,
      "learning_rate": 9.907045710195317e-05,
      "loss": 2.1377,
      "step": 920
    },
    {
      "epoch": 1.9018404907975461,
      "grad_norm": 1.3368264436721802,
      "learning_rate": 9.906023110747522e-05,
      "loss": 2.0771,
      "step": 930
    },
    {
      "epoch": 1.9222903885480571,
      "grad_norm": 1.8266981840133667,
      "learning_rate": 9.905000511299725e-05,
      "loss": 2.2411,
      "step": 940
    },
    {
      "epoch": 1.9427402862985685,
      "grad_norm": 1.5345149040222168,
      "learning_rate": 9.903977911851928e-05,
      "loss": 2.0399,
      "step": 950
    },
    {
      "epoch": 1.9631901840490797,
      "grad_norm": 1.434688925743103,
      "learning_rate": 9.902955312404132e-05,
      "loss": 2.0213,
      "step": 960
    },
    {
      "epoch": 1.983640081799591,
      "grad_norm": 1.3869184255599976,
      "learning_rate": 9.901932712956336e-05,
      "loss": 2.0488,
      "step": 970
    },
    {
      "epoch": 2.0040899795501024,
      "grad_norm": 2.0339577198028564,
      "learning_rate": 9.900910113508539e-05,
      "loss": 2.0885,
      "step": 980
    },
    {
      "epoch": 2.0245398773006134,
      "grad_norm": 1.0710231065750122,
      "learning_rate": 9.899887514060743e-05,
      "loss": 1.9206,
      "step": 990
    },
    {
      "epoch": 2.044989775051125,
      "grad_norm": 3.1997029781341553,
      "learning_rate": 9.898864914612946e-05,
      "loss": 1.8526,
      "step": 1000
    },
    {
      "epoch": 2.044989775051125,
      "eval_loss": 1.9556573629379272,
      "eval_runtime": 28.8732,
      "eval_samples_per_second": 11.152,
      "eval_steps_per_second": 0.935,
      "step": 1000
    },
    {
      "epoch": 2.065439672801636,
      "grad_norm": 2.1036386489868164,
      "learning_rate": 9.89784231516515e-05,
      "loss": 1.9498,
      "step": 1010
    },
    {
      "epoch": 2.085889570552147,
      "grad_norm": 1.6294180154800415,
      "learning_rate": 9.896819715717354e-05,
      "loss": 1.9247,
      "step": 1020
    },
    {
      "epoch": 2.1063394683026586,
      "grad_norm": 1.668054223060608,
      "learning_rate": 9.895797116269557e-05,
      "loss": 1.8987,
      "step": 1030
    },
    {
      "epoch": 2.1267893660531696,
      "grad_norm": 1.6462658643722534,
      "learning_rate": 9.89477451682176e-05,
      "loss": 1.8908,
      "step": 1040
    },
    {
      "epoch": 2.147239263803681,
      "grad_norm": 1.5598498582839966,
      "learning_rate": 9.893751917373965e-05,
      "loss": 1.7837,
      "step": 1050
    },
    {
      "epoch": 2.1676891615541924,
      "grad_norm": 1.2936503887176514,
      "learning_rate": 9.89272931792617e-05,
      "loss": 1.9595,
      "step": 1060
    },
    {
      "epoch": 2.1881390593047034,
      "grad_norm": 1.5929291248321533,
      "learning_rate": 9.891706718478373e-05,
      "loss": 1.9623,
      "step": 1070
    },
    {
      "epoch": 2.208588957055215,
      "grad_norm": 1.4549564123153687,
      "learning_rate": 9.890684119030577e-05,
      "loss": 1.8407,
      "step": 1080
    },
    {
      "epoch": 2.229038854805726,
      "grad_norm": 1.766180396080017,
      "learning_rate": 9.88966151958278e-05,
      "loss": 1.8282,
      "step": 1090
    },
    {
      "epoch": 2.2494887525562373,
      "grad_norm": 1.448747158050537,
      "learning_rate": 9.888638920134983e-05,
      "loss": 2.009,
      "step": 1100
    },
    {
      "epoch": 2.2494887525562373,
      "eval_loss": 1.959454894065857,
      "eval_runtime": 28.8302,
      "eval_samples_per_second": 11.169,
      "eval_steps_per_second": 0.937,
      "step": 1100
    },
    {
      "epoch": 2.2699386503067487,
      "grad_norm": 1.5542421340942383,
      "learning_rate": 9.887616320687188e-05,
      "loss": 1.9384,
      "step": 1110
    },
    {
      "epoch": 2.2903885480572597,
      "grad_norm": 1.1807643175125122,
      "learning_rate": 9.886593721239391e-05,
      "loss": 1.9636,
      "step": 1120
    },
    {
      "epoch": 2.310838445807771,
      "grad_norm": 1.8599724769592285,
      "learning_rate": 9.885571121791594e-05,
      "loss": 1.9137,
      "step": 1130
    },
    {
      "epoch": 2.331288343558282,
      "grad_norm": 1.4969556331634521,
      "learning_rate": 9.884548522343799e-05,
      "loss": 1.9662,
      "step": 1140
    },
    {
      "epoch": 2.3517382413087935,
      "grad_norm": 1.7970428466796875,
      "learning_rate": 9.883525922896002e-05,
      "loss": 2.0713,
      "step": 1150
    },
    {
      "epoch": 2.372188139059305,
      "grad_norm": 2.1110665798187256,
      "learning_rate": 9.882503323448205e-05,
      "loss": 1.8882,
      "step": 1160
    },
    {
      "epoch": 2.392638036809816,
      "grad_norm": 1.6269335746765137,
      "learning_rate": 9.88148072400041e-05,
      "loss": 2.0158,
      "step": 1170
    },
    {
      "epoch": 2.4130879345603273,
      "grad_norm": 2.118415117263794,
      "learning_rate": 9.880458124552613e-05,
      "loss": 1.8363,
      "step": 1180
    },
    {
      "epoch": 2.4335378323108383,
      "grad_norm": 2.4838337898254395,
      "learning_rate": 9.879435525104816e-05,
      "loss": 1.8556,
      "step": 1190
    },
    {
      "epoch": 2.4539877300613497,
      "grad_norm": 2.008312702178955,
      "learning_rate": 9.87841292565702e-05,
      "loss": 1.9151,
      "step": 1200
    },
    {
      "epoch": 2.4539877300613497,
      "eval_loss": 1.9420331716537476,
      "eval_runtime": 28.7585,
      "eval_samples_per_second": 11.197,
      "eval_steps_per_second": 0.939,
      "step": 1200
    },
    {
      "epoch": 2.474437627811861,
      "grad_norm": 2.4577159881591797,
      "learning_rate": 9.877390326209224e-05,
      "loss": 1.9151,
      "step": 1210
    },
    {
      "epoch": 2.494887525562372,
      "grad_norm": 1.9663729667663574,
      "learning_rate": 9.876367726761428e-05,
      "loss": 1.829,
      "step": 1220
    },
    {
      "epoch": 2.5153374233128836,
      "grad_norm": 1.7114672660827637,
      "learning_rate": 9.875345127313633e-05,
      "loss": 1.7539,
      "step": 1230
    },
    {
      "epoch": 2.5357873210633946,
      "grad_norm": 2.4550323486328125,
      "learning_rate": 9.874322527865836e-05,
      "loss": 1.9199,
      "step": 1240
    },
    {
      "epoch": 2.556237218813906,
      "grad_norm": 2.3284664154052734,
      "learning_rate": 9.873299928418039e-05,
      "loss": 1.724,
      "step": 1250
    },
    {
      "epoch": 2.5766871165644174,
      "grad_norm": 1.4237028360366821,
      "learning_rate": 9.872277328970243e-05,
      "loss": 2.0279,
      "step": 1260
    },
    {
      "epoch": 2.5971370143149284,
      "grad_norm": 2.3329520225524902,
      "learning_rate": 9.871254729522447e-05,
      "loss": 1.8995,
      "step": 1270
    },
    {
      "epoch": 2.61758691206544,
      "grad_norm": 2.3571414947509766,
      "learning_rate": 9.87023213007465e-05,
      "loss": 1.879,
      "step": 1280
    },
    {
      "epoch": 2.638036809815951,
      "grad_norm": 2.319779396057129,
      "learning_rate": 9.869209530626854e-05,
      "loss": 1.9454,
      "step": 1290
    },
    {
      "epoch": 2.658486707566462,
      "grad_norm": 1.8712784051895142,
      "learning_rate": 9.868186931179057e-05,
      "loss": 1.8443,
      "step": 1300
    },
    {
      "epoch": 2.658486707566462,
      "eval_loss": 1.9206727743148804,
      "eval_runtime": 28.811,
      "eval_samples_per_second": 11.176,
      "eval_steps_per_second": 0.937,
      "step": 1300
    },
    {
      "epoch": 2.6789366053169736,
      "grad_norm": 1.6551027297973633,
      "learning_rate": 9.86716433173126e-05,
      "loss": 1.9335,
      "step": 1310
    },
    {
      "epoch": 2.6993865030674846,
      "grad_norm": 1.835748314857483,
      "learning_rate": 9.866141732283465e-05,
      "loss": 1.872,
      "step": 1320
    },
    {
      "epoch": 2.719836400817996,
      "grad_norm": 1.6745686531066895,
      "learning_rate": 9.865119132835668e-05,
      "loss": 1.8107,
      "step": 1330
    },
    {
      "epoch": 2.740286298568507,
      "grad_norm": 2.0806868076324463,
      "learning_rate": 9.864096533387871e-05,
      "loss": 1.8473,
      "step": 1340
    },
    {
      "epoch": 2.7607361963190185,
      "grad_norm": 1.520707607269287,
      "learning_rate": 9.863073933940076e-05,
      "loss": 1.9492,
      "step": 1350
    },
    {
      "epoch": 2.78118609406953,
      "grad_norm": 1.2281907796859741,
      "learning_rate": 9.862051334492279e-05,
      "loss": 1.8106,
      "step": 1360
    },
    {
      "epoch": 2.801635991820041,
      "grad_norm": 2.4512674808502197,
      "learning_rate": 9.861028735044484e-05,
      "loss": 1.9595,
      "step": 1370
    },
    {
      "epoch": 2.8220858895705523,
      "grad_norm": 2.090725898742676,
      "learning_rate": 9.860006135596688e-05,
      "loss": 1.8497,
      "step": 1380
    },
    {
      "epoch": 2.8425357873210633,
      "grad_norm": 2.1714680194854736,
      "learning_rate": 9.858983536148891e-05,
      "loss": 1.7712,
      "step": 1390
    },
    {
      "epoch": 2.8629856850715747,
      "grad_norm": 5.905746936798096,
      "learning_rate": 9.857960936701094e-05,
      "loss": 1.847,
      "step": 1400
    },
    {
      "epoch": 2.8629856850715747,
      "eval_loss": 1.9054361581802368,
      "eval_runtime": 28.8063,
      "eval_samples_per_second": 11.178,
      "eval_steps_per_second": 0.937,
      "step": 1400
    },
    {
      "epoch": 2.883435582822086,
      "grad_norm": 2.05417799949646,
      "learning_rate": 9.856938337253299e-05,
      "loss": 1.9036,
      "step": 1410
    },
    {
      "epoch": 2.903885480572597,
      "grad_norm": 1.8082107305526733,
      "learning_rate": 9.855915737805502e-05,
      "loss": 1.8927,
      "step": 1420
    },
    {
      "epoch": 2.9243353783231085,
      "grad_norm": 2.416146993637085,
      "learning_rate": 9.854893138357705e-05,
      "loss": 1.8683,
      "step": 1430
    },
    {
      "epoch": 2.9447852760736195,
      "grad_norm": 2.0117974281311035,
      "learning_rate": 9.85387053890991e-05,
      "loss": 1.8167,
      "step": 1440
    },
    {
      "epoch": 2.965235173824131,
      "grad_norm": 1.874063491821289,
      "learning_rate": 9.852847939462113e-05,
      "loss": 1.6977,
      "step": 1450
    },
    {
      "epoch": 2.9856850715746424,
      "grad_norm": 2.4405035972595215,
      "learning_rate": 9.851825340014316e-05,
      "loss": 1.7916,
      "step": 1460
    },
    {
      "epoch": 3.0061349693251533,
      "grad_norm": 1.8543648719787598,
      "learning_rate": 9.850802740566521e-05,
      "loss": 1.7991,
      "step": 1470
    },
    {
      "epoch": 3.0265848670756648,
      "grad_norm": 2.0816473960876465,
      "learning_rate": 9.849780141118724e-05,
      "loss": 1.5619,
      "step": 1480
    },
    {
      "epoch": 3.0470347648261757,
      "grad_norm": 3.0356924533843994,
      "learning_rate": 9.848757541670928e-05,
      "loss": 1.5549,
      "step": 1490
    },
    {
      "epoch": 3.067484662576687,
      "grad_norm": 1.5118910074234009,
      "learning_rate": 9.847734942223132e-05,
      "loss": 1.6228,
      "step": 1500
    },
    {
      "epoch": 3.067484662576687,
      "eval_loss": 1.9134401082992554,
      "eval_runtime": 28.8081,
      "eval_samples_per_second": 11.177,
      "eval_steps_per_second": 0.937,
      "step": 1500
    },
    {
      "epoch": 3.087934560327198,
      "grad_norm": 2.6563992500305176,
      "learning_rate": 9.846712342775335e-05,
      "loss": 1.7227,
      "step": 1510
    },
    {
      "epoch": 3.1083844580777096,
      "grad_norm": 2.1798033714294434,
      "learning_rate": 9.845689743327539e-05,
      "loss": 1.5753,
      "step": 1520
    },
    {
      "epoch": 3.128834355828221,
      "grad_norm": 1.596625804901123,
      "learning_rate": 9.844667143879744e-05,
      "loss": 1.5182,
      "step": 1530
    },
    {
      "epoch": 3.149284253578732,
      "grad_norm": 2.261061191558838,
      "learning_rate": 9.843644544431947e-05,
      "loss": 1.5626,
      "step": 1540
    },
    {
      "epoch": 3.1697341513292434,
      "grad_norm": 2.3565356731414795,
      "learning_rate": 9.84262194498415e-05,
      "loss": 1.6345,
      "step": 1550
    },
    {
      "epoch": 3.190184049079755,
      "grad_norm": 2.603379726409912,
      "learning_rate": 9.841599345536355e-05,
      "loss": 1.5679,
      "step": 1560
    },
    {
      "epoch": 3.210633946830266,
      "grad_norm": 2.6916661262512207,
      "learning_rate": 9.840576746088558e-05,
      "loss": 1.6463,
      "step": 1570
    },
    {
      "epoch": 3.2310838445807772,
      "grad_norm": 2.900790214538574,
      "learning_rate": 9.839554146640761e-05,
      "loss": 1.6828,
      "step": 1580
    },
    {
      "epoch": 3.2515337423312882,
      "grad_norm": 3.9879283905029297,
      "learning_rate": 9.838531547192965e-05,
      "loss": 1.6447,
      "step": 1590
    },
    {
      "epoch": 3.2719836400817996,
      "grad_norm": 2.4110639095306396,
      "learning_rate": 9.837508947745169e-05,
      "loss": 1.5018,
      "step": 1600
    },
    {
      "epoch": 3.2719836400817996,
      "eval_loss": 1.9075027704238892,
      "eval_runtime": 28.7821,
      "eval_samples_per_second": 11.188,
      "eval_steps_per_second": 0.938,
      "step": 1600
    },
    {
      "epoch": 3.292433537832311,
      "grad_norm": 2.0234909057617188,
      "learning_rate": 9.836486348297372e-05,
      "loss": 1.7157,
      "step": 1610
    },
    {
      "epoch": 3.312883435582822,
      "grad_norm": 3.0828139781951904,
      "learning_rate": 9.835463748849576e-05,
      "loss": 1.6796,
      "step": 1620
    },
    {
      "epoch": 3.3333333333333335,
      "grad_norm": 2.089846134185791,
      "learning_rate": 9.83444114940178e-05,
      "loss": 1.6397,
      "step": 1630
    },
    {
      "epoch": 3.3537832310838445,
      "grad_norm": 3.2192187309265137,
      "learning_rate": 9.833418549953984e-05,
      "loss": 1.6006,
      "step": 1640
    },
    {
      "epoch": 3.374233128834356,
      "grad_norm": 1.543568730354309,
      "learning_rate": 9.832395950506187e-05,
      "loss": 1.5828,
      "step": 1650
    },
    {
      "epoch": 3.3946830265848673,
      "grad_norm": 3.254342555999756,
      "learning_rate": 9.83137335105839e-05,
      "loss": 1.6752,
      "step": 1660
    },
    {
      "epoch": 3.4151329243353783,
      "grad_norm": 2.9803366661071777,
      "learning_rate": 9.830350751610595e-05,
      "loss": 1.7069,
      "step": 1670
    },
    {
      "epoch": 3.4355828220858897,
      "grad_norm": 3.2749643325805664,
      "learning_rate": 9.829328152162798e-05,
      "loss": 1.7203,
      "step": 1680
    },
    {
      "epoch": 3.4560327198364007,
      "grad_norm": 2.2995762825012207,
      "learning_rate": 9.828305552715002e-05,
      "loss": 1.6134,
      "step": 1690
    },
    {
      "epoch": 3.476482617586912,
      "grad_norm": 3.0167958736419678,
      "learning_rate": 9.827282953267206e-05,
      "loss": 1.6912,
      "step": 1700
    },
    {
      "epoch": 3.476482617586912,
      "eval_loss": 1.8830958604812622,
      "eval_runtime": 28.8473,
      "eval_samples_per_second": 11.162,
      "eval_steps_per_second": 0.936,
      "step": 1700
    },
    {
      "epoch": 3.4969325153374236,
      "grad_norm": 2.168403387069702,
      "learning_rate": 9.82626035381941e-05,
      "loss": 1.8211,
      "step": 1710
    },
    {
      "epoch": 3.5173824130879345,
      "grad_norm": 1.9489232301712036,
      "learning_rate": 9.825237754371613e-05,
      "loss": 1.4842,
      "step": 1720
    },
    {
      "epoch": 3.537832310838446,
      "grad_norm": 2.447357654571533,
      "learning_rate": 9.824215154923816e-05,
      "loss": 1.7708,
      "step": 1730
    },
    {
      "epoch": 3.558282208588957,
      "grad_norm": 2.387925148010254,
      "learning_rate": 9.823192555476021e-05,
      "loss": 1.55,
      "step": 1740
    },
    {
      "epoch": 3.5787321063394684,
      "grad_norm": 1.8045074939727783,
      "learning_rate": 9.822169956028224e-05,
      "loss": 1.6067,
      "step": 1750
    },
    {
      "epoch": 3.59918200408998,
      "grad_norm": 2.0449423789978027,
      "learning_rate": 9.821147356580429e-05,
      "loss": 1.5821,
      "step": 1760
    },
    {
      "epoch": 3.6196319018404908,
      "grad_norm": 2.60722017288208,
      "learning_rate": 9.820124757132632e-05,
      "loss": 1.6707,
      "step": 1770
    },
    {
      "epoch": 3.640081799591002,
      "grad_norm": 1.4411919116973877,
      "learning_rate": 9.819102157684835e-05,
      "loss": 1.71,
      "step": 1780
    },
    {
      "epoch": 3.660531697341513,
      "grad_norm": 2.439310312271118,
      "learning_rate": 9.81807955823704e-05,
      "loss": 1.5479,
      "step": 1790
    },
    {
      "epoch": 3.6809815950920246,
      "grad_norm": 3.154533863067627,
      "learning_rate": 9.817056958789243e-05,
      "loss": 1.7049,
      "step": 1800
    },
    {
      "epoch": 3.6809815950920246,
      "eval_loss": 1.8796164989471436,
      "eval_runtime": 28.7828,
      "eval_samples_per_second": 11.187,
      "eval_steps_per_second": 0.938,
      "step": 1800
    },
    {
      "epoch": 3.701431492842536,
      "grad_norm": 3.2397124767303467,
      "learning_rate": 9.816034359341446e-05,
      "loss": 1.7013,
      "step": 1810
    },
    {
      "epoch": 3.721881390593047,
      "grad_norm": 2.155501365661621,
      "learning_rate": 9.81501175989365e-05,
      "loss": 1.6325,
      "step": 1820
    },
    {
      "epoch": 3.7423312883435584,
      "grad_norm": 4.92618989944458,
      "learning_rate": 9.813989160445853e-05,
      "loss": 1.6169,
      "step": 1830
    },
    {
      "epoch": 3.7627811860940694,
      "grad_norm": 2.502974271774292,
      "learning_rate": 9.812966560998057e-05,
      "loss": 1.6902,
      "step": 1840
    },
    {
      "epoch": 3.783231083844581,
      "grad_norm": 2.250502109527588,
      "learning_rate": 9.811943961550261e-05,
      "loss": 1.6425,
      "step": 1850
    },
    {
      "epoch": 3.8036809815950923,
      "grad_norm": 1.8553519248962402,
      "learning_rate": 9.810921362102466e-05,
      "loss": 1.4995,
      "step": 1860
    },
    {
      "epoch": 3.8241308793456033,
      "grad_norm": 2.4471516609191895,
      "learning_rate": 9.809898762654669e-05,
      "loss": 1.5873,
      "step": 1870
    },
    {
      "epoch": 3.8445807770961147,
      "grad_norm": 2.526855707168579,
      "learning_rate": 9.808876163206872e-05,
      "loss": 1.5436,
      "step": 1880
    },
    {
      "epoch": 3.8650306748466257,
      "grad_norm": 3.2008302211761475,
      "learning_rate": 9.807853563759076e-05,
      "loss": 1.5804,
      "step": 1890
    },
    {
      "epoch": 3.885480572597137,
      "grad_norm": 1.5239392518997192,
      "learning_rate": 9.80683096431128e-05,
      "loss": 1.4873,
      "step": 1900
    },
    {
      "epoch": 3.885480572597137,
      "eval_loss": 1.8612754344940186,
      "eval_runtime": 28.7848,
      "eval_samples_per_second": 11.186,
      "eval_steps_per_second": 0.938,
      "step": 1900
    },
    {
      "epoch": 3.9059304703476485,
      "grad_norm": 2.5062692165374756,
      "learning_rate": 9.805808364863484e-05,
      "loss": 1.5102,
      "step": 1910
    },
    {
      "epoch": 3.9263803680981595,
      "grad_norm": 2.215038299560547,
      "learning_rate": 9.804785765415687e-05,
      "loss": 1.5926,
      "step": 1920
    },
    {
      "epoch": 3.946830265848671,
      "grad_norm": 2.9763174057006836,
      "learning_rate": 9.80376316596789e-05,
      "loss": 1.5652,
      "step": 1930
    },
    {
      "epoch": 3.967280163599182,
      "grad_norm": 2.11491322517395,
      "learning_rate": 9.802740566520095e-05,
      "loss": 1.6084,
      "step": 1940
    },
    {
      "epoch": 3.9877300613496933,
      "grad_norm": 2.6789042949676514,
      "learning_rate": 9.801717967072298e-05,
      "loss": 1.4645,
      "step": 1950
    },
    {
      "epoch": 4.008179959100205,
      "grad_norm": 3.8913636207580566,
      "learning_rate": 9.800695367624501e-05,
      "loss": 1.3691,
      "step": 1960
    },
    {
      "epoch": 4.028629856850716,
      "grad_norm": 2.217745542526245,
      "learning_rate": 9.799672768176706e-05,
      "loss": 1.2352,
      "step": 1970
    },
    {
      "epoch": 4.049079754601227,
      "grad_norm": 3.1914398670196533,
      "learning_rate": 9.798650168728909e-05,
      "loss": 1.5044,
      "step": 1980
    },
    {
      "epoch": 4.069529652351738,
      "grad_norm": 3.3091089725494385,
      "learning_rate": 9.797627569281112e-05,
      "loss": 1.4522,
      "step": 1990
    },
    {
      "epoch": 4.08997955010225,
      "grad_norm": 3.185791254043579,
      "learning_rate": 9.796604969833317e-05,
      "loss": 1.4303,
      "step": 2000
    },
    {
      "epoch": 4.08997955010225,
      "eval_loss": 1.8791496753692627,
      "eval_runtime": 28.7518,
      "eval_samples_per_second": 11.199,
      "eval_steps_per_second": 0.939,
      "step": 2000
    },
    {
      "epoch": 4.110429447852761,
      "grad_norm": 1.7780603170394897,
      "learning_rate": 9.59112292902434e-05,
      "loss": 1.4264,
      "step": 2010
    },
    {
      "epoch": 4.130879345603272,
      "grad_norm": 2.386599063873291,
      "learning_rate": 9.589077520965433e-05,
      "loss": 1.4542,
      "step": 2020
    },
    {
      "epoch": 4.151329243353783,
      "grad_norm": 3.4552221298217773,
      "learning_rate": 9.587032112906525e-05,
      "loss": 1.36,
      "step": 2030
    },
    {
      "epoch": 4.171779141104294,
      "grad_norm": 2.6857447624206543,
      "learning_rate": 9.584986704847617e-05,
      "loss": 1.4104,
      "step": 2040
    },
    {
      "epoch": 4.192229038854806,
      "grad_norm": 2.926292657852173,
      "learning_rate": 9.58294129678871e-05,
      "loss": 1.2564,
      "step": 2050
    },
    {
      "epoch": 4.212678936605317,
      "grad_norm": 1.6384332180023193,
      "learning_rate": 9.580895888729802e-05,
      "loss": 1.4873,
      "step": 2060
    },
    {
      "epoch": 4.233128834355828,
      "grad_norm": 1.87344229221344,
      "learning_rate": 9.578850480670895e-05,
      "loss": 1.3424,
      "step": 2070
    },
    {
      "epoch": 4.253578732106339,
      "grad_norm": 2.168306589126587,
      "learning_rate": 9.576805072611986e-05,
      "loss": 1.3349,
      "step": 2080
    },
    {
      "epoch": 4.274028629856851,
      "grad_norm": 2.4015719890594482,
      "learning_rate": 9.57475966455308e-05,
      "loss": 1.434,
      "step": 2090
    },
    {
      "epoch": 4.294478527607362,
      "grad_norm": 2.066416025161743,
      "learning_rate": 9.57271425649417e-05,
      "loss": 1.4562,
      "step": 2100
    },
    {
      "epoch": 4.294478527607362,
      "eval_loss": 1.880524754524231,
      "eval_runtime": 27.4988,
      "eval_samples_per_second": 11.71,
      "eval_steps_per_second": 0.982,
      "step": 2100
    },
    {
      "epoch": 4.3149284253578735,
      "grad_norm": 3.1066722869873047,
      "learning_rate": 9.570668848435264e-05,
      "loss": 1.4232,
      "step": 2110
    },
    {
      "epoch": 4.335378323108385,
      "grad_norm": 2.8498153686523438,
      "learning_rate": 9.568623440376355e-05,
      "loss": 1.4108,
      "step": 2120
    },
    {
      "epoch": 4.355828220858895,
      "grad_norm": 3.0075268745422363,
      "learning_rate": 9.566578032317448e-05,
      "loss": 1.4745,
      "step": 2130
    },
    {
      "epoch": 4.376278118609407,
      "grad_norm": 2.1991841793060303,
      "learning_rate": 9.564532624258539e-05,
      "loss": 1.4972,
      "step": 2140
    },
    {
      "epoch": 4.396728016359918,
      "grad_norm": 1.9855378866195679,
      "learning_rate": 9.562487216199633e-05,
      "loss": 1.4141,
      "step": 2150
    },
    {
      "epoch": 4.41717791411043,
      "grad_norm": 3.8050878047943115,
      "learning_rate": 9.560441808140724e-05,
      "loss": 1.5143,
      "step": 2160
    },
    {
      "epoch": 4.43762781186094,
      "grad_norm": 2.532984733581543,
      "learning_rate": 9.558396400081817e-05,
      "loss": 1.3224,
      "step": 2170
    },
    {
      "epoch": 4.458077709611452,
      "grad_norm": 3.3192384243011475,
      "learning_rate": 9.55635099202291e-05,
      "loss": 1.3782,
      "step": 2180
    },
    {
      "epoch": 4.478527607361963,
      "grad_norm": 2.1606829166412354,
      "learning_rate": 9.554305583964002e-05,
      "loss": 1.6227,
      "step": 2190
    },
    {
      "epoch": 4.4989775051124745,
      "grad_norm": 3.408284902572632,
      "learning_rate": 9.552260175905094e-05,
      "loss": 1.3036,
      "step": 2200
    },
    {
      "epoch": 4.4989775051124745,
      "eval_loss": 1.8661261796951294,
      "eval_runtime": 27.6069,
      "eval_samples_per_second": 11.664,
      "eval_steps_per_second": 0.978,
      "step": 2200
    },
    {
      "epoch": 4.519427402862986,
      "grad_norm": 2.3339741230010986,
      "learning_rate": 9.550214767846186e-05,
      "loss": 1.3431,
      "step": 2210
    },
    {
      "epoch": 4.539877300613497,
      "grad_norm": 2.4306092262268066,
      "learning_rate": 9.548169359787278e-05,
      "loss": 1.3078,
      "step": 2220
    },
    {
      "epoch": 4.560327198364008,
      "grad_norm": 2.362920045852661,
      "learning_rate": 9.54612395172837e-05,
      "loss": 1.4182,
      "step": 2230
    },
    {
      "epoch": 4.580777096114519,
      "grad_norm": 3.8697872161865234,
      "learning_rate": 9.544078543669463e-05,
      "loss": 1.4833,
      "step": 2240
    },
    {
      "epoch": 4.601226993865031,
      "grad_norm": 2.5228583812713623,
      "learning_rate": 9.542033135610555e-05,
      "loss": 1.3992,
      "step": 2250
    },
    {
      "epoch": 4.621676891615542,
      "grad_norm": 3.857908010482788,
      "learning_rate": 9.539987727551647e-05,
      "loss": 1.3217,
      "step": 2260
    },
    {
      "epoch": 4.642126789366053,
      "grad_norm": 2.884817600250244,
      "learning_rate": 9.53794231949274e-05,
      "loss": 1.4456,
      "step": 2270
    },
    {
      "epoch": 4.662576687116564,
      "grad_norm": 2.599324941635132,
      "learning_rate": 9.535896911433832e-05,
      "loss": 1.3521,
      "step": 2280
    },
    {
      "epoch": 4.683026584867076,
      "grad_norm": 2.4563941955566406,
      "learning_rate": 9.533851503374924e-05,
      "loss": 1.3943,
      "step": 2290
    },
    {
      "epoch": 4.703476482617587,
      "grad_norm": 2.9468019008636475,
      "learning_rate": 9.531806095316016e-05,
      "loss": 1.3749,
      "step": 2300
    },
    {
      "epoch": 4.703476482617587,
      "eval_loss": 1.8336633443832397,
      "eval_runtime": 27.5659,
      "eval_samples_per_second": 11.681,
      "eval_steps_per_second": 0.979,
      "step": 2300
    },
    {
      "epoch": 4.723926380368098,
      "grad_norm": 2.837822198867798,
      "learning_rate": 9.529760687257108e-05,
      "loss": 1.1944,
      "step": 2310
    },
    {
      "epoch": 4.74437627811861,
      "grad_norm": 3.5285069942474365,
      "learning_rate": 9.5277152791982e-05,
      "loss": 1.3218,
      "step": 2320
    },
    {
      "epoch": 4.76482617586912,
      "grad_norm": 3.830476999282837,
      "learning_rate": 9.525669871139293e-05,
      "loss": 1.3796,
      "step": 2330
    },
    {
      "epoch": 4.785276073619632,
      "grad_norm": 3.3250346183776855,
      "learning_rate": 9.523624463080385e-05,
      "loss": 1.2264,
      "step": 2340
    },
    {
      "epoch": 4.805725971370143,
      "grad_norm": 3.76914381980896,
      "learning_rate": 9.521579055021477e-05,
      "loss": 1.2485,
      "step": 2350
    },
    {
      "epoch": 4.826175869120655,
      "grad_norm": 2.2480528354644775,
      "learning_rate": 9.519533646962569e-05,
      "loss": 1.4774,
      "step": 2360
    },
    {
      "epoch": 4.846625766871165,
      "grad_norm": 3.391969919204712,
      "learning_rate": 9.517488238903662e-05,
      "loss": 1.3211,
      "step": 2370
    },
    {
      "epoch": 4.867075664621677,
      "grad_norm": 3.2025833129882812,
      "learning_rate": 9.515442830844754e-05,
      "loss": 1.2963,
      "step": 2380
    },
    {
      "epoch": 4.887525562372188,
      "grad_norm": 3.1702916622161865,
      "learning_rate": 9.513397422785846e-05,
      "loss": 1.5009,
      "step": 2390
    },
    {
      "epoch": 4.9079754601226995,
      "grad_norm": 2.926823377609253,
      "learning_rate": 9.511352014726938e-05,
      "loss": 1.1926,
      "step": 2400
    },
    {
      "epoch": 4.9079754601226995,
      "eval_loss": 1.8397819995880127,
      "eval_runtime": 27.5984,
      "eval_samples_per_second": 11.667,
      "eval_steps_per_second": 0.978,
      "step": 2400
    },
    {
      "epoch": 4.928425357873211,
      "grad_norm": 2.468066930770874,
      "learning_rate": 9.50930660666803e-05,
      "loss": 1.3987,
      "step": 2410
    },
    {
      "epoch": 4.948875255623722,
      "grad_norm": 3.0268166065216064,
      "learning_rate": 9.507261198609123e-05,
      "loss": 1.4618,
      "step": 2420
    },
    {
      "epoch": 4.969325153374233,
      "grad_norm": 2.9782896041870117,
      "learning_rate": 9.505215790550215e-05,
      "loss": 1.4683,
      "step": 2430
    },
    {
      "epoch": 4.989775051124744,
      "grad_norm": 3.5281906127929688,
      "learning_rate": 9.503170382491307e-05,
      "loss": 1.4247,
      "step": 2440
    },
    {
      "epoch": 5.010224948875256,
      "grad_norm": 2.4150960445404053,
      "learning_rate": 9.501124974432399e-05,
      "loss": 1.287,
      "step": 2450
    },
    {
      "epoch": 5.030674846625767,
      "grad_norm": 3.74704909324646,
      "learning_rate": 9.499079566373493e-05,
      "loss": 1.1829,
      "step": 2460
    },
    {
      "epoch": 5.051124744376278,
      "grad_norm": 3.3687448501586914,
      "learning_rate": 9.497034158314584e-05,
      "loss": 1.3583,
      "step": 2470
    },
    {
      "epoch": 5.071574642126789,
      "grad_norm": 3.0298781394958496,
      "learning_rate": 9.494988750255677e-05,
      "loss": 1.1274,
      "step": 2480
    },
    {
      "epoch": 5.0920245398773005,
      "grad_norm": 4.7780537605285645,
      "learning_rate": 9.492943342196768e-05,
      "loss": 1.0035,
      "step": 2490
    },
    {
      "epoch": 5.112474437627812,
      "grad_norm": 2.083958148956299,
      "learning_rate": 9.490897934137862e-05,
      "loss": 1.2154,
      "step": 2500
    },
    {
      "epoch": 5.112474437627812,
      "eval_loss": 1.8765869140625,
      "eval_runtime": 27.6005,
      "eval_samples_per_second": 11.666,
      "eval_steps_per_second": 0.978,
      "step": 2500
    },
    {
      "epoch": 5.132924335378323,
      "grad_norm": 3.105919122695923,
      "learning_rate": 9.488852526078952e-05,
      "loss": 1.2725,
      "step": 2510
    },
    {
      "epoch": 5.153374233128835,
      "grad_norm": 2.267087459564209,
      "learning_rate": 9.486807118020046e-05,
      "loss": 1.1492,
      "step": 2520
    },
    {
      "epoch": 5.173824130879345,
      "grad_norm": 2.8361494541168213,
      "learning_rate": 9.484761709961137e-05,
      "loss": 1.4625,
      "step": 2530
    },
    {
      "epoch": 5.194274028629857,
      "grad_norm": 4.216054439544678,
      "learning_rate": 9.48271630190223e-05,
      "loss": 1.2385,
      "step": 2540
    },
    {
      "epoch": 5.214723926380368,
      "grad_norm": 3.456453323364258,
      "learning_rate": 9.480670893843321e-05,
      "loss": 1.1779,
      "step": 2550
    },
    {
      "epoch": 5.23517382413088,
      "grad_norm": 2.4649782180786133,
      "learning_rate": 9.478625485784415e-05,
      "loss": 0.9465,
      "step": 2560
    },
    {
      "epoch": 5.25562372188139,
      "grad_norm": 2.9983737468719482,
      "learning_rate": 9.476580077725507e-05,
      "loss": 1.304,
      "step": 2570
    },
    {
      "epoch": 5.276073619631902,
      "grad_norm": 3.0402421951293945,
      "learning_rate": 9.474534669666599e-05,
      "loss": 1.3254,
      "step": 2580
    },
    {
      "epoch": 5.296523517382413,
      "grad_norm": 3.6791672706604004,
      "learning_rate": 9.472489261607692e-05,
      "loss": 1.0487,
      "step": 2590
    },
    {
      "epoch": 5.316973415132924,
      "grad_norm": 2.6939570903778076,
      "learning_rate": 9.470443853548784e-05,
      "loss": 1.0966,
      "step": 2600
    },
    {
      "epoch": 5.316973415132924,
      "eval_loss": 1.8662083148956299,
      "eval_runtime": 27.557,
      "eval_samples_per_second": 11.685,
      "eval_steps_per_second": 0.98,
      "step": 2600
    },
    {
      "epoch": 5.337423312883436,
      "grad_norm": 2.616506576538086,
      "learning_rate": 9.468398445489876e-05,
      "loss": 1.2665,
      "step": 2610
    },
    {
      "epoch": 5.357873210633947,
      "grad_norm": 2.4716615676879883,
      "learning_rate": 9.466353037430968e-05,
      "loss": 1.5596,
      "step": 2620
    },
    {
      "epoch": 5.378323108384458,
      "grad_norm": 2.617891311645508,
      "learning_rate": 9.46430762937206e-05,
      "loss": 1.1852,
      "step": 2630
    },
    {
      "epoch": 5.398773006134969,
      "grad_norm": 3.161959171295166,
      "learning_rate": 9.462262221313153e-05,
      "loss": 1.3246,
      "step": 2640
    },
    {
      "epoch": 5.419222903885481,
      "grad_norm": 1.6593586206436157,
      "learning_rate": 9.460216813254245e-05,
      "loss": 1.2177,
      "step": 2650
    },
    {
      "epoch": 5.439672801635992,
      "grad_norm": 3.2933781147003174,
      "learning_rate": 9.458171405195337e-05,
      "loss": 1.3123,
      "step": 2660
    },
    {
      "epoch": 5.460122699386503,
      "grad_norm": 2.5910825729370117,
      "learning_rate": 9.456125997136429e-05,
      "loss": 1.3589,
      "step": 2670
    },
    {
      "epoch": 5.480572597137014,
      "grad_norm": 2.981522798538208,
      "learning_rate": 9.454080589077521e-05,
      "loss": 1.3269,
      "step": 2680
    },
    {
      "epoch": 5.5010224948875255,
      "grad_norm": 2.5106239318847656,
      "learning_rate": 9.452035181018614e-05,
      "loss": 1.2615,
      "step": 2690
    },
    {
      "epoch": 5.521472392638037,
      "grad_norm": 2.6329152584075928,
      "learning_rate": 9.449989772959706e-05,
      "loss": 1.3582,
      "step": 2700
    },
    {
      "epoch": 5.521472392638037,
      "eval_loss": 1.8593554496765137,
      "eval_runtime": 27.5234,
      "eval_samples_per_second": 11.699,
      "eval_steps_per_second": 0.981,
      "step": 2700
    },
    {
      "epoch": 5.541922290388548,
      "grad_norm": 3.031275510787964,
      "learning_rate": 9.447944364900798e-05,
      "loss": 1.198,
      "step": 2710
    },
    {
      "epoch": 5.56237218813906,
      "grad_norm": 3.2346105575561523,
      "learning_rate": 9.44589895684189e-05,
      "loss": 1.1378,
      "step": 2720
    },
    {
      "epoch": 5.58282208588957,
      "grad_norm": 2.800846815109253,
      "learning_rate": 9.443853548782982e-05,
      "loss": 1.3474,
      "step": 2730
    },
    {
      "epoch": 5.603271983640082,
      "grad_norm": 3.9688215255737305,
      "learning_rate": 9.441808140724075e-05,
      "loss": 1.2497,
      "step": 2740
    },
    {
      "epoch": 5.623721881390593,
      "grad_norm": 2.1660258769989014,
      "learning_rate": 9.439762732665167e-05,
      "loss": 1.1211,
      "step": 2750
    },
    {
      "epoch": 5.644171779141105,
      "grad_norm": 2.436614751815796,
      "learning_rate": 9.437717324606259e-05,
      "loss": 1.2486,
      "step": 2760
    },
    {
      "epoch": 5.664621676891615,
      "grad_norm": 3.8254432678222656,
      "learning_rate": 9.435671916547351e-05,
      "loss": 1.1616,
      "step": 2770
    },
    {
      "epoch": 5.6850715746421265,
      "grad_norm": 2.359205722808838,
      "learning_rate": 9.433626508488444e-05,
      "loss": 1.1496,
      "step": 2780
    },
    {
      "epoch": 5.705521472392638,
      "grad_norm": 2.850818634033203,
      "learning_rate": 9.431581100429536e-05,
      "loss": 1.1209,
      "step": 2790
    },
    {
      "epoch": 5.725971370143149,
      "grad_norm": 2.746335029602051,
      "learning_rate": 9.429535692370628e-05,
      "loss": 1.3315,
      "step": 2800
    },
    {
      "epoch": 5.725971370143149,
      "eval_loss": 1.8417140245437622,
      "eval_runtime": 27.5431,
      "eval_samples_per_second": 11.691,
      "eval_steps_per_second": 0.98,
      "step": 2800
    },
    {
      "epoch": 5.746421267893661,
      "grad_norm": 2.377164602279663,
      "learning_rate": 9.42749028431172e-05,
      "loss": 1.4904,
      "step": 2810
    },
    {
      "epoch": 5.766871165644172,
      "grad_norm": 2.134620189666748,
      "learning_rate": 9.425444876252812e-05,
      "loss": 1.2331,
      "step": 2820
    },
    {
      "epoch": 5.787321063394683,
      "grad_norm": 2.4891717433929443,
      "learning_rate": 9.423399468193906e-05,
      "loss": 1.0753,
      "step": 2830
    },
    {
      "epoch": 5.807770961145194,
      "grad_norm": 2.760864734649658,
      "learning_rate": 9.421354060134997e-05,
      "loss": 1.3149,
      "step": 2840
    },
    {
      "epoch": 5.828220858895706,
      "grad_norm": 2.431925058364868,
      "learning_rate": 9.41930865207609e-05,
      "loss": 1.3883,
      "step": 2850
    },
    {
      "epoch": 5.848670756646217,
      "grad_norm": 2.586735963821411,
      "learning_rate": 9.417263244017181e-05,
      "loss": 1.1947,
      "step": 2860
    },
    {
      "epoch": 5.869120654396728,
      "grad_norm": 3.849989175796509,
      "learning_rate": 9.415217835958275e-05,
      "loss": 1.2294,
      "step": 2870
    },
    {
      "epoch": 5.889570552147239,
      "grad_norm": 2.8431265354156494,
      "learning_rate": 9.413172427899366e-05,
      "loss": 1.1348,
      "step": 2880
    },
    {
      "epoch": 5.91002044989775,
      "grad_norm": 3.3074049949645996,
      "learning_rate": 9.411127019840459e-05,
      "loss": 1.2535,
      "step": 2890
    },
    {
      "epoch": 5.930470347648262,
      "grad_norm": 3.814135789871216,
      "learning_rate": 9.40908161178155e-05,
      "loss": 1.331,
      "step": 2900
    },
    {
      "epoch": 5.930470347648262,
      "eval_loss": 1.829906702041626,
      "eval_runtime": 27.5516,
      "eval_samples_per_second": 11.687,
      "eval_steps_per_second": 0.98,
      "step": 2900
    },
    {
      "epoch": 5.950920245398773,
      "grad_norm": 4.741674423217773,
      "learning_rate": 9.407036203722644e-05,
      "loss": 1.4588,
      "step": 2910
    },
    {
      "epoch": 5.971370143149285,
      "grad_norm": 2.458141326904297,
      "learning_rate": 9.404990795663735e-05,
      "loss": 1.14,
      "step": 2920
    },
    {
      "epoch": 5.991820040899795,
      "grad_norm": 2.9285740852355957,
      "learning_rate": 9.402945387604828e-05,
      "loss": 1.1228,
      "step": 2930
    },
    {
      "epoch": 6.012269938650307,
      "grad_norm": 2.6744327545166016,
      "learning_rate": 9.40089997954592e-05,
      "loss": 1.0106,
      "step": 2940
    },
    {
      "epoch": 6.032719836400818,
      "grad_norm": 4.208680629730225,
      "learning_rate": 9.398854571487012e-05,
      "loss": 0.9622,
      "step": 2950
    },
    {
      "epoch": 6.0531697341513295,
      "grad_norm": 2.1940572261810303,
      "learning_rate": 9.396809163428105e-05,
      "loss": 0.9724,
      "step": 2960
    },
    {
      "epoch": 6.07361963190184,
      "grad_norm": 3.9397027492523193,
      "learning_rate": 9.394763755369197e-05,
      "loss": 1.159,
      "step": 2970
    },
    {
      "epoch": 6.0940695296523515,
      "grad_norm": 3.4868204593658447,
      "learning_rate": 9.392718347310289e-05,
      "loss": 1.1148,
      "step": 2980
    },
    {
      "epoch": 6.114519427402863,
      "grad_norm": 2.2202577590942383,
      "learning_rate": 9.390672939251381e-05,
      "loss": 1.036,
      "step": 2990
    },
    {
      "epoch": 6.134969325153374,
      "grad_norm": 2.0883612632751465,
      "learning_rate": 9.388627531192474e-05,
      "loss": 1.0191,
      "step": 3000
    },
    {
      "epoch": 6.134969325153374,
      "eval_loss": 1.8973175287246704,
      "eval_runtime": 27.5426,
      "eval_samples_per_second": 11.691,
      "eval_steps_per_second": 0.98,
      "step": 3000
    },
    {
      "epoch": 6.155419222903886,
      "grad_norm": 4.064414978027344,
      "learning_rate": 9.386582123133566e-05,
      "loss": 1.1033,
      "step": 3010
    },
    {
      "epoch": 6.175869120654396,
      "grad_norm": 3.53377628326416,
      "learning_rate": 9.384536715074658e-05,
      "loss": 1.1326,
      "step": 3020
    },
    {
      "epoch": 6.196319018404908,
      "grad_norm": 2.193298578262329,
      "learning_rate": 9.38249130701575e-05,
      "loss": 1.048,
      "step": 3030
    },
    {
      "epoch": 6.216768916155419,
      "grad_norm": 5.054941654205322,
      "learning_rate": 9.380445898956842e-05,
      "loss": 1.1687,
      "step": 3040
    },
    {
      "epoch": 6.237218813905931,
      "grad_norm": 3.426129102706909,
      "learning_rate": 9.378400490897935e-05,
      "loss": 1.1264,
      "step": 3050
    },
    {
      "epoch": 6.257668711656442,
      "grad_norm": 3.8763949871063232,
      "learning_rate": 9.376355082839027e-05,
      "loss": 1.0792,
      "step": 3060
    },
    {
      "epoch": 6.2781186094069525,
      "grad_norm": 2.7389323711395264,
      "learning_rate": 9.374309674780119e-05,
      "loss": 0.8688,
      "step": 3070
    },
    {
      "epoch": 6.298568507157464,
      "grad_norm": 3.2476701736450195,
      "learning_rate": 9.372264266721211e-05,
      "loss": 0.9081,
      "step": 3080
    },
    {
      "epoch": 6.319018404907975,
      "grad_norm": 2.9579076766967773,
      "learning_rate": 9.370218858662303e-05,
      "loss": 1.0113,
      "step": 3090
    },
    {
      "epoch": 6.339468302658487,
      "grad_norm": 4.672913074493408,
      "learning_rate": 9.368173450603396e-05,
      "loss": 1.1166,
      "step": 3100
    },
    {
      "epoch": 6.339468302658487,
      "eval_loss": 1.9047633409500122,
      "eval_runtime": 27.5394,
      "eval_samples_per_second": 11.692,
      "eval_steps_per_second": 0.98,
      "step": 3100
    },
    {
      "epoch": 6.359918200408998,
      "grad_norm": 2.4347896575927734,
      "learning_rate": 9.366128042544489e-05,
      "loss": 1.2537,
      "step": 3110
    },
    {
      "epoch": 6.38036809815951,
      "grad_norm": 2.9861364364624023,
      "learning_rate": 9.36408263448558e-05,
      "loss": 1.1136,
      "step": 3120
    },
    {
      "epoch": 6.40081799591002,
      "grad_norm": 3.4791831970214844,
      "learning_rate": 9.362037226426672e-05,
      "loss": 1.1036,
      "step": 3130
    },
    {
      "epoch": 6.421267893660532,
      "grad_norm": 4.046227931976318,
      "learning_rate": 9.359991818367765e-05,
      "loss": 1.1712,
      "step": 3140
    },
    {
      "epoch": 6.441717791411043,
      "grad_norm": 2.2894303798675537,
      "learning_rate": 9.357946410308857e-05,
      "loss": 1.1403,
      "step": 3150
    },
    {
      "epoch": 6.4621676891615545,
      "grad_norm": 3.8989083766937256,
      "learning_rate": 9.355901002249949e-05,
      "loss": 1.0193,
      "step": 3160
    },
    {
      "epoch": 6.482617586912065,
      "grad_norm": 4.149906158447266,
      "learning_rate": 9.353855594191041e-05,
      "loss": 1.0695,
      "step": 3170
    },
    {
      "epoch": 6.5030674846625764,
      "grad_norm": 2.498328685760498,
      "learning_rate": 9.351810186132133e-05,
      "loss": 1.0007,
      "step": 3180
    },
    {
      "epoch": 6.523517382413088,
      "grad_norm": 3.560638666152954,
      "learning_rate": 9.349764778073226e-05,
      "loss": 1.1336,
      "step": 3190
    },
    {
      "epoch": 6.543967280163599,
      "grad_norm": 2.5322022438049316,
      "learning_rate": 9.347719370014318e-05,
      "loss": 0.9883,
      "step": 3200
    },
    {
      "epoch": 6.543967280163599,
      "eval_loss": 1.8979893922805786,
      "eval_runtime": 27.5729,
      "eval_samples_per_second": 11.678,
      "eval_steps_per_second": 0.979,
      "step": 3200
    },
    {
      "epoch": 6.564417177914111,
      "grad_norm": 4.016748905181885,
      "learning_rate": 9.34567396195541e-05,
      "loss": 1.1208,
      "step": 3210
    },
    {
      "epoch": 6.584867075664622,
      "grad_norm": 3.14975643157959,
      "learning_rate": 9.343628553896504e-05,
      "loss": 1.1274,
      "step": 3220
    },
    {
      "epoch": 6.605316973415133,
      "grad_norm": 4.338189125061035,
      "learning_rate": 9.341583145837594e-05,
      "loss": 0.9956,
      "step": 3230
    },
    {
      "epoch": 6.625766871165644,
      "grad_norm": 3.214175224304199,
      "learning_rate": 9.339537737778688e-05,
      "loss": 1.1544,
      "step": 3240
    },
    {
      "epoch": 6.6462167689161555,
      "grad_norm": 2.347911834716797,
      "learning_rate": 9.337492329719779e-05,
      "loss": 1.2435,
      "step": 3250
    },
    {
      "epoch": 6.666666666666667,
      "grad_norm": 3.4271726608276367,
      "learning_rate": 9.335446921660872e-05,
      "loss": 1.0571,
      "step": 3260
    },
    {
      "epoch": 6.6871165644171775,
      "grad_norm": 2.7374212741851807,
      "learning_rate": 9.333401513601963e-05,
      "loss": 1.0076,
      "step": 3270
    },
    {
      "epoch": 6.707566462167689,
      "grad_norm": 2.3400771617889404,
      "learning_rate": 9.331356105543057e-05,
      "loss": 1.3949,
      "step": 3280
    },
    {
      "epoch": 6.7280163599182,
      "grad_norm": 2.8969759941101074,
      "learning_rate": 9.329310697484148e-05,
      "loss": 1.0332,
      "step": 3290
    },
    {
      "epoch": 6.748466257668712,
      "grad_norm": 2.7222676277160645,
      "learning_rate": 9.327265289425241e-05,
      "loss": 1.2935,
      "step": 3300
    },
    {
      "epoch": 6.748466257668712,
      "eval_loss": 1.8703492879867554,
      "eval_runtime": 27.5309,
      "eval_samples_per_second": 11.696,
      "eval_steps_per_second": 0.981,
      "step": 3300
    },
    {
      "epoch": 6.768916155419223,
      "grad_norm": 2.5310757160186768,
      "learning_rate": 9.325219881366332e-05,
      "loss": 1.2093,
      "step": 3310
    },
    {
      "epoch": 6.789366053169735,
      "grad_norm": 2.4910011291503906,
      "learning_rate": 9.323174473307426e-05,
      "loss": 1.3728,
      "step": 3320
    },
    {
      "epoch": 6.809815950920245,
      "grad_norm": 2.2584388256073,
      "learning_rate": 9.321129065248518e-05,
      "loss": 1.1691,
      "step": 3330
    },
    {
      "epoch": 6.830265848670757,
      "grad_norm": 2.494370460510254,
      "learning_rate": 9.31908365718961e-05,
      "loss": 0.9797,
      "step": 3340
    },
    {
      "epoch": 6.850715746421268,
      "grad_norm": 2.751574754714966,
      "learning_rate": 9.317038249130702e-05,
      "loss": 1.0328,
      "step": 3350
    },
    {
      "epoch": 6.871165644171779,
      "grad_norm": 2.4138412475585938,
      "learning_rate": 9.314992841071795e-05,
      "loss": 1.2743,
      "step": 3360
    },
    {
      "epoch": 6.89161554192229,
      "grad_norm": 3.6309337615966797,
      "learning_rate": 9.312947433012887e-05,
      "loss": 1.1253,
      "step": 3370
    },
    {
      "epoch": 6.912065439672801,
      "grad_norm": 2.3006644248962402,
      "learning_rate": 9.310902024953979e-05,
      "loss": 1.2009,
      "step": 3380
    },
    {
      "epoch": 6.932515337423313,
      "grad_norm": 3.4294605255126953,
      "learning_rate": 9.308856616895071e-05,
      "loss": 1.0013,
      "step": 3390
    },
    {
      "epoch": 6.952965235173824,
      "grad_norm": 3.312291145324707,
      "learning_rate": 9.306811208836163e-05,
      "loss": 1.0337,
      "step": 3400
    },
    {
      "epoch": 6.952965235173824,
      "eval_loss": 1.8862645626068115,
      "eval_runtime": 27.5666,
      "eval_samples_per_second": 11.681,
      "eval_steps_per_second": 0.979,
      "step": 3400
    },
    {
      "epoch": 6.973415132924336,
      "grad_norm": 3.1388566493988037,
      "learning_rate": 9.304765800777256e-05,
      "loss": 1.0922,
      "step": 3410
    },
    {
      "epoch": 6.993865030674847,
      "grad_norm": 3.3008108139038086,
      "learning_rate": 9.302720392718348e-05,
      "loss": 1.0344,
      "step": 3420
    },
    {
      "epoch": 7.014314928425358,
      "grad_norm": 3.765932083129883,
      "learning_rate": 9.30067498465944e-05,
      "loss": 1.0277,
      "step": 3430
    },
    {
      "epoch": 7.034764826175869,
      "grad_norm": 2.351531505584717,
      "learning_rate": 9.298629576600532e-05,
      "loss": 1.019,
      "step": 3440
    },
    {
      "epoch": 7.0552147239263805,
      "grad_norm": 3.688459634780884,
      "learning_rate": 9.296584168541624e-05,
      "loss": 0.976,
      "step": 3450
    },
    {
      "epoch": 7.075664621676892,
      "grad_norm": 2.6491732597351074,
      "learning_rate": 9.294538760482717e-05,
      "loss": 1.1233,
      "step": 3460
    },
    {
      "epoch": 7.0961145194274025,
      "grad_norm": 3.034842014312744,
      "learning_rate": 9.292493352423809e-05,
      "loss": 0.9542,
      "step": 3470
    },
    {
      "epoch": 7.116564417177914,
      "grad_norm": 3.8747482299804688,
      "learning_rate": 9.290447944364901e-05,
      "loss": 0.8646,
      "step": 3480
    },
    {
      "epoch": 7.137014314928425,
      "grad_norm": 2.74662709236145,
      "learning_rate": 9.288402536305993e-05,
      "loss": 1.0665,
      "step": 3490
    },
    {
      "epoch": 7.157464212678937,
      "grad_norm": 2.3150742053985596,
      "learning_rate": 9.286357128247087e-05,
      "loss": 0.8482,
      "step": 3500
    },
    {
      "epoch": 7.157464212678937,
      "eval_loss": 1.958294153213501,
      "eval_runtime": 27.5303,
      "eval_samples_per_second": 11.696,
      "eval_steps_per_second": 0.981,
      "step": 3500
    },
    {
      "epoch": 7.177914110429448,
      "grad_norm": 2.636411428451538,
      "learning_rate": 9.284311720188178e-05,
      "loss": 0.9643,
      "step": 3510
    },
    {
      "epoch": 7.198364008179959,
      "grad_norm": 4.314235210418701,
      "learning_rate": 9.282266312129271e-05,
      "loss": 1.0316,
      "step": 3520
    },
    {
      "epoch": 7.21881390593047,
      "grad_norm": 2.7941396236419678,
      "learning_rate": 9.280220904070362e-05,
      "loss": 0.9056,
      "step": 3530
    },
    {
      "epoch": 7.2392638036809815,
      "grad_norm": 2.8283793926239014,
      "learning_rate": 9.278175496011454e-05,
      "loss": 1.0369,
      "step": 3540
    },
    {
      "epoch": 7.259713701431493,
      "grad_norm": 2.4196178913116455,
      "learning_rate": 9.276130087952547e-05,
      "loss": 0.946,
      "step": 3550
    },
    {
      "epoch": 7.280163599182004,
      "grad_norm": 4.040920257568359,
      "learning_rate": 9.274084679893639e-05,
      "loss": 1.0082,
      "step": 3560
    },
    {
      "epoch": 7.300613496932515,
      "grad_norm": 3.8296799659729004,
      "learning_rate": 9.272039271834731e-05,
      "loss": 0.7902,
      "step": 3570
    },
    {
      "epoch": 7.321063394683026,
      "grad_norm": 3.1223673820495605,
      "learning_rate": 9.269993863775823e-05,
      "loss": 0.9962,
      "step": 3580
    },
    {
      "epoch": 7.341513292433538,
      "grad_norm": 2.679166316986084,
      "learning_rate": 9.267948455716915e-05,
      "loss": 0.9779,
      "step": 3590
    },
    {
      "epoch": 7.361963190184049,
      "grad_norm": 2.5206735134124756,
      "learning_rate": 9.265903047658008e-05,
      "loss": 1.0606,
      "step": 3600
    },
    {
      "epoch": 7.361963190184049,
      "eval_loss": 1.9679418802261353,
      "eval_runtime": 27.5248,
      "eval_samples_per_second": 11.699,
      "eval_steps_per_second": 0.981,
      "step": 3600
    },
    {
      "epoch": 7.382413087934561,
      "grad_norm": 2.9208929538726807,
      "learning_rate": 9.263857639599101e-05,
      "loss": 0.9497,
      "step": 3610
    },
    {
      "epoch": 7.402862985685071,
      "grad_norm": 2.9496874809265137,
      "learning_rate": 9.261812231540192e-05,
      "loss": 1.0774,
      "step": 3620
    },
    {
      "epoch": 7.423312883435583,
      "grad_norm": 3.509847402572632,
      "learning_rate": 9.259766823481286e-05,
      "loss": 1.1589,
      "step": 3630
    },
    {
      "epoch": 7.443762781186094,
      "grad_norm": 2.781527042388916,
      "learning_rate": 9.257721415422376e-05,
      "loss": 0.7509,
      "step": 3640
    },
    {
      "epoch": 7.4642126789366054,
      "grad_norm": 4.100546360015869,
      "learning_rate": 9.25567600736347e-05,
      "loss": 0.9813,
      "step": 3650
    },
    {
      "epoch": 7.484662576687117,
      "grad_norm": 5.035166263580322,
      "learning_rate": 9.253630599304561e-05,
      "loss": 1.0162,
      "step": 3660
    },
    {
      "epoch": 7.505112474437627,
      "grad_norm": 3.8369555473327637,
      "learning_rate": 9.251585191245654e-05,
      "loss": 0.9415,
      "step": 3670
    },
    {
      "epoch": 7.525562372188139,
      "grad_norm": 3.1892447471618652,
      "learning_rate": 9.249539783186745e-05,
      "loss": 0.9741,
      "step": 3680
    },
    {
      "epoch": 7.54601226993865,
      "grad_norm": 2.897432565689087,
      "learning_rate": 9.247494375127839e-05,
      "loss": 1.0329,
      "step": 3690
    },
    {
      "epoch": 7.566462167689162,
      "grad_norm": 2.5360283851623535,
      "learning_rate": 9.24544896706893e-05,
      "loss": 1.0514,
      "step": 3700
    },
    {
      "epoch": 7.566462167689162,
      "eval_loss": 1.9287089109420776,
      "eval_runtime": 27.5157,
      "eval_samples_per_second": 11.702,
      "eval_steps_per_second": 0.981,
      "step": 3700
    },
    {
      "epoch": 7.586912065439673,
      "grad_norm": 3.009718179702759,
      "learning_rate": 9.243403559010023e-05,
      "loss": 0.9005,
      "step": 3710
    },
    {
      "epoch": 7.6073619631901845,
      "grad_norm": 2.8000099658966064,
      "learning_rate": 9.241358150951116e-05,
      "loss": 0.9113,
      "step": 3720
    },
    {
      "epoch": 7.627811860940695,
      "grad_norm": 2.97067928314209,
      "learning_rate": 9.239312742892208e-05,
      "loss": 1.0364,
      "step": 3730
    },
    {
      "epoch": 7.6482617586912065,
      "grad_norm": 3.282792091369629,
      "learning_rate": 9.2372673348333e-05,
      "loss": 0.8973,
      "step": 3740
    },
    {
      "epoch": 7.668711656441718,
      "grad_norm": 2.7970120906829834,
      "learning_rate": 9.235221926774392e-05,
      "loss": 1.0955,
      "step": 3750
    },
    {
      "epoch": 7.689161554192229,
      "grad_norm": 3.8195595741271973,
      "learning_rate": 9.233176518715484e-05,
      "loss": 0.9067,
      "step": 3760
    },
    {
      "epoch": 7.70961145194274,
      "grad_norm": 2.8245253562927246,
      "learning_rate": 9.231131110656577e-05,
      "loss": 1.0203,
      "step": 3770
    },
    {
      "epoch": 7.730061349693251,
      "grad_norm": 3.2150473594665527,
      "learning_rate": 9.229085702597669e-05,
      "loss": 0.8974,
      "step": 3780
    },
    {
      "epoch": 7.750511247443763,
      "grad_norm": 2.483067750930786,
      "learning_rate": 9.227040294538761e-05,
      "loss": 0.9469,
      "step": 3790
    },
    {
      "epoch": 7.770961145194274,
      "grad_norm": 2.5411336421966553,
      "learning_rate": 9.224994886479853e-05,
      "loss": 1.0245,
      "step": 3800
    },
    {
      "epoch": 7.770961145194274,
      "eval_loss": 1.9241416454315186,
      "eval_runtime": 27.5172,
      "eval_samples_per_second": 11.702,
      "eval_steps_per_second": 0.981,
      "step": 3800
    },
    {
      "epoch": 7.791411042944786,
      "grad_norm": 3.1628217697143555,
      "learning_rate": 9.222949478420945e-05,
      "loss": 1.0012,
      "step": 3810
    },
    {
      "epoch": 7.811860940695297,
      "grad_norm": 3.1779861450195312,
      "learning_rate": 9.220904070362038e-05,
      "loss": 0.9757,
      "step": 3820
    },
    {
      "epoch": 7.8323108384458076,
      "grad_norm": 4.056654930114746,
      "learning_rate": 9.21885866230313e-05,
      "loss": 1.1148,
      "step": 3830
    },
    {
      "epoch": 7.852760736196319,
      "grad_norm": 3.481241464614868,
      "learning_rate": 9.216813254244222e-05,
      "loss": 0.8721,
      "step": 3840
    },
    {
      "epoch": 7.87321063394683,
      "grad_norm": 2.97277569770813,
      "learning_rate": 9.214767846185314e-05,
      "loss": 1.1729,
      "step": 3850
    },
    {
      "epoch": 7.893660531697342,
      "grad_norm": 2.6767690181732178,
      "learning_rate": 9.212722438126406e-05,
      "loss": 0.9058,
      "step": 3860
    },
    {
      "epoch": 7.914110429447852,
      "grad_norm": 2.4867348670959473,
      "learning_rate": 9.2106770300675e-05,
      "loss": 1.1221,
      "step": 3870
    },
    {
      "epoch": 7.934560327198364,
      "grad_norm": 4.5675764083862305,
      "learning_rate": 9.208631622008591e-05,
      "loss": 1.0346,
      "step": 3880
    },
    {
      "epoch": 7.955010224948875,
      "grad_norm": 2.4860987663269043,
      "learning_rate": 9.206586213949684e-05,
      "loss": 1.0002,
      "step": 3890
    },
    {
      "epoch": 7.975460122699387,
      "grad_norm": 4.330163955688477,
      "learning_rate": 9.204540805890775e-05,
      "loss": 0.9466,
      "step": 3900
    },
    {
      "epoch": 7.975460122699387,
      "eval_loss": 1.9313783645629883,
      "eval_runtime": 27.5262,
      "eval_samples_per_second": 11.698,
      "eval_steps_per_second": 0.981,
      "step": 3900
    },
    {
      "epoch": 7.995910020449898,
      "grad_norm": 2.184013605117798,
      "learning_rate": 9.202495397831869e-05,
      "loss": 1.0184,
      "step": 3910
    },
    {
      "epoch": 8.01635991820041,
      "grad_norm": 4.6298089027404785,
      "learning_rate": 9.20044998977296e-05,
      "loss": 0.7969,
      "step": 3920
    },
    {
      "epoch": 8.036809815950921,
      "grad_norm": 3.3087663650512695,
      "learning_rate": 9.198404581714053e-05,
      "loss": 0.9061,
      "step": 3930
    },
    {
      "epoch": 8.057259713701432,
      "grad_norm": 3.267426013946533,
      "learning_rate": 9.196359173655144e-05,
      "loss": 0.7973,
      "step": 3940
    },
    {
      "epoch": 8.077709611451942,
      "grad_norm": 2.9828341007232666,
      "learning_rate": 9.194313765596236e-05,
      "loss": 0.8851,
      "step": 3950
    },
    {
      "epoch": 8.098159509202453,
      "grad_norm": 3.116729974746704,
      "learning_rate": 9.192268357537329e-05,
      "loss": 0.7941,
      "step": 3960
    },
    {
      "epoch": 8.118609406952965,
      "grad_norm": 3.8203110694885254,
      "learning_rate": 9.190222949478421e-05,
      "loss": 0.8043,
      "step": 3970
    },
    {
      "epoch": 8.139059304703476,
      "grad_norm": 3.7952160835266113,
      "learning_rate": 9.188177541419514e-05,
      "loss": 0.8234,
      "step": 3980
    },
    {
      "epoch": 8.159509202453988,
      "grad_norm": 4.476889133453369,
      "learning_rate": 9.186132133360605e-05,
      "loss": 0.8453,
      "step": 3990
    },
    {
      "epoch": 8.1799591002045,
      "grad_norm": 2.596127986907959,
      "learning_rate": 9.184086725301699e-05,
      "loss": 0.7928,
      "step": 4000
    },
    {
      "epoch": 8.1799591002045,
      "eval_loss": 2.07397723197937,
      "eval_runtime": 27.5169,
      "eval_samples_per_second": 11.702,
      "eval_steps_per_second": 0.981,
      "step": 4000
    },
    {
      "epoch": 8.20040899795501,
      "grad_norm": 3.2499237060546875,
      "learning_rate": 9.18204131724279e-05,
      "loss": 1.0187,
      "step": 4010
    },
    {
      "epoch": 8.220858895705522,
      "grad_norm": 4.133335590362549,
      "learning_rate": 9.179995909183883e-05,
      "loss": 1.0662,
      "step": 4020
    },
    {
      "epoch": 8.241308793456033,
      "grad_norm": 2.7396063804626465,
      "learning_rate": 9.177950501124974e-05,
      "loss": 0.9208,
      "step": 4030
    },
    {
      "epoch": 8.261758691206545,
      "grad_norm": 2.779555559158325,
      "learning_rate": 9.175905093066068e-05,
      "loss": 0.9087,
      "step": 4040
    },
    {
      "epoch": 8.282208588957054,
      "grad_norm": 3.4177725315093994,
      "learning_rate": 9.173859685007159e-05,
      "loss": 0.7937,
      "step": 4050
    },
    {
      "epoch": 8.302658486707566,
      "grad_norm": 3.4303650856018066,
      "learning_rate": 9.171814276948252e-05,
      "loss": 0.8514,
      "step": 4060
    },
    {
      "epoch": 8.323108384458077,
      "grad_norm": 3.9766106605529785,
      "learning_rate": 9.169768868889343e-05,
      "loss": 0.8526,
      "step": 4070
    },
    {
      "epoch": 8.343558282208589,
      "grad_norm": 3.337857723236084,
      "learning_rate": 9.167723460830436e-05,
      "loss": 0.9265,
      "step": 4080
    },
    {
      "epoch": 8.3640081799591,
      "grad_norm": 2.6583237648010254,
      "learning_rate": 9.165678052771527e-05,
      "loss": 0.8722,
      "step": 4090
    },
    {
      "epoch": 8.384458077709612,
      "grad_norm": 3.955352783203125,
      "learning_rate": 9.163632644712621e-05,
      "loss": 0.7868,
      "step": 4100
    },
    {
      "epoch": 8.384458077709612,
      "eval_loss": 2.0333364009857178,
      "eval_runtime": 27.3297,
      "eval_samples_per_second": 11.782,
      "eval_steps_per_second": 0.988,
      "step": 4100
    },
    {
      "epoch": 8.404907975460123,
      "grad_norm": 3.89926815032959,
      "learning_rate": 9.161587236653713e-05,
      "loss": 1.0256,
      "step": 4110
    },
    {
      "epoch": 8.425357873210634,
      "grad_norm": 5.220179557800293,
      "learning_rate": 9.159541828594805e-05,
      "loss": 0.878,
      "step": 4120
    },
    {
      "epoch": 8.445807770961146,
      "grad_norm": 2.4732682704925537,
      "learning_rate": 9.157496420535898e-05,
      "loss": 0.8829,
      "step": 4130
    },
    {
      "epoch": 8.466257668711656,
      "grad_norm": 3.1997451782226562,
      "learning_rate": 9.15545101247699e-05,
      "loss": 0.876,
      "step": 4140
    },
    {
      "epoch": 8.486707566462167,
      "grad_norm": 2.493621349334717,
      "learning_rate": 9.153405604418082e-05,
      "loss": 0.8969,
      "step": 4150
    },
    {
      "epoch": 8.507157464212678,
      "grad_norm": 3.7437620162963867,
      "learning_rate": 9.151360196359174e-05,
      "loss": 0.7741,
      "step": 4160
    },
    {
      "epoch": 8.52760736196319,
      "grad_norm": 4.288058280944824,
      "learning_rate": 9.149519329106157e-05,
      "loss": 0.9735,
      "step": 4170
    },
    {
      "epoch": 8.548057259713701,
      "grad_norm": 3.1236796379089355,
      "learning_rate": 9.14747392104725e-05,
      "loss": 0.9129,
      "step": 4180
    },
    {
      "epoch": 8.568507157464213,
      "grad_norm": 3.9526774883270264,
      "learning_rate": 9.145428512988342e-05,
      "loss": 0.8265,
      "step": 4190
    },
    {
      "epoch": 8.588957055214724,
      "grad_norm": 3.4653542041778564,
      "learning_rate": 9.143383104929434e-05,
      "loss": 0.8505,
      "step": 4200
    },
    {
      "epoch": 8.588957055214724,
      "eval_loss": 2.053739547729492,
      "eval_runtime": 27.3476,
      "eval_samples_per_second": 11.774,
      "eval_steps_per_second": 0.987,
      "step": 4200
    },
    {
      "epoch": 8.609406952965236,
      "grad_norm": 2.8430581092834473,
      "learning_rate": 9.141337696870526e-05,
      "loss": 0.9465,
      "step": 4210
    },
    {
      "epoch": 8.629856850715747,
      "grad_norm": 4.028820991516113,
      "learning_rate": 9.139292288811618e-05,
      "loss": 0.8639,
      "step": 4220
    },
    {
      "epoch": 8.650306748466258,
      "grad_norm": 3.3068721294403076,
      "learning_rate": 9.13724688075271e-05,
      "loss": 0.7285,
      "step": 4230
    },
    {
      "epoch": 8.67075664621677,
      "grad_norm": 2.431584119796753,
      "learning_rate": 9.135201472693803e-05,
      "loss": 0.869,
      "step": 4240
    },
    {
      "epoch": 8.69120654396728,
      "grad_norm": 4.087920665740967,
      "learning_rate": 9.133156064634895e-05,
      "loss": 0.9097,
      "step": 4250
    },
    {
      "epoch": 8.71165644171779,
      "grad_norm": 3.1780121326446533,
      "learning_rate": 9.131110656575987e-05,
      "loss": 0.7335,
      "step": 4260
    },
    {
      "epoch": 8.732106339468302,
      "grad_norm": 3.58845853805542,
      "learning_rate": 9.12906524851708e-05,
      "loss": 1.0809,
      "step": 4270
    },
    {
      "epoch": 8.752556237218814,
      "grad_norm": 4.085184097290039,
      "learning_rate": 9.127019840458172e-05,
      "loss": 0.9267,
      "step": 4280
    },
    {
      "epoch": 8.773006134969325,
      "grad_norm": 4.307929515838623,
      "learning_rate": 9.124974432399264e-05,
      "loss": 0.9351,
      "step": 4290
    },
    {
      "epoch": 8.793456032719837,
      "grad_norm": 3.370156764984131,
      "learning_rate": 9.122929024340356e-05,
      "loss": 0.7694,
      "step": 4300
    },
    {
      "epoch": 8.793456032719837,
      "eval_loss": 2.0053868293762207,
      "eval_runtime": 27.6483,
      "eval_samples_per_second": 11.646,
      "eval_steps_per_second": 0.977,
      "step": 4300
    },
    {
      "epoch": 8.813905930470348,
      "grad_norm": 3.0405192375183105,
      "learning_rate": 9.120883616281448e-05,
      "loss": 0.9187,
      "step": 4310
    },
    {
      "epoch": 8.83435582822086,
      "grad_norm": 2.7648732662200928,
      "learning_rate": 9.11883820822254e-05,
      "loss": 0.9275,
      "step": 4320
    },
    {
      "epoch": 8.85480572597137,
      "grad_norm": 3.314617872238159,
      "learning_rate": 9.116792800163633e-05,
      "loss": 0.9513,
      "step": 4330
    },
    {
      "epoch": 8.87525562372188,
      "grad_norm": 2.779212713241577,
      "learning_rate": 9.114747392104725e-05,
      "loss": 0.9177,
      "step": 4340
    },
    {
      "epoch": 8.895705521472392,
      "grad_norm": 4.74857759475708,
      "learning_rate": 9.112701984045817e-05,
      "loss": 0.8938,
      "step": 4350
    },
    {
      "epoch": 8.916155419222903,
      "grad_norm": 4.933828830718994,
      "learning_rate": 9.110656575986911e-05,
      "loss": 0.91,
      "step": 4360
    },
    {
      "epoch": 8.936605316973415,
      "grad_norm": 4.772159576416016,
      "learning_rate": 9.108611167928002e-05,
      "loss": 0.7282,
      "step": 4370
    },
    {
      "epoch": 8.957055214723926,
      "grad_norm": 2.7324886322021484,
      "learning_rate": 9.106565759869095e-05,
      "loss": 0.8147,
      "step": 4380
    },
    {
      "epoch": 8.977505112474438,
      "grad_norm": 2.950650930404663,
      "learning_rate": 9.104520351810186e-05,
      "loss": 0.9377,
      "step": 4390
    },
    {
      "epoch": 8.997955010224949,
      "grad_norm": 2.5407474040985107,
      "learning_rate": 9.10247494375128e-05,
      "loss": 0.925,
      "step": 4400
    },
    {
      "epoch": 8.997955010224949,
      "eval_loss": 2.0197219848632812,
      "eval_runtime": 27.4059,
      "eval_samples_per_second": 11.749,
      "eval_steps_per_second": 0.985,
      "step": 4400
    },
    {
      "epoch": 9.01840490797546,
      "grad_norm": 3.6624042987823486,
      "learning_rate": 9.10042953569237e-05,
      "loss": 0.7881,
      "step": 4410
    },
    {
      "epoch": 9.038854805725972,
      "grad_norm": 3.0722320079803467,
      "learning_rate": 9.098384127633464e-05,
      "loss": 0.6571,
      "step": 4420
    },
    {
      "epoch": 9.059304703476483,
      "grad_norm": 3.1869289875030518,
      "learning_rate": 9.096338719574555e-05,
      "loss": 0.7661,
      "step": 4430
    },
    {
      "epoch": 9.079754601226995,
      "grad_norm": 2.311676502227783,
      "learning_rate": 9.094293311515648e-05,
      "loss": 0.7231,
      "step": 4440
    },
    {
      "epoch": 9.100204498977504,
      "grad_norm": 4.233432769775391,
      "learning_rate": 9.092247903456739e-05,
      "loss": 0.7273,
      "step": 4450
    },
    {
      "epoch": 9.120654396728016,
      "grad_norm": 2.6292335987091064,
      "learning_rate": 9.090202495397833e-05,
      "loss": 0.8011,
      "step": 4460
    },
    {
      "epoch": 9.141104294478527,
      "grad_norm": 3.8165924549102783,
      "learning_rate": 9.088157087338925e-05,
      "loss": 0.7775,
      "step": 4470
    },
    {
      "epoch": 9.161554192229039,
      "grad_norm": 4.7927422523498535,
      "learning_rate": 9.086111679280017e-05,
      "loss": 0.8148,
      "step": 4480
    },
    {
      "epoch": 9.18200408997955,
      "grad_norm": 3.0389976501464844,
      "learning_rate": 9.08406627122111e-05,
      "loss": 0.848,
      "step": 4490
    },
    {
      "epoch": 9.202453987730062,
      "grad_norm": 3.321962594985962,
      "learning_rate": 9.082020863162202e-05,
      "loss": 0.7156,
      "step": 4500
    },
    {
      "epoch": 9.202453987730062,
      "eval_loss": 2.2169253826141357,
      "eval_runtime": 27.321,
      "eval_samples_per_second": 11.786,
      "eval_steps_per_second": 0.988,
      "step": 4500
    },
    {
      "epoch": 9.222903885480573,
      "grad_norm": 3.579576253890991,
      "learning_rate": 9.079975455103294e-05,
      "loss": 0.7421,
      "step": 4510
    },
    {
      "epoch": 9.243353783231084,
      "grad_norm": 3.4037275314331055,
      "learning_rate": 9.077930047044386e-05,
      "loss": 0.7582,
      "step": 4520
    },
    {
      "epoch": 9.263803680981596,
      "grad_norm": 3.630493402481079,
      "learning_rate": 9.075884638985478e-05,
      "loss": 0.6534,
      "step": 4530
    },
    {
      "epoch": 9.284253578732105,
      "grad_norm": 5.081292629241943,
      "learning_rate": 9.07383923092657e-05,
      "loss": 0.7689,
      "step": 4540
    },
    {
      "epoch": 9.304703476482617,
      "grad_norm": 2.5003201961517334,
      "learning_rate": 9.071793822867663e-05,
      "loss": 0.8244,
      "step": 4550
    },
    {
      "epoch": 9.325153374233128,
      "grad_norm": 2.861419677734375,
      "learning_rate": 9.069748414808755e-05,
      "loss": 0.8027,
      "step": 4560
    },
    {
      "epoch": 9.34560327198364,
      "grad_norm": 4.162790775299072,
      "learning_rate": 9.067703006749847e-05,
      "loss": 0.9255,
      "step": 4570
    },
    {
      "epoch": 9.366053169734151,
      "grad_norm": 3.5062708854675293,
      "learning_rate": 9.06565759869094e-05,
      "loss": 0.6319,
      "step": 4580
    },
    {
      "epoch": 9.386503067484663,
      "grad_norm": 3.694518804550171,
      "learning_rate": 9.063612190632032e-05,
      "loss": 0.7675,
      "step": 4590
    },
    {
      "epoch": 9.406952965235174,
      "grad_norm": 3.094169855117798,
      "learning_rate": 9.061566782573124e-05,
      "loss": 0.8452,
      "step": 4600
    },
    {
      "epoch": 9.406952965235174,
      "eval_loss": 2.1387836933135986,
      "eval_runtime": 27.5272,
      "eval_samples_per_second": 11.698,
      "eval_steps_per_second": 0.981,
      "step": 4600
    },
    {
      "epoch": 9.427402862985685,
      "grad_norm": 3.281146764755249,
      "learning_rate": 9.059521374514216e-05,
      "loss": 0.7161,
      "step": 4610
    },
    {
      "epoch": 9.447852760736197,
      "grad_norm": 3.002322196960449,
      "learning_rate": 9.057475966455308e-05,
      "loss": 0.865,
      "step": 4620
    },
    {
      "epoch": 9.468302658486708,
      "grad_norm": 3.4159514904022217,
      "learning_rate": 9.0554305583964e-05,
      "loss": 0.7657,
      "step": 4630
    },
    {
      "epoch": 9.48875255623722,
      "grad_norm": 3.098200559616089,
      "learning_rate": 9.053385150337493e-05,
      "loss": 0.6945,
      "step": 4640
    },
    {
      "epoch": 9.50920245398773,
      "grad_norm": 4.375757217407227,
      "learning_rate": 9.051339742278585e-05,
      "loss": 0.7248,
      "step": 4650
    },
    {
      "epoch": 9.52965235173824,
      "grad_norm": 2.5807032585144043,
      "learning_rate": 9.049294334219677e-05,
      "loss": 0.883,
      "step": 4660
    },
    {
      "epoch": 9.550102249488752,
      "grad_norm": 4.263159275054932,
      "learning_rate": 9.047248926160769e-05,
      "loss": 0.863,
      "step": 4670
    },
    {
      "epoch": 9.570552147239264,
      "grad_norm": 3.0344693660736084,
      "learning_rate": 9.045203518101861e-05,
      "loss": 0.7435,
      "step": 4680
    },
    {
      "epoch": 9.591002044989775,
      "grad_norm": 2.709913730621338,
      "learning_rate": 9.043158110042954e-05,
      "loss": 0.7177,
      "step": 4690
    },
    {
      "epoch": 9.611451942740286,
      "grad_norm": 2.8909711837768555,
      "learning_rate": 9.041112701984046e-05,
      "loss": 0.7182,
      "step": 4700
    },
    {
      "epoch": 9.611451942740286,
      "eval_loss": 2.1204659938812256,
      "eval_runtime": 27.5275,
      "eval_samples_per_second": 11.697,
      "eval_steps_per_second": 0.981,
      "step": 4700
    },
    {
      "epoch": 9.631901840490798,
      "grad_norm": 3.2916219234466553,
      "learning_rate": 9.039067293925138e-05,
      "loss": 0.8886,
      "step": 4710
    },
    {
      "epoch": 9.65235173824131,
      "grad_norm": 2.649275779724121,
      "learning_rate": 9.03702188586623e-05,
      "loss": 0.7343,
      "step": 4720
    },
    {
      "epoch": 9.67280163599182,
      "grad_norm": 5.789233207702637,
      "learning_rate": 9.034976477807323e-05,
      "loss": 0.7571,
      "step": 4730
    },
    {
      "epoch": 9.69325153374233,
      "grad_norm": 3.020568609237671,
      "learning_rate": 9.032931069748415e-05,
      "loss": 0.7105,
      "step": 4740
    },
    {
      "epoch": 9.713701431492842,
      "grad_norm": 3.625537157058716,
      "learning_rate": 9.030885661689508e-05,
      "loss": 0.786,
      "step": 4750
    },
    {
      "epoch": 9.734151329243353,
      "grad_norm": 2.842298984527588,
      "learning_rate": 9.028840253630599e-05,
      "loss": 0.7567,
      "step": 4760
    },
    {
      "epoch": 9.754601226993865,
      "grad_norm": 3.3278512954711914,
      "learning_rate": 9.026794845571693e-05,
      "loss": 0.8472,
      "step": 4770
    },
    {
      "epoch": 9.775051124744376,
      "grad_norm": 3.383638381958008,
      "learning_rate": 9.024749437512784e-05,
      "loss": 0.7115,
      "step": 4780
    },
    {
      "epoch": 9.795501022494888,
      "grad_norm": 3.9272003173828125,
      "learning_rate": 9.022704029453877e-05,
      "loss": 0.7276,
      "step": 4790
    },
    {
      "epoch": 9.815950920245399,
      "grad_norm": 3.4468929767608643,
      "learning_rate": 9.020658621394968e-05,
      "loss": 0.7536,
      "step": 4800
    },
    {
      "epoch": 9.815950920245399,
      "eval_loss": 2.1169192790985107,
      "eval_runtime": 27.3992,
      "eval_samples_per_second": 11.752,
      "eval_steps_per_second": 0.985,
      "step": 4800
    },
    {
      "epoch": 9.83640081799591,
      "grad_norm": 4.952263355255127,
      "learning_rate": 9.018613213336062e-05,
      "loss": 0.9346,
      "step": 4810
    },
    {
      "epoch": 9.856850715746422,
      "grad_norm": 3.4951083660125732,
      "learning_rate": 9.016567805277152e-05,
      "loss": 0.7864,
      "step": 4820
    },
    {
      "epoch": 9.877300613496933,
      "grad_norm": 4.881157875061035,
      "learning_rate": 9.014522397218246e-05,
      "loss": 0.7616,
      "step": 4830
    },
    {
      "epoch": 9.897750511247445,
      "grad_norm": 3.8890745639801025,
      "learning_rate": 9.012476989159337e-05,
      "loss": 0.6543,
      "step": 4840
    },
    {
      "epoch": 9.918200408997954,
      "grad_norm": 3.1551573276519775,
      "learning_rate": 9.01043158110043e-05,
      "loss": 0.7709,
      "step": 4850
    },
    {
      "epoch": 9.938650306748466,
      "grad_norm": 3.9983179569244385,
      "learning_rate": 9.008386173041523e-05,
      "loss": 0.8423,
      "step": 4860
    },
    {
      "epoch": 9.959100204498977,
      "grad_norm": 3.4670562744140625,
      "learning_rate": 9.006340764982615e-05,
      "loss": 0.8594,
      "step": 4870
    },
    {
      "epoch": 9.979550102249489,
      "grad_norm": 4.6879987716674805,
      "learning_rate": 9.004295356923707e-05,
      "loss": 0.782,
      "step": 4880
    },
    {
      "epoch": 10.0,
      "grad_norm": 11.831233978271484,
      "learning_rate": 9.002249948864799e-05,
      "loss": 0.8493,
      "step": 4890
    },
    {
      "epoch": 10.020449897750511,
      "grad_norm": 2.4931156635284424,
      "learning_rate": 9.000204540805891e-05,
      "loss": 0.7255,
      "step": 4900
    },
    {
      "epoch": 10.020449897750511,
      "eval_loss": 2.290515661239624,
      "eval_runtime": 27.4006,
      "eval_samples_per_second": 11.752,
      "eval_steps_per_second": 0.985,
      "step": 4900
    },
    {
      "epoch": 10.040899795501023,
      "grad_norm": 2.918783664703369,
      "learning_rate": 8.998159132746984e-05,
      "loss": 0.6115,
      "step": 4910
    },
    {
      "epoch": 10.061349693251534,
      "grad_norm": 4.598121643066406,
      "learning_rate": 8.996113724688076e-05,
      "loss": 0.6875,
      "step": 4920
    },
    {
      "epoch": 10.081799591002046,
      "grad_norm": 2.8163046836853027,
      "learning_rate": 8.994068316629168e-05,
      "loss": 0.5758,
      "step": 4930
    },
    {
      "epoch": 10.102249488752555,
      "grad_norm": 2.360400438308716,
      "learning_rate": 8.99202290857026e-05,
      "loss": 0.6174,
      "step": 4940
    },
    {
      "epoch": 10.122699386503067,
      "grad_norm": 2.600757122039795,
      "learning_rate": 8.989977500511353e-05,
      "loss": 0.5485,
      "step": 4950
    },
    {
      "epoch": 10.143149284253578,
      "grad_norm": 3.7921700477600098,
      "learning_rate": 8.987932092452445e-05,
      "loss": 0.6081,
      "step": 4960
    },
    {
      "epoch": 10.16359918200409,
      "grad_norm": 5.356991291046143,
      "learning_rate": 8.985886684393537e-05,
      "loss": 0.6914,
      "step": 4970
    },
    {
      "epoch": 10.184049079754601,
      "grad_norm": 3.369351625442505,
      "learning_rate": 8.983841276334629e-05,
      "loss": 0.6436,
      "step": 4980
    },
    {
      "epoch": 10.204498977505112,
      "grad_norm": 4.107081890106201,
      "learning_rate": 8.981795868275721e-05,
      "loss": 0.7956,
      "step": 4990
    },
    {
      "epoch": 10.224948875255624,
      "grad_norm": 3.480116605758667,
      "learning_rate": 8.979750460216814e-05,
      "loss": 0.7619,
      "step": 5000
    },
    {
      "epoch": 10.224948875255624,
      "eval_loss": 2.2748138904571533,
      "eval_runtime": 27.3466,
      "eval_samples_per_second": 11.775,
      "eval_steps_per_second": 0.987,
      "step": 5000
    },
    {
      "epoch": 10.245398773006135,
      "grad_norm": 2.8752188682556152,
      "learning_rate": 8.977705052157906e-05,
      "loss": 0.6871,
      "step": 5010
    },
    {
      "epoch": 10.265848670756647,
      "grad_norm": 4.150045394897461,
      "learning_rate": 8.975659644098998e-05,
      "loss": 0.7245,
      "step": 5020
    },
    {
      "epoch": 10.286298568507158,
      "grad_norm": 2.964797019958496,
      "learning_rate": 8.97361423604009e-05,
      "loss": 0.6726,
      "step": 5030
    },
    {
      "epoch": 10.30674846625767,
      "grad_norm": 3.42268443107605,
      "learning_rate": 8.971568827981182e-05,
      "loss": 0.6949,
      "step": 5040
    },
    {
      "epoch": 10.32719836400818,
      "grad_norm": 3.015550136566162,
      "learning_rate": 8.969523419922275e-05,
      "loss": 0.6458,
      "step": 5050
    },
    {
      "epoch": 10.34764826175869,
      "grad_norm": 4.174319267272949,
      "learning_rate": 8.967478011863367e-05,
      "loss": 0.6728,
      "step": 5060
    },
    {
      "epoch": 10.368098159509202,
      "grad_norm": 3.4199023246765137,
      "learning_rate": 8.965432603804459e-05,
      "loss": 0.6254,
      "step": 5070
    },
    {
      "epoch": 10.388548057259714,
      "grad_norm": 3.5062601566314697,
      "learning_rate": 8.963387195745551e-05,
      "loss": 0.6316,
      "step": 5080
    },
    {
      "epoch": 10.408997955010225,
      "grad_norm": 3.408902406692505,
      "learning_rate": 8.961341787686644e-05,
      "loss": 0.6527,
      "step": 5090
    },
    {
      "epoch": 10.429447852760736,
      "grad_norm": 2.633439540863037,
      "learning_rate": 8.959296379627736e-05,
      "loss": 0.7164,
      "step": 5100
    },
    {
      "epoch": 10.429447852760736,
      "eval_loss": 2.241420030593872,
      "eval_runtime": 27.2939,
      "eval_samples_per_second": 11.798,
      "eval_steps_per_second": 0.989,
      "step": 5100
    },
    {
      "epoch": 10.449897750511248,
      "grad_norm": 4.773955345153809,
      "learning_rate": 8.957250971568828e-05,
      "loss": 0.6326,
      "step": 5110
    },
    {
      "epoch": 10.47034764826176,
      "grad_norm": 3.324775457382202,
      "learning_rate": 8.95520556350992e-05,
      "loss": 0.7166,
      "step": 5120
    },
    {
      "epoch": 10.49079754601227,
      "grad_norm": 3.7117037773132324,
      "learning_rate": 8.953160155451012e-05,
      "loss": 0.7739,
      "step": 5130
    },
    {
      "epoch": 10.51124744376278,
      "grad_norm": 5.235572338104248,
      "learning_rate": 8.951114747392106e-05,
      "loss": 0.7573,
      "step": 5140
    },
    {
      "epoch": 10.531697341513292,
      "grad_norm": 3.3823370933532715,
      "learning_rate": 8.949069339333197e-05,
      "loss": 0.685,
      "step": 5150
    },
    {
      "epoch": 10.552147239263803,
      "grad_norm": 4.025106430053711,
      "learning_rate": 8.94702393127429e-05,
      "loss": 0.7033,
      "step": 5160
    },
    {
      "epoch": 10.572597137014315,
      "grad_norm": 4.661429405212402,
      "learning_rate": 8.944978523215381e-05,
      "loss": 0.7198,
      "step": 5170
    },
    {
      "epoch": 10.593047034764826,
      "grad_norm": 2.6778042316436768,
      "learning_rate": 8.942933115156475e-05,
      "loss": 0.7478,
      "step": 5180
    },
    {
      "epoch": 10.613496932515337,
      "grad_norm": 3.222288131713867,
      "learning_rate": 8.940887707097566e-05,
      "loss": 0.6775,
      "step": 5190
    },
    {
      "epoch": 10.633946830265849,
      "grad_norm": 2.6820857524871826,
      "learning_rate": 8.938842299038659e-05,
      "loss": 0.596,
      "step": 5200
    },
    {
      "epoch": 10.633946830265849,
      "eval_loss": 2.2575113773345947,
      "eval_runtime": 27.2875,
      "eval_samples_per_second": 11.8,
      "eval_steps_per_second": 0.989,
      "step": 5200
    },
    {
      "epoch": 10.65439672801636,
      "grad_norm": 3.574357748031616,
      "learning_rate": 8.93679689097975e-05,
      "loss": 0.7054,
      "step": 5210
    },
    {
      "epoch": 10.674846625766872,
      "grad_norm": 3.2875068187713623,
      "learning_rate": 8.934751482920844e-05,
      "loss": 0.662,
      "step": 5220
    },
    {
      "epoch": 10.695296523517383,
      "grad_norm": 2.947950839996338,
      "learning_rate": 8.932706074861934e-05,
      "loss": 0.871,
      "step": 5230
    },
    {
      "epoch": 10.715746421267895,
      "grad_norm": 4.326605796813965,
      "learning_rate": 8.930660666803028e-05,
      "loss": 0.7437,
      "step": 5240
    },
    {
      "epoch": 10.736196319018404,
      "grad_norm": 2.8684942722320557,
      "learning_rate": 8.92861525874412e-05,
      "loss": 0.7631,
      "step": 5250
    },
    {
      "epoch": 10.756646216768916,
      "grad_norm": 2.9064061641693115,
      "learning_rate": 8.926569850685212e-05,
      "loss": 0.574,
      "step": 5260
    },
    {
      "epoch": 10.777096114519427,
      "grad_norm": 4.577054977416992,
      "learning_rate": 8.924524442626305e-05,
      "loss": 0.7748,
      "step": 5270
    },
    {
      "epoch": 10.797546012269938,
      "grad_norm": 4.087352275848389,
      "learning_rate": 8.922479034567397e-05,
      "loss": 0.7267,
      "step": 5280
    },
    {
      "epoch": 10.81799591002045,
      "grad_norm": 2.744279623031616,
      "learning_rate": 8.920433626508489e-05,
      "loss": 0.7391,
      "step": 5290
    },
    {
      "epoch": 10.838445807770961,
      "grad_norm": 3.226713180541992,
      "learning_rate": 8.918388218449581e-05,
      "loss": 0.6712,
      "step": 5300
    },
    {
      "epoch": 10.838445807770961,
      "eval_loss": 2.2210867404937744,
      "eval_runtime": 27.3117,
      "eval_samples_per_second": 11.79,
      "eval_steps_per_second": 0.989,
      "step": 5300
    },
    {
      "epoch": 10.858895705521473,
      "grad_norm": 2.8538739681243896,
      "learning_rate": 8.916342810390674e-05,
      "loss": 0.5894,
      "step": 5310
    },
    {
      "epoch": 10.879345603271984,
      "grad_norm": 3.1129262447357178,
      "learning_rate": 8.914297402331766e-05,
      "loss": 0.5852,
      "step": 5320
    },
    {
      "epoch": 10.899795501022496,
      "grad_norm": 4.97841739654541,
      "learning_rate": 8.912251994272858e-05,
      "loss": 0.6485,
      "step": 5330
    },
    {
      "epoch": 10.920245398773005,
      "grad_norm": 3.5887134075164795,
      "learning_rate": 8.91020658621395e-05,
      "loss": 0.6143,
      "step": 5340
    },
    {
      "epoch": 10.940695296523517,
      "grad_norm": 3.064281702041626,
      "learning_rate": 8.908161178155042e-05,
      "loss": 0.759,
      "step": 5350
    },
    {
      "epoch": 10.961145194274028,
      "grad_norm": 3.9682717323303223,
      "learning_rate": 8.906115770096135e-05,
      "loss": 0.6995,
      "step": 5360
    },
    {
      "epoch": 10.98159509202454,
      "grad_norm": 2.8186652660369873,
      "learning_rate": 8.904070362037227e-05,
      "loss": 0.6894,
      "step": 5370
    },
    {
      "epoch": 11.002044989775051,
      "grad_norm": 2.1624133586883545,
      "learning_rate": 8.902024953978319e-05,
      "loss": 0.706,
      "step": 5380
    },
    {
      "epoch": 11.022494887525562,
      "grad_norm": 4.194616794586182,
      "learning_rate": 8.899979545919411e-05,
      "loss": 0.5356,
      "step": 5390
    },
    {
      "epoch": 11.042944785276074,
      "grad_norm": 2.6072731018066406,
      "learning_rate": 8.897934137860505e-05,
      "loss": 0.5684,
      "step": 5400
    },
    {
      "epoch": 11.042944785276074,
      "eval_loss": 2.347569704055786,
      "eval_runtime": 27.2851,
      "eval_samples_per_second": 11.801,
      "eval_steps_per_second": 0.99,
      "step": 5400
    },
    {
      "epoch": 11.063394683026585,
      "grad_norm": 3.1940932273864746,
      "learning_rate": 8.895888729801596e-05,
      "loss": 0.5513,
      "step": 5410
    },
    {
      "epoch": 11.083844580777097,
      "grad_norm": 4.016446113586426,
      "learning_rate": 8.893843321742689e-05,
      "loss": 0.5013,
      "step": 5420
    },
    {
      "epoch": 11.104294478527608,
      "grad_norm": 3.568075180053711,
      "learning_rate": 8.89179791368378e-05,
      "loss": 0.5939,
      "step": 5430
    },
    {
      "epoch": 11.124744376278118,
      "grad_norm": 2.6759965419769287,
      "learning_rate": 8.889752505624872e-05,
      "loss": 0.6015,
      "step": 5440
    },
    {
      "epoch": 11.14519427402863,
      "grad_norm": 4.796261310577393,
      "learning_rate": 8.887707097565964e-05,
      "loss": 0.6726,
      "step": 5450
    },
    {
      "epoch": 11.16564417177914,
      "grad_norm": 4.261343002319336,
      "learning_rate": 8.885661689507057e-05,
      "loss": 0.6062,
      "step": 5460
    },
    {
      "epoch": 11.186094069529652,
      "grad_norm": 3.012535572052002,
      "learning_rate": 8.883616281448149e-05,
      "loss": 0.6269,
      "step": 5470
    },
    {
      "epoch": 11.206543967280163,
      "grad_norm": 3.979335308074951,
      "learning_rate": 8.881570873389241e-05,
      "loss": 0.6553,
      "step": 5480
    },
    {
      "epoch": 11.226993865030675,
      "grad_norm": 3.560178756713867,
      "learning_rate": 8.879525465330333e-05,
      "loss": 0.6105,
      "step": 5490
    },
    {
      "epoch": 11.247443762781186,
      "grad_norm": 4.1801958084106445,
      "learning_rate": 8.877480057271426e-05,
      "loss": 0.612,
      "step": 5500
    },
    {
      "epoch": 11.247443762781186,
      "eval_loss": 2.4665610790252686,
      "eval_runtime": 27.3396,
      "eval_samples_per_second": 11.778,
      "eval_steps_per_second": 0.988,
      "step": 5500
    },
    {
      "epoch": 11.267893660531698,
      "grad_norm": 6.419643878936768,
      "learning_rate": 8.875434649212519e-05,
      "loss": 0.5242,
      "step": 5510
    },
    {
      "epoch": 11.28834355828221,
      "grad_norm": 3.100745677947998,
      "learning_rate": 8.87338924115361e-05,
      "loss": 0.6429,
      "step": 5520
    },
    {
      "epoch": 11.30879345603272,
      "grad_norm": 3.9422950744628906,
      "learning_rate": 8.871343833094704e-05,
      "loss": 0.7364,
      "step": 5530
    },
    {
      "epoch": 11.32924335378323,
      "grad_norm": 5.0084733963012695,
      "learning_rate": 8.869298425035794e-05,
      "loss": 0.5945,
      "step": 5540
    },
    {
      "epoch": 11.349693251533742,
      "grad_norm": 3.922466278076172,
      "learning_rate": 8.867253016976888e-05,
      "loss": 0.4758,
      "step": 5550
    },
    {
      "epoch": 11.370143149284253,
      "grad_norm": 3.0843329429626465,
      "learning_rate": 8.865207608917979e-05,
      "loss": 0.639,
      "step": 5560
    },
    {
      "epoch": 11.390593047034764,
      "grad_norm": 3.2641866207122803,
      "learning_rate": 8.863162200859072e-05,
      "loss": 0.6064,
      "step": 5570
    },
    {
      "epoch": 11.411042944785276,
      "grad_norm": 3.959820508956909,
      "learning_rate": 8.861116792800163e-05,
      "loss": 0.6345,
      "step": 5580
    },
    {
      "epoch": 11.431492842535787,
      "grad_norm": 4.805384159088135,
      "learning_rate": 8.859071384741257e-05,
      "loss": 0.6545,
      "step": 5590
    },
    {
      "epoch": 11.451942740286299,
      "grad_norm": 3.326512575149536,
      "learning_rate": 8.857025976682348e-05,
      "loss": 0.582,
      "step": 5600
    },
    {
      "epoch": 11.451942740286299,
      "eval_loss": 2.38735032081604,
      "eval_runtime": 27.3016,
      "eval_samples_per_second": 11.794,
      "eval_steps_per_second": 0.989,
      "step": 5600
    },
    {
      "epoch": 11.47239263803681,
      "grad_norm": 4.56752872467041,
      "learning_rate": 8.854980568623441e-05,
      "loss": 0.6135,
      "step": 5610
    },
    {
      "epoch": 11.492842535787322,
      "grad_norm": 3.887824296951294,
      "learning_rate": 8.852935160564532e-05,
      "loss": 0.7102,
      "step": 5620
    },
    {
      "epoch": 11.513292433537833,
      "grad_norm": 3.4547312259674072,
      "learning_rate": 8.850889752505626e-05,
      "loss": 0.5074,
      "step": 5630
    },
    {
      "epoch": 11.533742331288344,
      "grad_norm": 3.1280252933502197,
      "learning_rate": 8.848844344446718e-05,
      "loss": 0.5584,
      "step": 5640
    },
    {
      "epoch": 11.554192229038854,
      "grad_norm": 4.4461283683776855,
      "learning_rate": 8.84679893638781e-05,
      "loss": 0.666,
      "step": 5650
    },
    {
      "epoch": 11.574642126789366,
      "grad_norm": 2.489163398742676,
      "learning_rate": 8.844753528328902e-05,
      "loss": 0.6517,
      "step": 5660
    },
    {
      "epoch": 11.595092024539877,
      "grad_norm": 3.5499422550201416,
      "learning_rate": 8.842708120269994e-05,
      "loss": 0.6092,
      "step": 5670
    },
    {
      "epoch": 11.615541922290388,
      "grad_norm": 2.904984951019287,
      "learning_rate": 8.840662712211087e-05,
      "loss": 0.4972,
      "step": 5680
    },
    {
      "epoch": 11.6359918200409,
      "grad_norm": 3.361239433288574,
      "learning_rate": 8.838617304152179e-05,
      "loss": 0.6352,
      "step": 5690
    },
    {
      "epoch": 11.656441717791411,
      "grad_norm": 3.797717809677124,
      "learning_rate": 8.836571896093271e-05,
      "loss": 0.6218,
      "step": 5700
    },
    {
      "epoch": 11.656441717791411,
      "eval_loss": 2.371079921722412,
      "eval_runtime": 27.356,
      "eval_samples_per_second": 11.771,
      "eval_steps_per_second": 0.987,
      "step": 5700
    },
    {
      "epoch": 11.676891615541923,
      "grad_norm": 3.5297412872314453,
      "learning_rate": 8.834526488034363e-05,
      "loss": 0.5919,
      "step": 5710
    },
    {
      "epoch": 11.697341513292434,
      "grad_norm": 4.90101957321167,
      "learning_rate": 8.832481079975456e-05,
      "loss": 0.6159,
      "step": 5720
    },
    {
      "epoch": 11.717791411042946,
      "grad_norm": 3.9625415802001953,
      "learning_rate": 8.830435671916548e-05,
      "loss": 0.5664,
      "step": 5730
    },
    {
      "epoch": 11.738241308793455,
      "grad_norm": 5.029921531677246,
      "learning_rate": 8.82839026385764e-05,
      "loss": 0.645,
      "step": 5740
    },
    {
      "epoch": 11.758691206543967,
      "grad_norm": 3.291147232055664,
      "learning_rate": 8.826344855798732e-05,
      "loss": 0.6299,
      "step": 5750
    },
    {
      "epoch": 11.779141104294478,
      "grad_norm": 3.4588165283203125,
      "learning_rate": 8.824299447739824e-05,
      "loss": 0.6373,
      "step": 5760
    },
    {
      "epoch": 11.79959100204499,
      "grad_norm": 4.586079120635986,
      "learning_rate": 8.822254039680917e-05,
      "loss": 0.5362,
      "step": 5770
    },
    {
      "epoch": 11.8200408997955,
      "grad_norm": 4.945774555206299,
      "learning_rate": 8.820208631622009e-05,
      "loss": 0.5667,
      "step": 5780
    },
    {
      "epoch": 11.840490797546012,
      "grad_norm": 3.6933863162994385,
      "learning_rate": 8.818163223563102e-05,
      "loss": 0.6775,
      "step": 5790
    },
    {
      "epoch": 11.860940695296524,
      "grad_norm": 4.245481491088867,
      "learning_rate": 8.816117815504193e-05,
      "loss": 0.6037,
      "step": 5800
    },
    {
      "epoch": 11.860940695296524,
      "eval_loss": 2.3420207500457764,
      "eval_runtime": 27.4021,
      "eval_samples_per_second": 11.751,
      "eval_steps_per_second": 0.985,
      "step": 5800
    },
    {
      "epoch": 11.881390593047035,
      "grad_norm": 5.9371256828308105,
      "learning_rate": 8.814072407445287e-05,
      "loss": 0.7326,
      "step": 5810
    },
    {
      "epoch": 11.901840490797547,
      "grad_norm": 5.160583019256592,
      "learning_rate": 8.812026999386378e-05,
      "loss": 0.5844,
      "step": 5820
    },
    {
      "epoch": 11.922290388548058,
      "grad_norm": 2.9625298976898193,
      "learning_rate": 8.809981591327471e-05,
      "loss": 0.6236,
      "step": 5830
    },
    {
      "epoch": 11.94274028629857,
      "grad_norm": 3.962254285812378,
      "learning_rate": 8.807936183268562e-05,
      "loss": 0.7353,
      "step": 5840
    },
    {
      "epoch": 11.963190184049079,
      "grad_norm": 3.7103025913238525,
      "learning_rate": 8.805890775209654e-05,
      "loss": 0.6767,
      "step": 5850
    },
    {
      "epoch": 11.98364008179959,
      "grad_norm": 4.123032569885254,
      "learning_rate": 8.803845367150747e-05,
      "loss": 0.6596,
      "step": 5860
    },
    {
      "epoch": 12.004089979550102,
      "grad_norm": 3.085202932357788,
      "learning_rate": 8.801799959091839e-05,
      "loss": 0.5569,
      "step": 5870
    },
    {
      "epoch": 12.024539877300613,
      "grad_norm": 4.58689022064209,
      "learning_rate": 8.799754551032931e-05,
      "loss": 0.5011,
      "step": 5880
    },
    {
      "epoch": 12.044989775051125,
      "grad_norm": 3.950169801712036,
      "learning_rate": 8.797709142974023e-05,
      "loss": 0.5294,
      "step": 5890
    },
    {
      "epoch": 12.065439672801636,
      "grad_norm": 4.053771018981934,
      "learning_rate": 8.795663734915117e-05,
      "loss": 0.5493,
      "step": 5900
    },
    {
      "epoch": 12.065439672801636,
      "eval_loss": 2.539915084838867,
      "eval_runtime": 27.2249,
      "eval_samples_per_second": 11.827,
      "eval_steps_per_second": 0.992,
      "step": 5900
    },
    {
      "epoch": 12.085889570552148,
      "grad_norm": 3.2971370220184326,
      "learning_rate": 8.793618326856208e-05,
      "loss": 0.4963,
      "step": 5910
    },
    {
      "epoch": 12.106339468302659,
      "grad_norm": 4.51231050491333,
      "learning_rate": 8.791572918797301e-05,
      "loss": 0.5553,
      "step": 5920
    },
    {
      "epoch": 12.12678936605317,
      "grad_norm": 3.5361404418945312,
      "learning_rate": 8.789527510738392e-05,
      "loss": 0.4898,
      "step": 5930
    },
    {
      "epoch": 12.14723926380368,
      "grad_norm": 3.137850761413574,
      "learning_rate": 8.787482102679486e-05,
      "loss": 0.4404,
      "step": 5940
    },
    {
      "epoch": 12.167689161554192,
      "grad_norm": 4.069644927978516,
      "learning_rate": 8.785436694620576e-05,
      "loss": 0.5308,
      "step": 5950
    },
    {
      "epoch": 12.188139059304703,
      "grad_norm": 2.6506879329681396,
      "learning_rate": 8.78339128656167e-05,
      "loss": 0.5457,
      "step": 5960
    },
    {
      "epoch": 12.208588957055214,
      "grad_norm": 5.739704132080078,
      "learning_rate": 8.781345878502761e-05,
      "loss": 0.567,
      "step": 5970
    },
    {
      "epoch": 12.229038854805726,
      "grad_norm": 2.777451992034912,
      "learning_rate": 8.779300470443854e-05,
      "loss": 0.5101,
      "step": 5980
    },
    {
      "epoch": 12.249488752556237,
      "grad_norm": 5.416274070739746,
      "learning_rate": 8.777255062384945e-05,
      "loss": 0.6251,
      "step": 5990
    },
    {
      "epoch": 12.269938650306749,
      "grad_norm": 2.8825607299804688,
      "learning_rate": 8.775209654326039e-05,
      "loss": 0.601,
      "step": 6000
    },
    {
      "epoch": 12.269938650306749,
      "eval_loss": 2.4975123405456543,
      "eval_runtime": 27.2545,
      "eval_samples_per_second": 11.815,
      "eval_steps_per_second": 0.991,
      "step": 6000
    },
    {
      "epoch": 12.29038854805726,
      "grad_norm": 2.738318920135498,
      "learning_rate": 8.773164246267131e-05,
      "loss": 0.4282,
      "step": 6010
    },
    {
      "epoch": 12.310838445807772,
      "grad_norm": 5.334701061248779,
      "learning_rate": 8.771118838208223e-05,
      "loss": 0.4863,
      "step": 6020
    },
    {
      "epoch": 12.331288343558283,
      "grad_norm": 2.702655076980591,
      "learning_rate": 8.769073430149315e-05,
      "loss": 0.5697,
      "step": 6030
    },
    {
      "epoch": 12.351738241308793,
      "grad_norm": 4.526920795440674,
      "learning_rate": 8.767028022090408e-05,
      "loss": 0.5456,
      "step": 6040
    },
    {
      "epoch": 12.372188139059304,
      "grad_norm": 3.4027791023254395,
      "learning_rate": 8.7649826140315e-05,
      "loss": 0.5699,
      "step": 6050
    },
    {
      "epoch": 12.392638036809815,
      "grad_norm": 2.917599678039551,
      "learning_rate": 8.762937205972592e-05,
      "loss": 0.4964,
      "step": 6060
    },
    {
      "epoch": 12.413087934560327,
      "grad_norm": 2.672978162765503,
      "learning_rate": 8.760891797913684e-05,
      "loss": 0.54,
      "step": 6070
    },
    {
      "epoch": 12.433537832310838,
      "grad_norm": 3.797964334487915,
      "learning_rate": 8.758846389854777e-05,
      "loss": 0.4581,
      "step": 6080
    },
    {
      "epoch": 12.45398773006135,
      "grad_norm": 4.55403995513916,
      "learning_rate": 8.756800981795869e-05,
      "loss": 0.4821,
      "step": 6090
    },
    {
      "epoch": 12.474437627811861,
      "grad_norm": 4.549325466156006,
      "learning_rate": 8.754755573736961e-05,
      "loss": 0.5211,
      "step": 6100
    },
    {
      "epoch": 12.474437627811861,
      "eval_loss": 2.50543212890625,
      "eval_runtime": 27.3284,
      "eval_samples_per_second": 11.783,
      "eval_steps_per_second": 0.988,
      "step": 6100
    },
    {
      "epoch": 12.494887525562373,
      "grad_norm": 4.474483966827393,
      "learning_rate": 8.752710165678053e-05,
      "loss": 0.5659,
      "step": 6110
    },
    {
      "epoch": 12.515337423312884,
      "grad_norm": 3.6209468841552734,
      "learning_rate": 8.750664757619145e-05,
      "loss": 0.5571,
      "step": 6120
    },
    {
      "epoch": 12.535787321063395,
      "grad_norm": 3.386561632156372,
      "learning_rate": 8.748619349560238e-05,
      "loss": 0.5739,
      "step": 6130
    },
    {
      "epoch": 12.556237218813905,
      "grad_norm": 2.4574224948883057,
      "learning_rate": 8.74657394150133e-05,
      "loss": 0.5228,
      "step": 6140
    },
    {
      "epoch": 12.576687116564417,
      "grad_norm": 2.493833065032959,
      "learning_rate": 8.744528533442422e-05,
      "loss": 0.5298,
      "step": 6150
    },
    {
      "epoch": 12.597137014314928,
      "grad_norm": 3.337069034576416,
      "learning_rate": 8.742483125383514e-05,
      "loss": 0.554,
      "step": 6160
    },
    {
      "epoch": 12.61758691206544,
      "grad_norm": 3.6680028438568115,
      "learning_rate": 8.740437717324606e-05,
      "loss": 0.5701,
      "step": 6170
    },
    {
      "epoch": 12.63803680981595,
      "grad_norm": 3.8304693698883057,
      "learning_rate": 8.7383923092657e-05,
      "loss": 0.5668,
      "step": 6180
    },
    {
      "epoch": 12.658486707566462,
      "grad_norm": 3.416449546813965,
      "learning_rate": 8.736346901206791e-05,
      "loss": 0.4919,
      "step": 6190
    },
    {
      "epoch": 12.678936605316974,
      "grad_norm": 4.79457950592041,
      "learning_rate": 8.734301493147884e-05,
      "loss": 0.6735,
      "step": 6200
    },
    {
      "epoch": 12.678936605316974,
      "eval_loss": 2.4860026836395264,
      "eval_runtime": 27.3093,
      "eval_samples_per_second": 11.791,
      "eval_steps_per_second": 0.989,
      "step": 6200
    },
    {
      "epoch": 12.699386503067485,
      "grad_norm": 2.7336220741271973,
      "learning_rate": 8.732256085088975e-05,
      "loss": 0.5816,
      "step": 6210
    },
    {
      "epoch": 12.719836400817996,
      "grad_norm": 3.406898260116577,
      "learning_rate": 8.730210677030069e-05,
      "loss": 0.557,
      "step": 6220
    },
    {
      "epoch": 12.740286298568508,
      "grad_norm": 3.3824050426483154,
      "learning_rate": 8.72816526897116e-05,
      "loss": 0.6086,
      "step": 6230
    },
    {
      "epoch": 12.76073619631902,
      "grad_norm": 4.2718634605407715,
      "learning_rate": 8.726119860912252e-05,
      "loss": 0.4943,
      "step": 6240
    },
    {
      "epoch": 12.781186094069529,
      "grad_norm": 5.662449836730957,
      "learning_rate": 8.724074452853344e-05,
      "loss": 0.6136,
      "step": 6250
    },
    {
      "epoch": 12.80163599182004,
      "grad_norm": 4.717245101928711,
      "learning_rate": 8.722029044794436e-05,
      "loss": 0.5485,
      "step": 6260
    },
    {
      "epoch": 12.822085889570552,
      "grad_norm": 4.508052349090576,
      "learning_rate": 8.719983636735529e-05,
      "loss": 0.6161,
      "step": 6270
    },
    {
      "epoch": 12.842535787321063,
      "grad_norm": 3.9787094593048096,
      "learning_rate": 8.717938228676621e-05,
      "loss": 0.5246,
      "step": 6280
    },
    {
      "epoch": 12.862985685071575,
      "grad_norm": 3.1977062225341797,
      "learning_rate": 8.715892820617714e-05,
      "loss": 0.5252,
      "step": 6290
    },
    {
      "epoch": 12.883435582822086,
      "grad_norm": 3.5913195610046387,
      "learning_rate": 8.713847412558805e-05,
      "loss": 0.6099,
      "step": 6300
    },
    {
      "epoch": 12.883435582822086,
      "eval_loss": 2.4603896141052246,
      "eval_runtime": 27.2455,
      "eval_samples_per_second": 11.818,
      "eval_steps_per_second": 0.991,
      "step": 6300
    },
    {
      "epoch": 12.903885480572598,
      "grad_norm": 4.734371662139893,
      "learning_rate": 8.711802004499899e-05,
      "loss": 0.5679,
      "step": 6310
    },
    {
      "epoch": 12.924335378323109,
      "grad_norm": 3.662119150161743,
      "learning_rate": 8.70975659644099e-05,
      "loss": 0.5542,
      "step": 6320
    },
    {
      "epoch": 12.94478527607362,
      "grad_norm": 4.198345184326172,
      "learning_rate": 8.707711188382083e-05,
      "loss": 0.5854,
      "step": 6330
    },
    {
      "epoch": 12.96523517382413,
      "grad_norm": 3.7215728759765625,
      "learning_rate": 8.705665780323174e-05,
      "loss": 0.5829,
      "step": 6340
    },
    {
      "epoch": 12.985685071574641,
      "grad_norm": 3.3840980529785156,
      "learning_rate": 8.703620372264268e-05,
      "loss": 0.5831,
      "step": 6350
    },
    {
      "epoch": 13.006134969325153,
      "grad_norm": 5.207888126373291,
      "learning_rate": 8.701574964205358e-05,
      "loss": 0.4861,
      "step": 6360
    },
    {
      "epoch": 13.026584867075664,
      "grad_norm": 7.280799388885498,
      "learning_rate": 8.699529556146452e-05,
      "loss": 0.4544,
      "step": 6370
    },
    {
      "epoch": 13.047034764826176,
      "grad_norm": 3.3771843910217285,
      "learning_rate": 8.697484148087543e-05,
      "loss": 0.4471,
      "step": 6380
    },
    {
      "epoch": 13.067484662576687,
      "grad_norm": 3.810072660446167,
      "learning_rate": 8.695438740028636e-05,
      "loss": 0.4632,
      "step": 6390
    },
    {
      "epoch": 13.087934560327199,
      "grad_norm": 3.7115211486816406,
      "learning_rate": 8.693393331969729e-05,
      "loss": 0.4637,
      "step": 6400
    },
    {
      "epoch": 13.087934560327199,
      "eval_loss": 2.613065719604492,
      "eval_runtime": 27.3015,
      "eval_samples_per_second": 11.794,
      "eval_steps_per_second": 0.989,
      "step": 6400
    },
    {
      "epoch": 13.10838445807771,
      "grad_norm": 3.4278829097747803,
      "learning_rate": 8.691347923910821e-05,
      "loss": 0.4804,
      "step": 6410
    },
    {
      "epoch": 13.128834355828221,
      "grad_norm": 4.949928283691406,
      "learning_rate": 8.689302515851913e-05,
      "loss": 0.5027,
      "step": 6420
    },
    {
      "epoch": 13.149284253578733,
      "grad_norm": 5.3950018882751465,
      "learning_rate": 8.687257107793005e-05,
      "loss": 0.4954,
      "step": 6430
    },
    {
      "epoch": 13.169734151329243,
      "grad_norm": 1.9285023212432861,
      "learning_rate": 8.685211699734098e-05,
      "loss": 0.4535,
      "step": 6440
    },
    {
      "epoch": 13.190184049079754,
      "grad_norm": 7.292084693908691,
      "learning_rate": 8.68316629167519e-05,
      "loss": 0.4869,
      "step": 6450
    },
    {
      "epoch": 13.210633946830265,
      "grad_norm": 3.9987118244171143,
      "learning_rate": 8.681120883616282e-05,
      "loss": 0.5029,
      "step": 6460
    },
    {
      "epoch": 13.231083844580777,
      "grad_norm": 2.8562309741973877,
      "learning_rate": 8.679075475557374e-05,
      "loss": 0.4864,
      "step": 6470
    },
    {
      "epoch": 13.251533742331288,
      "grad_norm": 2.862783193588257,
      "learning_rate": 8.677030067498466e-05,
      "loss": 0.4437,
      "step": 6480
    },
    {
      "epoch": 13.2719836400818,
      "grad_norm": 2.9028987884521484,
      "learning_rate": 8.674984659439559e-05,
      "loss": 0.4567,
      "step": 6490
    },
    {
      "epoch": 13.292433537832311,
      "grad_norm": 2.3011322021484375,
      "learning_rate": 8.672939251380651e-05,
      "loss": 0.4744,
      "step": 6500
    },
    {
      "epoch": 13.292433537832311,
      "eval_loss": 2.5855906009674072,
      "eval_runtime": 27.2008,
      "eval_samples_per_second": 11.838,
      "eval_steps_per_second": 0.993,
      "step": 6500
    },
    {
      "epoch": 13.312883435582823,
      "grad_norm": 2.9699249267578125,
      "learning_rate": 8.670893843321743e-05,
      "loss": 0.4878,
      "step": 6510
    },
    {
      "epoch": 13.333333333333334,
      "grad_norm": 2.6667776107788086,
      "learning_rate": 8.668848435262835e-05,
      "loss": 0.5218,
      "step": 6520
    },
    {
      "epoch": 13.353783231083845,
      "grad_norm": 4.16123104095459,
      "learning_rate": 8.666803027203927e-05,
      "loss": 0.4202,
      "step": 6530
    },
    {
      "epoch": 13.374233128834355,
      "grad_norm": 3.277653455734253,
      "learning_rate": 8.66475761914502e-05,
      "loss": 0.5471,
      "step": 6540
    },
    {
      "epoch": 13.394683026584866,
      "grad_norm": 4.674957275390625,
      "learning_rate": 8.662712211086113e-05,
      "loss": 0.4652,
      "step": 6550
    },
    {
      "epoch": 13.415132924335378,
      "grad_norm": 1.99196457862854,
      "learning_rate": 8.660666803027204e-05,
      "loss": 0.5112,
      "step": 6560
    },
    {
      "epoch": 13.43558282208589,
      "grad_norm": 4.611999034881592,
      "learning_rate": 8.658621394968298e-05,
      "loss": 0.4988,
      "step": 6570
    },
    {
      "epoch": 13.4560327198364,
      "grad_norm": 4.242366313934326,
      "learning_rate": 8.656575986909388e-05,
      "loss": 0.4405,
      "step": 6580
    },
    {
      "epoch": 13.476482617586912,
      "grad_norm": 7.024600028991699,
      "learning_rate": 8.654530578850482e-05,
      "loss": 0.4415,
      "step": 6590
    },
    {
      "epoch": 13.496932515337424,
      "grad_norm": 4.202225685119629,
      "learning_rate": 8.652485170791573e-05,
      "loss": 0.5309,
      "step": 6600
    },
    {
      "epoch": 13.496932515337424,
      "eval_loss": 2.5859477519989014,
      "eval_runtime": 27.2041,
      "eval_samples_per_second": 11.836,
      "eval_steps_per_second": 0.992,
      "step": 6600
    },
    {
      "epoch": 13.517382413087935,
      "grad_norm": 5.587560176849365,
      "learning_rate": 8.650439762732666e-05,
      "loss": 0.5654,
      "step": 6610
    },
    {
      "epoch": 13.537832310838446,
      "grad_norm": 3.738642454147339,
      "learning_rate": 8.648394354673757e-05,
      "loss": 0.4768,
      "step": 6620
    },
    {
      "epoch": 13.558282208588958,
      "grad_norm": 4.7205705642700195,
      "learning_rate": 8.646348946614851e-05,
      "loss": 0.5667,
      "step": 6630
    },
    {
      "epoch": 13.578732106339467,
      "grad_norm": 5.473227500915527,
      "learning_rate": 8.644303538555942e-05,
      "loss": 0.4683,
      "step": 6640
    },
    {
      "epoch": 13.599182004089979,
      "grad_norm": 3.537827730178833,
      "learning_rate": 8.642258130497034e-05,
      "loss": 0.4468,
      "step": 6650
    },
    {
      "epoch": 13.61963190184049,
      "grad_norm": 3.1483700275421143,
      "learning_rate": 8.640212722438126e-05,
      "loss": 0.4943,
      "step": 6660
    },
    {
      "epoch": 13.640081799591002,
      "grad_norm": 4.254865646362305,
      "learning_rate": 8.638167314379218e-05,
      "loss": 0.6298,
      "step": 6670
    },
    {
      "epoch": 13.660531697341513,
      "grad_norm": 4.183143615722656,
      "learning_rate": 8.636121906320312e-05,
      "loss": 0.5348,
      "step": 6680
    },
    {
      "epoch": 13.680981595092025,
      "grad_norm": 3.1991465091705322,
      "learning_rate": 8.634076498261403e-05,
      "loss": 0.4674,
      "step": 6690
    },
    {
      "epoch": 13.701431492842536,
      "grad_norm": 3.481132984161377,
      "learning_rate": 8.632031090202496e-05,
      "loss": 0.5083,
      "step": 6700
    },
    {
      "epoch": 13.701431492842536,
      "eval_loss": 2.5952353477478027,
      "eval_runtime": 27.206,
      "eval_samples_per_second": 11.836,
      "eval_steps_per_second": 0.992,
      "step": 6700
    },
    {
      "epoch": 13.721881390593047,
      "grad_norm": 5.195807456970215,
      "learning_rate": 8.629985682143587e-05,
      "loss": 0.5156,
      "step": 6710
    },
    {
      "epoch": 13.742331288343559,
      "grad_norm": 4.183887004852295,
      "learning_rate": 8.627940274084681e-05,
      "loss": 0.5479,
      "step": 6720
    },
    {
      "epoch": 13.76278118609407,
      "grad_norm": 3.847661256790161,
      "learning_rate": 8.625894866025772e-05,
      "loss": 0.5034,
      "step": 6730
    },
    {
      "epoch": 13.78323108384458,
      "grad_norm": 3.0192110538482666,
      "learning_rate": 8.623849457966865e-05,
      "loss": 0.5165,
      "step": 6740
    },
    {
      "epoch": 13.803680981595091,
      "grad_norm": 3.3062102794647217,
      "learning_rate": 8.621804049907956e-05,
      "loss": 0.4835,
      "step": 6750
    },
    {
      "epoch": 13.824130879345603,
      "grad_norm": 4.309158802032471,
      "learning_rate": 8.61975864184905e-05,
      "loss": 0.5093,
      "step": 6760
    },
    {
      "epoch": 13.844580777096114,
      "grad_norm": 3.6792664527893066,
      "learning_rate": 8.61771323379014e-05,
      "loss": 0.5429,
      "step": 6770
    },
    {
      "epoch": 13.865030674846626,
      "grad_norm": 4.132877349853516,
      "learning_rate": 8.615667825731234e-05,
      "loss": 0.4893,
      "step": 6780
    },
    {
      "epoch": 13.885480572597137,
      "grad_norm": 3.081268548965454,
      "learning_rate": 8.613622417672326e-05,
      "loss": 0.4962,
      "step": 6790
    },
    {
      "epoch": 13.905930470347649,
      "grad_norm": 3.949180841445923,
      "learning_rate": 8.611577009613418e-05,
      "loss": 0.4955,
      "step": 6800
    },
    {
      "epoch": 13.905930470347649,
      "eval_loss": 2.5653138160705566,
      "eval_runtime": 27.2323,
      "eval_samples_per_second": 11.824,
      "eval_steps_per_second": 0.991,
      "step": 6800
    },
    {
      "epoch": 13.92638036809816,
      "grad_norm": 5.479201793670654,
      "learning_rate": 8.609531601554511e-05,
      "loss": 0.6048,
      "step": 6810
    },
    {
      "epoch": 13.946830265848671,
      "grad_norm": 4.620283126831055,
      "learning_rate": 8.607486193495603e-05,
      "loss": 0.5807,
      "step": 6820
    },
    {
      "epoch": 13.967280163599183,
      "grad_norm": 3.539823293685913,
      "learning_rate": 8.605440785436695e-05,
      "loss": 0.4915,
      "step": 6830
    },
    {
      "epoch": 13.987730061349692,
      "grad_norm": 2.8092122077941895,
      "learning_rate": 8.603395377377787e-05,
      "loss": 0.5272,
      "step": 6840
    },
    {
      "epoch": 14.008179959100204,
      "grad_norm": 3.4978580474853516,
      "learning_rate": 8.60134996931888e-05,
      "loss": 0.5502,
      "step": 6850
    },
    {
      "epoch": 14.028629856850715,
      "grad_norm": 2.1664981842041016,
      "learning_rate": 8.599304561259972e-05,
      "loss": 0.3919,
      "step": 6860
    },
    {
      "epoch": 14.049079754601227,
      "grad_norm": 5.201249122619629,
      "learning_rate": 8.597259153201064e-05,
      "loss": 0.4478,
      "step": 6870
    },
    {
      "epoch": 14.069529652351738,
      "grad_norm": 4.4631876945495605,
      "learning_rate": 8.595213745142156e-05,
      "loss": 0.4715,
      "step": 6880
    },
    {
      "epoch": 14.08997955010225,
      "grad_norm": 3.2939367294311523,
      "learning_rate": 8.593168337083248e-05,
      "loss": 0.4531,
      "step": 6890
    },
    {
      "epoch": 14.110429447852761,
      "grad_norm": 5.0906877517700195,
      "learning_rate": 8.59112292902434e-05,
      "loss": 0.4163,
      "step": 6900
    },
    {
      "epoch": 14.110429447852761,
      "eval_loss": 2.7382476329803467,
      "eval_runtime": 27.2379,
      "eval_samples_per_second": 11.822,
      "eval_steps_per_second": 0.991,
      "step": 6900
    },
    {
      "epoch": 14.130879345603272,
      "grad_norm": 4.405657768249512,
      "learning_rate": 8.589077520965433e-05,
      "loss": 0.4321,
      "step": 6910
    },
    {
      "epoch": 14.151329243353784,
      "grad_norm": 3.0858993530273438,
      "learning_rate": 8.587032112906525e-05,
      "loss": 0.4133,
      "step": 6920
    },
    {
      "epoch": 14.171779141104295,
      "grad_norm": 4.51290225982666,
      "learning_rate": 8.584986704847617e-05,
      "loss": 0.4464,
      "step": 6930
    },
    {
      "epoch": 14.192229038854805,
      "grad_norm": 4.033680438995361,
      "learning_rate": 8.582941296788711e-05,
      "loss": 0.4669,
      "step": 6940
    },
    {
      "epoch": 14.212678936605316,
      "grad_norm": 5.079061985015869,
      "learning_rate": 8.580895888729802e-05,
      "loss": 0.4498,
      "step": 6950
    },
    {
      "epoch": 14.233128834355828,
      "grad_norm": 3.399648904800415,
      "learning_rate": 8.578850480670895e-05,
      "loss": 0.4213,
      "step": 6960
    },
    {
      "epoch": 14.25357873210634,
      "grad_norm": 4.418502330780029,
      "learning_rate": 8.576805072611986e-05,
      "loss": 0.4604,
      "step": 6970
    },
    {
      "epoch": 14.27402862985685,
      "grad_norm": 2.066984176635742,
      "learning_rate": 8.57475966455308e-05,
      "loss": 0.4225,
      "step": 6980
    },
    {
      "epoch": 14.294478527607362,
      "grad_norm": 2.9664483070373535,
      "learning_rate": 8.57271425649417e-05,
      "loss": 0.4468,
      "step": 6990
    },
    {
      "epoch": 14.314928425357873,
      "grad_norm": 3.90639328956604,
      "learning_rate": 8.570668848435264e-05,
      "loss": 0.3916,
      "step": 7000
    },
    {
      "epoch": 14.314928425357873,
      "eval_loss": 2.714186668395996,
      "eval_runtime": 27.2377,
      "eval_samples_per_second": 11.822,
      "eval_steps_per_second": 0.991,
      "step": 7000
    },
    {
      "epoch": 14.335378323108385,
      "grad_norm": 3.1585710048675537,
      "learning_rate": 8.568623440376355e-05,
      "loss": 0.5281,
      "step": 7010
    },
    {
      "epoch": 14.355828220858896,
      "grad_norm": 2.729747772216797,
      "learning_rate": 8.566578032317449e-05,
      "loss": 0.4551,
      "step": 7020
    },
    {
      "epoch": 14.376278118609408,
      "grad_norm": 3.8636600971221924,
      "learning_rate": 8.56453262425854e-05,
      "loss": 0.4747,
      "step": 7030
    },
    {
      "epoch": 14.396728016359917,
      "grad_norm": 3.3507118225097656,
      "learning_rate": 8.562487216199633e-05,
      "loss": 0.4238,
      "step": 7040
    },
    {
      "epoch": 14.417177914110429,
      "grad_norm": 2.4211864471435547,
      "learning_rate": 8.560441808140725e-05,
      "loss": 0.4074,
      "step": 7050
    },
    {
      "epoch": 14.43762781186094,
      "grad_norm": 2.845780611038208,
      "learning_rate": 8.558396400081816e-05,
      "loss": 0.4169,
      "step": 7060
    },
    {
      "epoch": 14.458077709611452,
      "grad_norm": 3.1029438972473145,
      "learning_rate": 8.55635099202291e-05,
      "loss": 0.4644,
      "step": 7070
    },
    {
      "epoch": 14.478527607361963,
      "grad_norm": 3.498802423477173,
      "learning_rate": 8.554305583964e-05,
      "loss": 0.4956,
      "step": 7080
    },
    {
      "epoch": 14.498977505112475,
      "grad_norm": 3.881871461868286,
      "learning_rate": 8.552260175905094e-05,
      "loss": 0.4116,
      "step": 7090
    },
    {
      "epoch": 14.519427402862986,
      "grad_norm": 5.168504238128662,
      "learning_rate": 8.550214767846185e-05,
      "loss": 0.4488,
      "step": 7100
    },
    {
      "epoch": 14.519427402862986,
      "eval_loss": 2.661007881164551,
      "eval_runtime": 27.2553,
      "eval_samples_per_second": 11.814,
      "eval_steps_per_second": 0.991,
      "step": 7100
    },
    {
      "epoch": 14.539877300613497,
      "grad_norm": 3.04970121383667,
      "learning_rate": 8.548169359787278e-05,
      "loss": 0.4854,
      "step": 7110
    },
    {
      "epoch": 14.560327198364009,
      "grad_norm": 4.746358871459961,
      "learning_rate": 8.546123951728369e-05,
      "loss": 0.4893,
      "step": 7120
    },
    {
      "epoch": 14.58077709611452,
      "grad_norm": 2.5785367488861084,
      "learning_rate": 8.544078543669463e-05,
      "loss": 0.501,
      "step": 7130
    },
    {
      "epoch": 14.60122699386503,
      "grad_norm": 3.2554030418395996,
      "learning_rate": 8.542033135610554e-05,
      "loss": 0.4293,
      "step": 7140
    },
    {
      "epoch": 14.621676891615541,
      "grad_norm": 3.195416212081909,
      "learning_rate": 8.539987727551647e-05,
      "loss": 0.4458,
      "step": 7150
    },
    {
      "epoch": 14.642126789366053,
      "grad_norm": 3.2411084175109863,
      "learning_rate": 8.53794231949274e-05,
      "loss": 0.4745,
      "step": 7160
    },
    {
      "epoch": 14.662576687116564,
      "grad_norm": 3.0091326236724854,
      "learning_rate": 8.535896911433832e-05,
      "loss": 0.4317,
      "step": 7170
    },
    {
      "epoch": 14.683026584867076,
      "grad_norm": 3.6625497341156006,
      "learning_rate": 8.533851503374924e-05,
      "loss": 0.5098,
      "step": 7180
    },
    {
      "epoch": 14.703476482617587,
      "grad_norm": 3.5727744102478027,
      "learning_rate": 8.531806095316016e-05,
      "loss": 0.4134,
      "step": 7190
    },
    {
      "epoch": 14.723926380368098,
      "grad_norm": 2.4367799758911133,
      "learning_rate": 8.529760687257108e-05,
      "loss": 0.4992,
      "step": 7200
    },
    {
      "epoch": 14.723926380368098,
      "eval_loss": 2.718686819076538,
      "eval_runtime": 27.1974,
      "eval_samples_per_second": 11.839,
      "eval_steps_per_second": 0.993,
      "step": 7200
    },
    {
      "epoch": 14.74437627811861,
      "grad_norm": 3.301673650741577,
      "learning_rate": 8.5277152791982e-05,
      "loss": 0.4605,
      "step": 7210
    },
    {
      "epoch": 14.764826175869121,
      "grad_norm": 4.933656215667725,
      "learning_rate": 8.525669871139293e-05,
      "loss": 0.4679,
      "step": 7220
    },
    {
      "epoch": 14.785276073619633,
      "grad_norm": 5.088372230529785,
      "learning_rate": 8.523624463080385e-05,
      "loss": 0.4785,
      "step": 7230
    },
    {
      "epoch": 14.805725971370142,
      "grad_norm": 4.043270587921143,
      "learning_rate": 8.521579055021477e-05,
      "loss": 0.5029,
      "step": 7240
    },
    {
      "epoch": 14.826175869120654,
      "grad_norm": 6.104616641998291,
      "learning_rate": 8.51953364696257e-05,
      "loss": 0.451,
      "step": 7250
    },
    {
      "epoch": 14.846625766871165,
      "grad_norm": 3.5243122577667236,
      "learning_rate": 8.517488238903662e-05,
      "loss": 0.455,
      "step": 7260
    },
    {
      "epoch": 14.867075664621677,
      "grad_norm": 3.009187936782837,
      "learning_rate": 8.515442830844754e-05,
      "loss": 0.4224,
      "step": 7270
    },
    {
      "epoch": 14.887525562372188,
      "grad_norm": 2.902470827102661,
      "learning_rate": 8.513397422785846e-05,
      "loss": 0.4985,
      "step": 7280
    },
    {
      "epoch": 14.9079754601227,
      "grad_norm": 3.047703504562378,
      "learning_rate": 8.511352014726938e-05,
      "loss": 0.4732,
      "step": 7290
    },
    {
      "epoch": 14.928425357873211,
      "grad_norm": 4.873942852020264,
      "learning_rate": 8.50930660666803e-05,
      "loss": 0.5342,
      "step": 7300
    },
    {
      "epoch": 14.928425357873211,
      "eval_loss": 2.6595234870910645,
      "eval_runtime": 27.7878,
      "eval_samples_per_second": 11.588,
      "eval_steps_per_second": 0.972,
      "step": 7300
    },
    {
      "epoch": 14.948875255623722,
      "grad_norm": 2.4641201496124268,
      "learning_rate": 8.507261198609123e-05,
      "loss": 0.4426,
      "step": 7310
    },
    {
      "epoch": 14.969325153374234,
      "grad_norm": 3.792276382446289,
      "learning_rate": 8.505215790550215e-05,
      "loss": 0.4506,
      "step": 7320
    },
    {
      "epoch": 14.989775051124745,
      "grad_norm": 4.97307825088501,
      "learning_rate": 8.503170382491308e-05,
      "loss": 0.4551,
      "step": 7330
    },
    {
      "epoch": 15.010224948875255,
      "grad_norm": 3.815232515335083,
      "learning_rate": 8.501124974432399e-05,
      "loss": 0.4982,
      "step": 7340
    },
    {
      "epoch": 15.030674846625766,
      "grad_norm": 3.8063042163848877,
      "learning_rate": 8.499079566373493e-05,
      "loss": 0.3893,
      "step": 7350
    },
    {
      "epoch": 15.051124744376278,
      "grad_norm": 4.0596466064453125,
      "learning_rate": 8.497034158314584e-05,
      "loss": 0.3526,
      "step": 7360
    },
    {
      "epoch": 15.071574642126789,
      "grad_norm": 3.869595766067505,
      "learning_rate": 8.494988750255677e-05,
      "loss": 0.3874,
      "step": 7370
    },
    {
      "epoch": 15.0920245398773,
      "grad_norm": 3.7780075073242188,
      "learning_rate": 8.492943342196768e-05,
      "loss": 0.4079,
      "step": 7380
    },
    {
      "epoch": 15.112474437627812,
      "grad_norm": 2.9554944038391113,
      "learning_rate": 8.490897934137862e-05,
      "loss": 0.4282,
      "step": 7390
    },
    {
      "epoch": 15.132924335378323,
      "grad_norm": 4.014184951782227,
      "learning_rate": 8.488852526078953e-05,
      "loss": 0.4022,
      "step": 7400
    },
    {
      "epoch": 15.132924335378323,
      "eval_loss": 2.772425413131714,
      "eval_runtime": 27.2361,
      "eval_samples_per_second": 11.823,
      "eval_steps_per_second": 0.991,
      "step": 7400
    },
    {
      "epoch": 15.153374233128835,
      "grad_norm": 4.344181537628174,
      "learning_rate": 8.486807118020046e-05,
      "loss": 0.4571,
      "step": 7410
    },
    {
      "epoch": 15.173824130879346,
      "grad_norm": 3.1382241249084473,
      "learning_rate": 8.484761709961137e-05,
      "loss": 0.4113,
      "step": 7420
    },
    {
      "epoch": 15.194274028629858,
      "grad_norm": 3.4159040451049805,
      "learning_rate": 8.48271630190223e-05,
      "loss": 0.4246,
      "step": 7430
    },
    {
      "epoch": 15.214723926380367,
      "grad_norm": 5.894619464874268,
      "learning_rate": 8.480670893843323e-05,
      "loss": 0.4554,
      "step": 7440
    },
    {
      "epoch": 15.235173824130879,
      "grad_norm": 4.026488304138184,
      "learning_rate": 8.478625485784414e-05,
      "loss": 0.4361,
      "step": 7450
    },
    {
      "epoch": 15.25562372188139,
      "grad_norm": 3.2106714248657227,
      "learning_rate": 8.476580077725507e-05,
      "loss": 0.41,
      "step": 7460
    },
    {
      "epoch": 15.276073619631902,
      "grad_norm": 1.9320168495178223,
      "learning_rate": 8.474534669666598e-05,
      "loss": 0.398,
      "step": 7470
    },
    {
      "epoch": 15.296523517382413,
      "grad_norm": 5.6750078201293945,
      "learning_rate": 8.472489261607692e-05,
      "loss": 0.412,
      "step": 7480
    },
    {
      "epoch": 15.316973415132924,
      "grad_norm": 4.478093147277832,
      "learning_rate": 8.470443853548782e-05,
      "loss": 0.4287,
      "step": 7490
    },
    {
      "epoch": 15.337423312883436,
      "grad_norm": 2.7388200759887695,
      "learning_rate": 8.468398445489876e-05,
      "loss": 0.4531,
      "step": 7500
    },
    {
      "epoch": 15.337423312883436,
      "eval_loss": 2.7618043422698975,
      "eval_runtime": 27.3124,
      "eval_samples_per_second": 11.79,
      "eval_steps_per_second": 0.989,
      "step": 7500
    },
    {
      "epoch": 15.357873210633947,
      "grad_norm": 2.7902252674102783,
      "learning_rate": 8.466353037430967e-05,
      "loss": 0.3601,
      "step": 7510
    },
    {
      "epoch": 15.378323108384459,
      "grad_norm": 3.085975170135498,
      "learning_rate": 8.46430762937206e-05,
      "loss": 0.4378,
      "step": 7520
    },
    {
      "epoch": 15.39877300613497,
      "grad_norm": 4.10988187789917,
      "learning_rate": 8.462262221313151e-05,
      "loss": 0.4589,
      "step": 7530
    },
    {
      "epoch": 15.41922290388548,
      "grad_norm": 2.6300973892211914,
      "learning_rate": 8.460216813254245e-05,
      "loss": 0.386,
      "step": 7540
    },
    {
      "epoch": 15.439672801635991,
      "grad_norm": 4.086325168609619,
      "learning_rate": 8.458171405195337e-05,
      "loss": 0.4542,
      "step": 7550
    },
    {
      "epoch": 15.460122699386503,
      "grad_norm": 3.089085817337036,
      "learning_rate": 8.456125997136429e-05,
      "loss": 0.4238,
      "step": 7560
    },
    {
      "epoch": 15.480572597137014,
      "grad_norm": 2.808915138244629,
      "learning_rate": 8.454080589077522e-05,
      "loss": 0.4233,
      "step": 7570
    },
    {
      "epoch": 15.501022494887525,
      "grad_norm": 3.699129343032837,
      "learning_rate": 8.452035181018614e-05,
      "loss": 0.469,
      "step": 7580
    },
    {
      "epoch": 15.521472392638037,
      "grad_norm": 4.032441139221191,
      "learning_rate": 8.449989772959706e-05,
      "loss": 0.4229,
      "step": 7590
    },
    {
      "epoch": 15.541922290388548,
      "grad_norm": 6.708615779876709,
      "learning_rate": 8.447944364900798e-05,
      "loss": 0.4254,
      "step": 7600
    },
    {
      "epoch": 15.541922290388548,
      "eval_loss": 2.787853717803955,
      "eval_runtime": 27.2793,
      "eval_samples_per_second": 11.804,
      "eval_steps_per_second": 0.99,
      "step": 7600
    },
    {
      "epoch": 15.56237218813906,
      "grad_norm": 2.8044424057006836,
      "learning_rate": 8.44589895684189e-05,
      "loss": 0.4313,
      "step": 7610
    },
    {
      "epoch": 15.582822085889571,
      "grad_norm": 3.2798447608947754,
      "learning_rate": 8.443853548782983e-05,
      "loss": 0.3991,
      "step": 7620
    },
    {
      "epoch": 15.603271983640083,
      "grad_norm": 2.9794859886169434,
      "learning_rate": 8.441808140724075e-05,
      "loss": 0.481,
      "step": 7630
    },
    {
      "epoch": 15.623721881390592,
      "grad_norm": 4.736888885498047,
      "learning_rate": 8.439762732665167e-05,
      "loss": 0.4226,
      "step": 7640
    },
    {
      "epoch": 15.644171779141104,
      "grad_norm": 2.4807498455047607,
      "learning_rate": 8.437717324606259e-05,
      "loss": 0.433,
      "step": 7650
    },
    {
      "epoch": 15.664621676891615,
      "grad_norm": 3.0895090103149414,
      "learning_rate": 8.435671916547351e-05,
      "loss": 0.3854,
      "step": 7660
    },
    {
      "epoch": 15.685071574642127,
      "grad_norm": 4.054802417755127,
      "learning_rate": 8.433626508488444e-05,
      "loss": 0.4291,
      "step": 7670
    },
    {
      "epoch": 15.705521472392638,
      "grad_norm": 3.3605735301971436,
      "learning_rate": 8.431581100429536e-05,
      "loss": 0.424,
      "step": 7680
    },
    {
      "epoch": 15.72597137014315,
      "grad_norm": 4.075857639312744,
      "learning_rate": 8.429535692370628e-05,
      "loss": 0.4528,
      "step": 7690
    },
    {
      "epoch": 15.74642126789366,
      "grad_norm": 2.7166435718536377,
      "learning_rate": 8.42749028431172e-05,
      "loss": 0.4216,
      "step": 7700
    },
    {
      "epoch": 15.74642126789366,
      "eval_loss": 2.7365567684173584,
      "eval_runtime": 27.2356,
      "eval_samples_per_second": 11.823,
      "eval_steps_per_second": 0.991,
      "step": 7700
    },
    {
      "epoch": 15.766871165644172,
      "grad_norm": 3.2911672592163086,
      "learning_rate": 8.425444876252812e-05,
      "loss": 0.4634,
      "step": 7710
    },
    {
      "epoch": 15.787321063394684,
      "grad_norm": 2.2626802921295166,
      "learning_rate": 8.423399468193906e-05,
      "loss": 0.4106,
      "step": 7720
    },
    {
      "epoch": 15.807770961145195,
      "grad_norm": 3.6775712966918945,
      "learning_rate": 8.421354060134997e-05,
      "loss": 0.4018,
      "step": 7730
    },
    {
      "epoch": 15.828220858895705,
      "grad_norm": 5.015663146972656,
      "learning_rate": 8.41930865207609e-05,
      "loss": 0.3889,
      "step": 7740
    },
    {
      "epoch": 15.848670756646216,
      "grad_norm": 2.537738561630249,
      "learning_rate": 8.417263244017181e-05,
      "loss": 0.4196,
      "step": 7750
    },
    {
      "epoch": 15.869120654396728,
      "grad_norm": 4.860976219177246,
      "learning_rate": 8.415217835958275e-05,
      "loss": 0.4375,
      "step": 7760
    },
    {
      "epoch": 15.889570552147239,
      "grad_norm": 4.687358856201172,
      "learning_rate": 8.413172427899366e-05,
      "loss": 0.4498,
      "step": 7770
    },
    {
      "epoch": 15.91002044989775,
      "grad_norm": 2.3970882892608643,
      "learning_rate": 8.411127019840459e-05,
      "loss": 0.4488,
      "step": 7780
    },
    {
      "epoch": 15.930470347648262,
      "grad_norm": 3.8675053119659424,
      "learning_rate": 8.40908161178155e-05,
      "loss": 0.4545,
      "step": 7790
    },
    {
      "epoch": 15.950920245398773,
      "grad_norm": 3.8295860290527344,
      "learning_rate": 8.407036203722644e-05,
      "loss": 0.4966,
      "step": 7800
    },
    {
      "epoch": 15.950920245398773,
      "eval_loss": 2.753783702850342,
      "eval_runtime": 27.3241,
      "eval_samples_per_second": 11.784,
      "eval_steps_per_second": 0.988,
      "step": 7800
    },
    {
      "epoch": 15.971370143149285,
      "grad_norm": 3.276057720184326,
      "learning_rate": 8.404990795663735e-05,
      "loss": 0.4515,
      "step": 7810
    },
    {
      "epoch": 15.991820040899796,
      "grad_norm": 5.456321716308594,
      "learning_rate": 8.402945387604828e-05,
      "loss": 0.4386,
      "step": 7820
    },
    {
      "epoch": 16.012269938650306,
      "grad_norm": 4.040839195251465,
      "learning_rate": 8.40089997954592e-05,
      "loss": 0.3929,
      "step": 7830
    },
    {
      "epoch": 16.03271983640082,
      "grad_norm": 3.167917251586914,
      "learning_rate": 8.398854571487013e-05,
      "loss": 0.4079,
      "step": 7840
    },
    {
      "epoch": 16.05316973415133,
      "grad_norm": 4.165860176086426,
      "learning_rate": 8.396809163428105e-05,
      "loss": 0.4082,
      "step": 7850
    },
    {
      "epoch": 16.073619631901842,
      "grad_norm": 2.533890962600708,
      "learning_rate": 8.394763755369196e-05,
      "loss": 0.3921,
      "step": 7860
    },
    {
      "epoch": 16.09406952965235,
      "grad_norm": 4.5262227058410645,
      "learning_rate": 8.392718347310289e-05,
      "loss": 0.39,
      "step": 7870
    },
    {
      "epoch": 16.114519427402865,
      "grad_norm": 4.606950759887695,
      "learning_rate": 8.39067293925138e-05,
      "loss": 0.3753,
      "step": 7880
    },
    {
      "epoch": 16.134969325153374,
      "grad_norm": 3.0105669498443604,
      "learning_rate": 8.388627531192474e-05,
      "loss": 0.3716,
      "step": 7890
    },
    {
      "epoch": 16.155419222903884,
      "grad_norm": 5.75258731842041,
      "learning_rate": 8.386582123133564e-05,
      "loss": 0.361,
      "step": 7900
    },
    {
      "epoch": 16.155419222903884,
      "eval_loss": 2.878964424133301,
      "eval_runtime": 27.2488,
      "eval_samples_per_second": 11.817,
      "eval_steps_per_second": 0.991,
      "step": 7900
    },
    {
      "epoch": 16.175869120654397,
      "grad_norm": 3.0391674041748047,
      "learning_rate": 8.384536715074658e-05,
      "loss": 0.4008,
      "step": 7910
    },
    {
      "epoch": 16.196319018404907,
      "grad_norm": 4.078560829162598,
      "learning_rate": 8.382491307015749e-05,
      "loss": 0.3541,
      "step": 7920
    },
    {
      "epoch": 16.21676891615542,
      "grad_norm": 4.432421684265137,
      "learning_rate": 8.380445898956842e-05,
      "loss": 0.4019,
      "step": 7930
    },
    {
      "epoch": 16.23721881390593,
      "grad_norm": 2.407322406768799,
      "learning_rate": 8.378400490897935e-05,
      "loss": 0.3857,
      "step": 7940
    },
    {
      "epoch": 16.257668711656443,
      "grad_norm": 3.1650702953338623,
      "learning_rate": 8.376355082839027e-05,
      "loss": 0.3569,
      "step": 7950
    },
    {
      "epoch": 16.278118609406953,
      "grad_norm": 2.7961130142211914,
      "learning_rate": 8.374309674780119e-05,
      "loss": 0.3591,
      "step": 7960
    },
    {
      "epoch": 16.298568507157466,
      "grad_norm": 4.970595836639404,
      "learning_rate": 8.372264266721211e-05,
      "loss": 0.3722,
      "step": 7970
    },
    {
      "epoch": 16.319018404907975,
      "grad_norm": 2.5399670600891113,
      "learning_rate": 8.370218858662304e-05,
      "loss": 0.3888,
      "step": 7980
    },
    {
      "epoch": 16.339468302658485,
      "grad_norm": 2.387382745742798,
      "learning_rate": 8.368173450603396e-05,
      "loss": 0.4102,
      "step": 7990
    },
    {
      "epoch": 16.359918200409,
      "grad_norm": 4.1817946434021,
      "learning_rate": 8.366128042544488e-05,
      "loss": 0.3917,
      "step": 8000
    },
    {
      "epoch": 16.359918200409,
      "eval_loss": 2.83447527885437,
      "eval_runtime": 27.2208,
      "eval_samples_per_second": 11.829,
      "eval_steps_per_second": 0.992,
      "step": 8000
    },
    {
      "epoch": 16.380368098159508,
      "grad_norm": 5.392812252044678,
      "learning_rate": 8.36408263448558e-05,
      "loss": 0.4038,
      "step": 8010
    },
    {
      "epoch": 16.40081799591002,
      "grad_norm": 2.954660415649414,
      "learning_rate": 8.362037226426672e-05,
      "loss": 0.3785,
      "step": 8020
    },
    {
      "epoch": 16.42126789366053,
      "grad_norm": 2.729663133621216,
      "learning_rate": 8.359991818367765e-05,
      "loss": 0.3918,
      "step": 8030
    },
    {
      "epoch": 16.441717791411044,
      "grad_norm": 3.834346055984497,
      "learning_rate": 8.357946410308857e-05,
      "loss": 0.357,
      "step": 8040
    },
    {
      "epoch": 16.462167689161554,
      "grad_norm": 2.699495315551758,
      "learning_rate": 8.355901002249949e-05,
      "loss": 0.3813,
      "step": 8050
    },
    {
      "epoch": 16.482617586912067,
      "grad_norm": 3.526156187057495,
      "learning_rate": 8.353855594191041e-05,
      "loss": 0.4168,
      "step": 8060
    },
    {
      "epoch": 16.503067484662576,
      "grad_norm": 6.247732162475586,
      "learning_rate": 8.351810186132133e-05,
      "loss": 0.4197,
      "step": 8070
    },
    {
      "epoch": 16.52351738241309,
      "grad_norm": 5.354669570922852,
      "learning_rate": 8.349764778073226e-05,
      "loss": 0.4076,
      "step": 8080
    },
    {
      "epoch": 16.5439672801636,
      "grad_norm": 2.3473386764526367,
      "learning_rate": 8.347719370014319e-05,
      "loss": 0.4061,
      "step": 8090
    },
    {
      "epoch": 16.56441717791411,
      "grad_norm": 4.838039398193359,
      "learning_rate": 8.34567396195541e-05,
      "loss": 0.437,
      "step": 8100
    },
    {
      "epoch": 16.56441717791411,
      "eval_loss": 2.8817296028137207,
      "eval_runtime": 27.2087,
      "eval_samples_per_second": 11.834,
      "eval_steps_per_second": 0.992,
      "step": 8100
    },
    {
      "epoch": 16.584867075664622,
      "grad_norm": 3.203141927719116,
      "learning_rate": 8.343628553896504e-05,
      "loss": 0.3609,
      "step": 8110
    },
    {
      "epoch": 16.605316973415132,
      "grad_norm": 3.721947431564331,
      "learning_rate": 8.341583145837595e-05,
      "loss": 0.4148,
      "step": 8120
    },
    {
      "epoch": 16.625766871165645,
      "grad_norm": 2.905344247817993,
      "learning_rate": 8.339537737778688e-05,
      "loss": 0.3848,
      "step": 8130
    },
    {
      "epoch": 16.646216768916155,
      "grad_norm": 2.6096951961517334,
      "learning_rate": 8.337492329719779e-05,
      "loss": 0.3861,
      "step": 8140
    },
    {
      "epoch": 16.666666666666668,
      "grad_norm": 4.898407459259033,
      "learning_rate": 8.335446921660873e-05,
      "loss": 0.4519,
      "step": 8150
    },
    {
      "epoch": 16.687116564417177,
      "grad_norm": 2.834608316421509,
      "learning_rate": 8.333401513601963e-05,
      "loss": 0.3899,
      "step": 8160
    },
    {
      "epoch": 16.70756646216769,
      "grad_norm": 3.890069007873535,
      "learning_rate": 8.331356105543057e-05,
      "loss": 0.4388,
      "step": 8170
    },
    {
      "epoch": 16.7280163599182,
      "grad_norm": 3.2157678604125977,
      "learning_rate": 8.329515238290039e-05,
      "loss": 0.3918,
      "step": 8180
    },
    {
      "epoch": 16.74846625766871,
      "grad_norm": 5.122617244720459,
      "learning_rate": 8.327469830231131e-05,
      "loss": 0.4146,
      "step": 8190
    },
    {
      "epoch": 16.768916155419223,
      "grad_norm": 4.109670639038086,
      "learning_rate": 8.325424422172223e-05,
      "loss": 0.4003,
      "step": 8200
    },
    {
      "epoch": 16.768916155419223,
      "eval_loss": 2.8017642498016357,
      "eval_runtime": 27.1676,
      "eval_samples_per_second": 11.852,
      "eval_steps_per_second": 0.994,
      "step": 8200
    },
    {
      "epoch": 16.789366053169733,
      "grad_norm": 4.53236722946167,
      "learning_rate": 8.323379014113317e-05,
      "loss": 0.4706,
      "step": 8210
    },
    {
      "epoch": 16.809815950920246,
      "grad_norm": 3.308187484741211,
      "learning_rate": 8.321333606054408e-05,
      "loss": 0.4535,
      "step": 8220
    },
    {
      "epoch": 16.830265848670756,
      "grad_norm": 2.4602198600769043,
      "learning_rate": 8.319288197995501e-05,
      "loss": 0.4332,
      "step": 8230
    },
    {
      "epoch": 16.85071574642127,
      "grad_norm": 5.567054271697998,
      "learning_rate": 8.317242789936592e-05,
      "loss": 0.4342,
      "step": 8240
    },
    {
      "epoch": 16.87116564417178,
      "grad_norm": 3.383327007293701,
      "learning_rate": 8.315197381877686e-05,
      "loss": 0.4509,
      "step": 8250
    },
    {
      "epoch": 16.89161554192229,
      "grad_norm": 5.244418144226074,
      "learning_rate": 8.313151973818776e-05,
      "loss": 0.4097,
      "step": 8260
    },
    {
      "epoch": 16.9120654396728,
      "grad_norm": 2.888148784637451,
      "learning_rate": 8.31110656575987e-05,
      "loss": 0.4209,
      "step": 8270
    },
    {
      "epoch": 16.93251533742331,
      "grad_norm": 2.8597137928009033,
      "learning_rate": 8.309061157700961e-05,
      "loss": 0.4272,
      "step": 8280
    },
    {
      "epoch": 16.952965235173824,
      "grad_norm": 4.0997114181518555,
      "learning_rate": 8.307015749642054e-05,
      "loss": 0.4643,
      "step": 8290
    },
    {
      "epoch": 16.973415132924334,
      "grad_norm": 4.514531135559082,
      "learning_rate": 8.304970341583145e-05,
      "loss": 0.4693,
      "step": 8300
    },
    {
      "epoch": 16.973415132924334,
      "eval_loss": 2.8321690559387207,
      "eval_runtime": 27.2463,
      "eval_samples_per_second": 11.818,
      "eval_steps_per_second": 0.991,
      "step": 8300
    },
    {
      "epoch": 16.993865030674847,
      "grad_norm": 2.4257302284240723,
      "learning_rate": 8.302924933524239e-05,
      "loss": 0.4136,
      "step": 8310
    },
    {
      "epoch": 17.014314928425357,
      "grad_norm": 2.2438724040985107,
      "learning_rate": 8.300879525465331e-05,
      "loss": 0.3574,
      "step": 8320
    },
    {
      "epoch": 17.03476482617587,
      "grad_norm": 3.4831225872039795,
      "learning_rate": 8.298834117406423e-05,
      "loss": 0.3487,
      "step": 8330
    },
    {
      "epoch": 17.05521472392638,
      "grad_norm": 1.8840266466140747,
      "learning_rate": 8.296788709347515e-05,
      "loss": 0.361,
      "step": 8340
    },
    {
      "epoch": 17.075664621676893,
      "grad_norm": 3.717007875442505,
      "learning_rate": 8.294743301288608e-05,
      "loss": 0.401,
      "step": 8350
    },
    {
      "epoch": 17.096114519427402,
      "grad_norm": 3.423543930053711,
      "learning_rate": 8.2926978932297e-05,
      "loss": 0.411,
      "step": 8360
    },
    {
      "epoch": 17.116564417177916,
      "grad_norm": 2.526975631713867,
      "learning_rate": 8.290652485170792e-05,
      "loss": 0.3611,
      "step": 8370
    },
    {
      "epoch": 17.137014314928425,
      "grad_norm": 4.102063179016113,
      "learning_rate": 8.288607077111884e-05,
      "loss": 0.3791,
      "step": 8380
    },
    {
      "epoch": 17.157464212678935,
      "grad_norm": 2.974729537963867,
      "learning_rate": 8.286561669052977e-05,
      "loss": 0.3674,
      "step": 8390
    },
    {
      "epoch": 17.177914110429448,
      "grad_norm": 3.145843267440796,
      "learning_rate": 8.284516260994069e-05,
      "loss": 0.3565,
      "step": 8400
    },
    {
      "epoch": 17.177914110429448,
      "eval_loss": 2.9001379013061523,
      "eval_runtime": 27.2266,
      "eval_samples_per_second": 11.827,
      "eval_steps_per_second": 0.992,
      "step": 8400
    },
    {
      "epoch": 17.198364008179958,
      "grad_norm": 4.848390102386475,
      "learning_rate": 8.282470852935161e-05,
      "loss": 0.3655,
      "step": 8410
    },
    {
      "epoch": 17.21881390593047,
      "grad_norm": 3.579444408416748,
      "learning_rate": 8.280425444876253e-05,
      "loss": 0.3592,
      "step": 8420
    },
    {
      "epoch": 17.23926380368098,
      "grad_norm": 2.2921149730682373,
      "learning_rate": 8.278380036817345e-05,
      "loss": 0.384,
      "step": 8430
    },
    {
      "epoch": 17.259713701431494,
      "grad_norm": 3.0673251152038574,
      "learning_rate": 8.276334628758438e-05,
      "loss": 0.3781,
      "step": 8440
    },
    {
      "epoch": 17.280163599182004,
      "grad_norm": 2.085465431213379,
      "learning_rate": 8.27428922069953e-05,
      "loss": 0.3838,
      "step": 8450
    },
    {
      "epoch": 17.300613496932517,
      "grad_norm": 3.238206624984741,
      "learning_rate": 8.272243812640622e-05,
      "loss": 0.369,
      "step": 8460
    },
    {
      "epoch": 17.321063394683026,
      "grad_norm": 2.5731828212738037,
      "learning_rate": 8.270198404581716e-05,
      "loss": 0.372,
      "step": 8470
    },
    {
      "epoch": 17.34151329243354,
      "grad_norm": 2.929643154144287,
      "learning_rate": 8.268152996522806e-05,
      "loss": 0.3839,
      "step": 8480
    },
    {
      "epoch": 17.36196319018405,
      "grad_norm": 3.9623055458068848,
      "learning_rate": 8.2661075884639e-05,
      "loss": 0.3833,
      "step": 8490
    },
    {
      "epoch": 17.38241308793456,
      "grad_norm": 4.58570671081543,
      "learning_rate": 8.264062180404991e-05,
      "loss": 0.3797,
      "step": 8500
    },
    {
      "epoch": 17.38241308793456,
      "eval_loss": 2.890471935272217,
      "eval_runtime": 27.3465,
      "eval_samples_per_second": 11.775,
      "eval_steps_per_second": 0.987,
      "step": 8500
    },
    {
      "epoch": 17.402862985685072,
      "grad_norm": 2.642566204071045,
      "learning_rate": 8.262016772346084e-05,
      "loss": 0.3718,
      "step": 8510
    },
    {
      "epoch": 17.42331288343558,
      "grad_norm": 4.34605073928833,
      "learning_rate": 8.259971364287175e-05,
      "loss": 0.4155,
      "step": 8520
    },
    {
      "epoch": 17.443762781186095,
      "grad_norm": 2.7282209396362305,
      "learning_rate": 8.257925956228269e-05,
      "loss": 0.3771,
      "step": 8530
    },
    {
      "epoch": 17.464212678936605,
      "grad_norm": 2.659884214401245,
      "learning_rate": 8.25588054816936e-05,
      "loss": 0.3999,
      "step": 8540
    },
    {
      "epoch": 17.484662576687118,
      "grad_norm": 4.546421051025391,
      "learning_rate": 8.253835140110452e-05,
      "loss": 0.4088,
      "step": 8550
    },
    {
      "epoch": 17.505112474437627,
      "grad_norm": 3.3192343711853027,
      "learning_rate": 8.251789732051544e-05,
      "loss": 0.3657,
      "step": 8560
    },
    {
      "epoch": 17.52556237218814,
      "grad_norm": 6.202864646911621,
      "learning_rate": 8.249744323992636e-05,
      "loss": 0.3695,
      "step": 8570
    },
    {
      "epoch": 17.54601226993865,
      "grad_norm": 3.3775453567504883,
      "learning_rate": 8.24769891593373e-05,
      "loss": 0.3666,
      "step": 8580
    },
    {
      "epoch": 17.56646216768916,
      "grad_norm": 3.210878372192383,
      "learning_rate": 8.245653507874821e-05,
      "loss": 0.4103,
      "step": 8590
    },
    {
      "epoch": 17.586912065439673,
      "grad_norm": 3.2354187965393066,
      "learning_rate": 8.243608099815914e-05,
      "loss": 0.3632,
      "step": 8600
    },
    {
      "epoch": 17.586912065439673,
      "eval_loss": 2.8915321826934814,
      "eval_runtime": 27.5444,
      "eval_samples_per_second": 11.69,
      "eval_steps_per_second": 0.98,
      "step": 8600
    },
    {
      "epoch": 17.607361963190183,
      "grad_norm": 3.4946939945220947,
      "learning_rate": 8.241562691757005e-05,
      "loss": 0.3748,
      "step": 8610
    },
    {
      "epoch": 17.627811860940696,
      "grad_norm": 3.511120557785034,
      "learning_rate": 8.239517283698099e-05,
      "loss": 0.4196,
      "step": 8620
    },
    {
      "epoch": 17.648261758691206,
      "grad_norm": 4.821274757385254,
      "learning_rate": 8.23747187563919e-05,
      "loss": 0.408,
      "step": 8630
    },
    {
      "epoch": 17.66871165644172,
      "grad_norm": 3.8432271480560303,
      "learning_rate": 8.235426467580283e-05,
      "loss": 0.4067,
      "step": 8640
    },
    {
      "epoch": 17.68916155419223,
      "grad_norm": 3.7526566982269287,
      "learning_rate": 8.233381059521374e-05,
      "loss": 0.4482,
      "step": 8650
    },
    {
      "epoch": 17.70961145194274,
      "grad_norm": 3.256673812866211,
      "learning_rate": 8.231335651462468e-05,
      "loss": 0.375,
      "step": 8660
    },
    {
      "epoch": 17.73006134969325,
      "grad_norm": 3.1590919494628906,
      "learning_rate": 8.229290243403558e-05,
      "loss": 0.4013,
      "step": 8670
    },
    {
      "epoch": 17.75051124744376,
      "grad_norm": 4.091094017028809,
      "learning_rate": 8.227244835344652e-05,
      "loss": 0.4035,
      "step": 8680
    },
    {
      "epoch": 17.770961145194274,
      "grad_norm": 3.060572862625122,
      "learning_rate": 8.225199427285744e-05,
      "loss": 0.3839,
      "step": 8690
    },
    {
      "epoch": 17.791411042944784,
      "grad_norm": 4.792555332183838,
      "learning_rate": 8.223154019226836e-05,
      "loss": 0.3965,
      "step": 8700
    },
    {
      "epoch": 17.791411042944784,
      "eval_loss": 2.881690502166748,
      "eval_runtime": 27.3776,
      "eval_samples_per_second": 11.761,
      "eval_steps_per_second": 0.986,
      "step": 8700
    },
    {
      "epoch": 17.811860940695297,
      "grad_norm": 5.587008476257324,
      "learning_rate": 8.221108611167929e-05,
      "loss": 0.3746,
      "step": 8710
    },
    {
      "epoch": 17.832310838445807,
      "grad_norm": 3.2158396244049072,
      "learning_rate": 8.219063203109021e-05,
      "loss": 0.3892,
      "step": 8720
    },
    {
      "epoch": 17.85276073619632,
      "grad_norm": 3.016098737716675,
      "learning_rate": 8.217017795050113e-05,
      "loss": 0.4216,
      "step": 8730
    },
    {
      "epoch": 17.87321063394683,
      "grad_norm": 2.565152168273926,
      "learning_rate": 8.214972386991205e-05,
      "loss": 0.3961,
      "step": 8740
    },
    {
      "epoch": 17.893660531697343,
      "grad_norm": 4.17725944519043,
      "learning_rate": 8.212926978932297e-05,
      "loss": 0.3654,
      "step": 8750
    },
    {
      "epoch": 17.914110429447852,
      "grad_norm": 3.1852638721466064,
      "learning_rate": 8.21088157087339e-05,
      "loss": 0.3898,
      "step": 8760
    },
    {
      "epoch": 17.934560327198366,
      "grad_norm": 3.6141700744628906,
      "learning_rate": 8.208836162814482e-05,
      "loss": 0.4237,
      "step": 8770
    },
    {
      "epoch": 17.955010224948875,
      "grad_norm": 4.227231025695801,
      "learning_rate": 8.206790754755574e-05,
      "loss": 0.4043,
      "step": 8780
    },
    {
      "epoch": 17.975460122699385,
      "grad_norm": 3.92105770111084,
      "learning_rate": 8.204745346696666e-05,
      "loss": 0.3927,
      "step": 8790
    },
    {
      "epoch": 17.995910020449898,
      "grad_norm": 5.978156566619873,
      "learning_rate": 8.202699938637759e-05,
      "loss": 0.4059,
      "step": 8800
    },
    {
      "epoch": 17.995910020449898,
      "eval_loss": 2.8730216026306152,
      "eval_runtime": 27.1916,
      "eval_samples_per_second": 11.842,
      "eval_steps_per_second": 0.993,
      "step": 8800
    },
    {
      "epoch": 18.016359918200408,
      "grad_norm": 3.808042526245117,
      "learning_rate": 8.200654530578851e-05,
      "loss": 0.3306,
      "step": 8810
    },
    {
      "epoch": 18.03680981595092,
      "grad_norm": 3.1546554565429688,
      "learning_rate": 8.198609122519943e-05,
      "loss": 0.3436,
      "step": 8820
    },
    {
      "epoch": 18.05725971370143,
      "grad_norm": 2.645404815673828,
      "learning_rate": 8.196563714461035e-05,
      "loss": 0.3232,
      "step": 8830
    },
    {
      "epoch": 18.077709611451944,
      "grad_norm": 3.9639313220977783,
      "learning_rate": 8.194518306402127e-05,
      "loss": 0.3857,
      "step": 8840
    },
    {
      "epoch": 18.098159509202453,
      "grad_norm": 2.8235833644866943,
      "learning_rate": 8.19247289834322e-05,
      "loss": 0.3627,
      "step": 8850
    },
    {
      "epoch": 18.118609406952967,
      "grad_norm": 3.726335287094116,
      "learning_rate": 8.190427490284313e-05,
      "loss": 0.3714,
      "step": 8860
    },
    {
      "epoch": 18.139059304703476,
      "grad_norm": 5.788264274597168,
      "learning_rate": 8.188382082225404e-05,
      "loss": 0.3736,
      "step": 8870
    },
    {
      "epoch": 18.15950920245399,
      "grad_norm": 2.305901527404785,
      "learning_rate": 8.186336674166498e-05,
      "loss": 0.3494,
      "step": 8880
    },
    {
      "epoch": 18.1799591002045,
      "grad_norm": 3.734731435775757,
      "learning_rate": 8.184291266107588e-05,
      "loss": 0.3457,
      "step": 8890
    },
    {
      "epoch": 18.20040899795501,
      "grad_norm": 2.6746528148651123,
      "learning_rate": 8.182245858048682e-05,
      "loss": 0.3613,
      "step": 8900
    },
    {
      "epoch": 18.20040899795501,
      "eval_loss": 2.9369993209838867,
      "eval_runtime": 27.1996,
      "eval_samples_per_second": 11.838,
      "eval_steps_per_second": 0.993,
      "step": 8900
    },
    {
      "epoch": 18.220858895705522,
      "grad_norm": 2.6414008140563965,
      "learning_rate": 8.180200449989773e-05,
      "loss": 0.3393,
      "step": 8910
    },
    {
      "epoch": 18.24130879345603,
      "grad_norm": 2.6569037437438965,
      "learning_rate": 8.178155041930866e-05,
      "loss": 0.3706,
      "step": 8920
    },
    {
      "epoch": 18.261758691206545,
      "grad_norm": 2.1832492351531982,
      "learning_rate": 8.176109633871957e-05,
      "loss": 0.3743,
      "step": 8930
    },
    {
      "epoch": 18.282208588957054,
      "grad_norm": 3.6482224464416504,
      "learning_rate": 8.174064225813051e-05,
      "loss": 0.3777,
      "step": 8940
    },
    {
      "epoch": 18.302658486707568,
      "grad_norm": 5.266613483428955,
      "learning_rate": 8.172018817754142e-05,
      "loss": 0.3669,
      "step": 8950
    },
    {
      "epoch": 18.323108384458077,
      "grad_norm": 3.72269344329834,
      "learning_rate": 8.169973409695234e-05,
      "loss": 0.3751,
      "step": 8960
    },
    {
      "epoch": 18.34355828220859,
      "grad_norm": 2.1486148834228516,
      "learning_rate": 8.167928001636327e-05,
      "loss": 0.386,
      "step": 8970
    },
    {
      "epoch": 18.3640081799591,
      "grad_norm": 2.3902101516723633,
      "learning_rate": 8.165882593577418e-05,
      "loss": 0.3699,
      "step": 8980
    },
    {
      "epoch": 18.38445807770961,
      "grad_norm": 4.04072904586792,
      "learning_rate": 8.163837185518512e-05,
      "loss": 0.3786,
      "step": 8990
    },
    {
      "epoch": 18.404907975460123,
      "grad_norm": 3.1429965496063232,
      "learning_rate": 8.161791777459603e-05,
      "loss": 0.3567,
      "step": 9000
    },
    {
      "epoch": 18.404907975460123,
      "eval_loss": 2.937760829925537,
      "eval_runtime": 27.2217,
      "eval_samples_per_second": 11.829,
      "eval_steps_per_second": 0.992,
      "step": 9000
    },
    {
      "epoch": 18.425357873210633,
      "grad_norm": 3.1713907718658447,
      "learning_rate": 8.159746369400696e-05,
      "loss": 0.3832,
      "step": 9010
    },
    {
      "epoch": 18.445807770961146,
      "grad_norm": 2.833676815032959,
      "learning_rate": 8.157700961341787e-05,
      "loss": 0.3619,
      "step": 9020
    },
    {
      "epoch": 18.466257668711656,
      "grad_norm": 2.943326234817505,
      "learning_rate": 8.155655553282881e-05,
      "loss": 0.359,
      "step": 9030
    },
    {
      "epoch": 18.48670756646217,
      "grad_norm": 2.7783572673797607,
      "learning_rate": 8.153610145223972e-05,
      "loss": 0.3742,
      "step": 9040
    },
    {
      "epoch": 18.50715746421268,
      "grad_norm": 2.992868661880493,
      "learning_rate": 8.151564737165065e-05,
      "loss": 0.3652,
      "step": 9050
    },
    {
      "epoch": 18.52760736196319,
      "grad_norm": 2.9994850158691406,
      "learning_rate": 8.149519329106156e-05,
      "loss": 0.4069,
      "step": 9060
    },
    {
      "epoch": 18.5480572597137,
      "grad_norm": 3.2950704097747803,
      "learning_rate": 8.14747392104725e-05,
      "loss": 0.3873,
      "step": 9070
    },
    {
      "epoch": 18.56850715746421,
      "grad_norm": 2.4036755561828613,
      "learning_rate": 8.145428512988342e-05,
      "loss": 0.3578,
      "step": 9080
    },
    {
      "epoch": 18.588957055214724,
      "grad_norm": 4.970525741577148,
      "learning_rate": 8.143383104929434e-05,
      "loss": 0.3871,
      "step": 9090
    },
    {
      "epoch": 18.609406952965234,
      "grad_norm": 3.1466472148895264,
      "learning_rate": 8.141337696870526e-05,
      "loss": 0.3746,
      "step": 9100
    },
    {
      "epoch": 18.609406952965234,
      "eval_loss": 2.9046905040740967,
      "eval_runtime": 27.2098,
      "eval_samples_per_second": 11.834,
      "eval_steps_per_second": 0.992,
      "step": 9100
    },
    {
      "epoch": 18.629856850715747,
      "grad_norm": 2.804387331008911,
      "learning_rate": 8.139292288811618e-05,
      "loss": 0.3753,
      "step": 9110
    },
    {
      "epoch": 18.650306748466257,
      "grad_norm": 1.9836775064468384,
      "learning_rate": 8.13724688075271e-05,
      "loss": 0.3665,
      "step": 9120
    },
    {
      "epoch": 18.67075664621677,
      "grad_norm": 3.3944215774536133,
      "learning_rate": 8.135201472693803e-05,
      "loss": 0.3526,
      "step": 9130
    },
    {
      "epoch": 18.69120654396728,
      "grad_norm": 3.447248935699463,
      "learning_rate": 8.133156064634895e-05,
      "loss": 0.3984,
      "step": 9140
    },
    {
      "epoch": 18.711656441717793,
      "grad_norm": 2.5696897506713867,
      "learning_rate": 8.131110656575987e-05,
      "loss": 0.3632,
      "step": 9150
    },
    {
      "epoch": 18.732106339468302,
      "grad_norm": 3.156055212020874,
      "learning_rate": 8.12906524851708e-05,
      "loss": 0.4154,
      "step": 9160
    },
    {
      "epoch": 18.752556237218815,
      "grad_norm": 3.053929567337036,
      "learning_rate": 8.127019840458172e-05,
      "loss": 0.379,
      "step": 9170
    },
    {
      "epoch": 18.773006134969325,
      "grad_norm": 3.5505175590515137,
      "learning_rate": 8.124974432399264e-05,
      "loss": 0.3468,
      "step": 9180
    },
    {
      "epoch": 18.793456032719835,
      "grad_norm": 2.5365772247314453,
      "learning_rate": 8.122929024340356e-05,
      "loss": 0.3774,
      "step": 9190
    },
    {
      "epoch": 18.813905930470348,
      "grad_norm": 3.255019187927246,
      "learning_rate": 8.120883616281448e-05,
      "loss": 0.3693,
      "step": 9200
    },
    {
      "epoch": 18.813905930470348,
      "eval_loss": 2.944803237915039,
      "eval_runtime": 27.2093,
      "eval_samples_per_second": 11.834,
      "eval_steps_per_second": 0.992,
      "step": 9200
    },
    {
      "epoch": 18.834355828220858,
      "grad_norm": 4.023104667663574,
      "learning_rate": 8.11883820822254e-05,
      "loss": 0.3693,
      "step": 9210
    },
    {
      "epoch": 18.85480572597137,
      "grad_norm": 3.3802740573883057,
      "learning_rate": 8.116792800163633e-05,
      "loss": 0.4005,
      "step": 9220
    },
    {
      "epoch": 18.87525562372188,
      "grad_norm": 3.0998902320861816,
      "learning_rate": 8.114747392104725e-05,
      "loss": 0.4074,
      "step": 9230
    },
    {
      "epoch": 18.895705521472394,
      "grad_norm": 3.518167018890381,
      "learning_rate": 8.112701984045817e-05,
      "loss": 0.3671,
      "step": 9240
    },
    {
      "epoch": 18.916155419222903,
      "grad_norm": 2.563084840774536,
      "learning_rate": 8.110656575986911e-05,
      "loss": 0.3799,
      "step": 9250
    },
    {
      "epoch": 18.936605316973417,
      "grad_norm": 2.7742388248443604,
      "learning_rate": 8.108611167928002e-05,
      "loss": 0.3819,
      "step": 9260
    },
    {
      "epoch": 18.957055214723926,
      "grad_norm": 3.4002785682678223,
      "learning_rate": 8.106565759869095e-05,
      "loss": 0.393,
      "step": 9270
    },
    {
      "epoch": 18.97750511247444,
      "grad_norm": 2.270552396774292,
      "learning_rate": 8.104520351810186e-05,
      "loss": 0.4134,
      "step": 9280
    },
    {
      "epoch": 18.99795501022495,
      "grad_norm": 3.805833101272583,
      "learning_rate": 8.10247494375128e-05,
      "loss": 0.3911,
      "step": 9290
    },
    {
      "epoch": 19.01840490797546,
      "grad_norm": 2.797945022583008,
      "learning_rate": 8.10042953569237e-05,
      "loss": 0.3433,
      "step": 9300
    },
    {
      "epoch": 19.01840490797546,
      "eval_loss": 3.056678056716919,
      "eval_runtime": 27.235,
      "eval_samples_per_second": 11.823,
      "eval_steps_per_second": 0.991,
      "step": 9300
    },
    {
      "epoch": 19.038854805725972,
      "grad_norm": 2.588709592819214,
      "learning_rate": 8.098384127633464e-05,
      "loss": 0.3306,
      "step": 9310
    },
    {
      "epoch": 19.05930470347648,
      "grad_norm": 2.126596689224243,
      "learning_rate": 8.096338719574555e-05,
      "loss": 0.354,
      "step": 9320
    },
    {
      "epoch": 19.079754601226995,
      "grad_norm": 2.882093667984009,
      "learning_rate": 8.094293311515648e-05,
      "loss": 0.3289,
      "step": 9330
    },
    {
      "epoch": 19.100204498977504,
      "grad_norm": 2.1548690795898438,
      "learning_rate": 8.09224790345674e-05,
      "loss": 0.3549,
      "step": 9340
    },
    {
      "epoch": 19.120654396728018,
      "grad_norm": 4.636746883392334,
      "learning_rate": 8.090202495397832e-05,
      "loss": 0.3465,
      "step": 9350
    },
    {
      "epoch": 19.141104294478527,
      "grad_norm": 2.254545211791992,
      "learning_rate": 8.088157087338925e-05,
      "loss": 0.3174,
      "step": 9360
    },
    {
      "epoch": 19.16155419222904,
      "grad_norm": 4.405336380004883,
      "learning_rate": 8.086111679280016e-05,
      "loss": 0.3495,
      "step": 9370
    },
    {
      "epoch": 19.18200408997955,
      "grad_norm": 3.3665170669555664,
      "learning_rate": 8.08406627122111e-05,
      "loss": 0.3403,
      "step": 9380
    },
    {
      "epoch": 19.20245398773006,
      "grad_norm": 3.1899521350860596,
      "learning_rate": 8.0820208631622e-05,
      "loss": 0.3567,
      "step": 9390
    },
    {
      "epoch": 19.222903885480573,
      "grad_norm": 2.2003045082092285,
      "learning_rate": 8.079975455103294e-05,
      "loss": 0.3623,
      "step": 9400
    },
    {
      "epoch": 19.222903885480573,
      "eval_loss": 3.0505824089050293,
      "eval_runtime": 27.2455,
      "eval_samples_per_second": 11.818,
      "eval_steps_per_second": 0.991,
      "step": 9400
    },
    {
      "epoch": 19.243353783231083,
      "grad_norm": 3.111858367919922,
      "learning_rate": 8.077930047044385e-05,
      "loss": 0.3467,
      "step": 9410
    },
    {
      "epoch": 19.263803680981596,
      "grad_norm": 4.031261920928955,
      "learning_rate": 8.075884638985478e-05,
      "loss": 0.3813,
      "step": 9420
    },
    {
      "epoch": 19.284253578732105,
      "grad_norm": 2.9497151374816895,
      "learning_rate": 8.073839230926569e-05,
      "loss": 0.3617,
      "step": 9430
    },
    {
      "epoch": 19.30470347648262,
      "grad_norm": 2.52103590965271,
      "learning_rate": 8.071793822867663e-05,
      "loss": 0.3646,
      "step": 9440
    },
    {
      "epoch": 19.32515337423313,
      "grad_norm": 2.4383389949798584,
      "learning_rate": 8.069748414808754e-05,
      "loss": 0.3471,
      "step": 9450
    },
    {
      "epoch": 19.34560327198364,
      "grad_norm": 2.4915454387664795,
      "learning_rate": 8.067703006749847e-05,
      "loss": 0.3262,
      "step": 9460
    },
    {
      "epoch": 19.36605316973415,
      "grad_norm": 2.2771105766296387,
      "learning_rate": 8.06565759869094e-05,
      "loss": 0.3503,
      "step": 9470
    },
    {
      "epoch": 19.38650306748466,
      "grad_norm": 2.4494268894195557,
      "learning_rate": 8.063612190632032e-05,
      "loss": 0.3506,
      "step": 9480
    },
    {
      "epoch": 19.406952965235174,
      "grad_norm": 3.8348042964935303,
      "learning_rate": 8.061566782573124e-05,
      "loss": 0.3431,
      "step": 9490
    },
    {
      "epoch": 19.427402862985684,
      "grad_norm": 5.130831718444824,
      "learning_rate": 8.059521374514216e-05,
      "loss": 0.3361,
      "step": 9500
    },
    {
      "epoch": 19.427402862985684,
      "eval_loss": 2.94417667388916,
      "eval_runtime": 27.1994,
      "eval_samples_per_second": 11.838,
      "eval_steps_per_second": 0.993,
      "step": 9500
    },
    {
      "epoch": 19.447852760736197,
      "grad_norm": 2.206207275390625,
      "learning_rate": 8.057475966455308e-05,
      "loss": 0.389,
      "step": 9510
    },
    {
      "epoch": 19.468302658486706,
      "grad_norm": 3.2987239360809326,
      "learning_rate": 8.0554305583964e-05,
      "loss": 0.3562,
      "step": 9520
    },
    {
      "epoch": 19.48875255623722,
      "grad_norm": 3.496805191040039,
      "learning_rate": 8.053385150337493e-05,
      "loss": 0.3562,
      "step": 9530
    },
    {
      "epoch": 19.50920245398773,
      "grad_norm": 2.7391674518585205,
      "learning_rate": 8.051339742278585e-05,
      "loss": 0.3723,
      "step": 9540
    },
    {
      "epoch": 19.529652351738243,
      "grad_norm": 3.1994900703430176,
      "learning_rate": 8.049294334219677e-05,
      "loss": 0.3673,
      "step": 9550
    },
    {
      "epoch": 19.550102249488752,
      "grad_norm": 3.1325631141662598,
      "learning_rate": 8.04724892616077e-05,
      "loss": 0.3437,
      "step": 9560
    },
    {
      "epoch": 19.570552147239265,
      "grad_norm": 2.5825228691101074,
      "learning_rate": 8.045203518101862e-05,
      "loss": 0.3661,
      "step": 9570
    },
    {
      "epoch": 19.591002044989775,
      "grad_norm": 2.1060469150543213,
      "learning_rate": 8.043158110042954e-05,
      "loss": 0.3674,
      "step": 9580
    },
    {
      "epoch": 19.611451942740285,
      "grad_norm": 2.265364408493042,
      "learning_rate": 8.041112701984046e-05,
      "loss": 0.3828,
      "step": 9590
    },
    {
      "epoch": 19.631901840490798,
      "grad_norm": 3.346050977706909,
      "learning_rate": 8.039067293925138e-05,
      "loss": 0.3541,
      "step": 9600
    },
    {
      "epoch": 19.631901840490798,
      "eval_loss": 2.9954655170440674,
      "eval_runtime": 27.2023,
      "eval_samples_per_second": 11.837,
      "eval_steps_per_second": 0.993,
      "step": 9600
    },
    {
      "epoch": 19.652351738241308,
      "grad_norm": 3.5553176403045654,
      "learning_rate": 8.03702188586623e-05,
      "loss": 0.3604,
      "step": 9610
    },
    {
      "epoch": 19.67280163599182,
      "grad_norm": 3.720215320587158,
      "learning_rate": 8.034976477807324e-05,
      "loss": 0.3833,
      "step": 9620
    },
    {
      "epoch": 19.69325153374233,
      "grad_norm": 5.207097053527832,
      "learning_rate": 8.032931069748415e-05,
      "loss": 0.3584,
      "step": 9630
    },
    {
      "epoch": 19.713701431492844,
      "grad_norm": 2.6586992740631104,
      "learning_rate": 8.030885661689508e-05,
      "loss": 0.3574,
      "step": 9640
    },
    {
      "epoch": 19.734151329243353,
      "grad_norm": 3.54929780960083,
      "learning_rate": 8.028840253630599e-05,
      "loss": 0.3758,
      "step": 9650
    },
    {
      "epoch": 19.754601226993866,
      "grad_norm": 3.386317253112793,
      "learning_rate": 8.026794845571693e-05,
      "loss": 0.3997,
      "step": 9660
    },
    {
      "epoch": 19.775051124744376,
      "grad_norm": 4.093102931976318,
      "learning_rate": 8.024749437512784e-05,
      "loss": 0.3693,
      "step": 9670
    },
    {
      "epoch": 19.79550102249489,
      "grad_norm": 3.4729909896850586,
      "learning_rate": 8.022704029453877e-05,
      "loss": 0.3764,
      "step": 9680
    },
    {
      "epoch": 19.8159509202454,
      "grad_norm": 7.457663059234619,
      "learning_rate": 8.020658621394968e-05,
      "loss": 0.3761,
      "step": 9690
    },
    {
      "epoch": 19.83640081799591,
      "grad_norm": 3.9829320907592773,
      "learning_rate": 8.018613213336062e-05,
      "loss": 0.3572,
      "step": 9700
    },
    {
      "epoch": 19.83640081799591,
      "eval_loss": 2.931065797805786,
      "eval_runtime": 27.1957,
      "eval_samples_per_second": 11.84,
      "eval_steps_per_second": 0.993,
      "step": 9700
    },
    {
      "epoch": 19.856850715746422,
      "grad_norm": 4.289834022521973,
      "learning_rate": 8.016567805277153e-05,
      "loss": 0.3742,
      "step": 9710
    },
    {
      "epoch": 19.87730061349693,
      "grad_norm": 3.719557285308838,
      "learning_rate": 8.014522397218246e-05,
      "loss": 0.3777,
      "step": 9720
    },
    {
      "epoch": 19.897750511247445,
      "grad_norm": 5.085900783538818,
      "learning_rate": 8.012476989159338e-05,
      "loss": 0.3941,
      "step": 9730
    },
    {
      "epoch": 19.918200408997954,
      "grad_norm": 2.9109349250793457,
      "learning_rate": 8.01043158110043e-05,
      "loss": 0.3537,
      "step": 9740
    },
    {
      "epoch": 19.938650306748468,
      "grad_norm": 3.3904290199279785,
      "learning_rate": 8.008386173041523e-05,
      "loss": 0.396,
      "step": 9750
    },
    {
      "epoch": 19.959100204498977,
      "grad_norm": 2.221796751022339,
      "learning_rate": 8.006340764982614e-05,
      "loss": 0.3609,
      "step": 9760
    },
    {
      "epoch": 19.97955010224949,
      "grad_norm": 5.301194190979004,
      "learning_rate": 8.004295356923707e-05,
      "loss": 0.3569,
      "step": 9770
    },
    {
      "epoch": 20.0,
      "grad_norm": 8.302833557128906,
      "learning_rate": 8.002249948864798e-05,
      "loss": 0.406,
      "step": 9780
    },
    {
      "epoch": 20.02044989775051,
      "grad_norm": 4.0478339195251465,
      "learning_rate": 8.000204540805892e-05,
      "loss": 0.3378,
      "step": 9790
    },
    {
      "epoch": 20.040899795501023,
      "grad_norm": 3.7675304412841797,
      "learning_rate": 7.998159132746982e-05,
      "loss": 0.3304,
      "step": 9800
    },
    {
      "epoch": 20.040899795501023,
      "eval_loss": 3.039968490600586,
      "eval_runtime": 27.2102,
      "eval_samples_per_second": 11.834,
      "eval_steps_per_second": 0.992,
      "step": 9800
    },
    {
      "epoch": 20.061349693251532,
      "grad_norm": 2.3279616832733154,
      "learning_rate": 7.996113724688076e-05,
      "loss": 0.3383,
      "step": 9810
    },
    {
      "epoch": 20.081799591002046,
      "grad_norm": 3.138633966445923,
      "learning_rate": 7.994068316629167e-05,
      "loss": 0.3429,
      "step": 9820
    },
    {
      "epoch": 20.102249488752555,
      "grad_norm": 3.052196741104126,
      "learning_rate": 7.99202290857026e-05,
      "loss": 0.316,
      "step": 9830
    },
    {
      "epoch": 20.12269938650307,
      "grad_norm": 2.801652669906616,
      "learning_rate": 7.989977500511353e-05,
      "loss": 0.3628,
      "step": 9840
    },
    {
      "epoch": 20.143149284253578,
      "grad_norm": 3.207975149154663,
      "learning_rate": 7.987932092452445e-05,
      "loss": 0.3763,
      "step": 9850
    },
    {
      "epoch": 20.16359918200409,
      "grad_norm": 4.096457481384277,
      "learning_rate": 7.985886684393537e-05,
      "loss": 0.3508,
      "step": 9860
    },
    {
      "epoch": 20.1840490797546,
      "grad_norm": 1.648681640625,
      "learning_rate": 7.983841276334629e-05,
      "loss": 0.3739,
      "step": 9870
    },
    {
      "epoch": 20.20449897750511,
      "grad_norm": 2.089620351791382,
      "learning_rate": 7.981795868275721e-05,
      "loss": 0.3466,
      "step": 9880
    },
    {
      "epoch": 20.224948875255624,
      "grad_norm": 2.708916664123535,
      "learning_rate": 7.979750460216814e-05,
      "loss": 0.35,
      "step": 9890
    },
    {
      "epoch": 20.245398773006134,
      "grad_norm": 3.517794609069824,
      "learning_rate": 7.977705052157906e-05,
      "loss": 0.3438,
      "step": 9900
    },
    {
      "epoch": 20.245398773006134,
      "eval_loss": 3.088056802749634,
      "eval_runtime": 27.2246,
      "eval_samples_per_second": 11.828,
      "eval_steps_per_second": 0.992,
      "step": 9900
    },
    {
      "epoch": 20.265848670756647,
      "grad_norm": 2.24320125579834,
      "learning_rate": 7.975659644098998e-05,
      "loss": 0.3537,
      "step": 9910
    },
    {
      "epoch": 20.286298568507156,
      "grad_norm": 2.3643691539764404,
      "learning_rate": 7.97361423604009e-05,
      "loss": 0.353,
      "step": 9920
    },
    {
      "epoch": 20.30674846625767,
      "grad_norm": 2.6292967796325684,
      "learning_rate": 7.971568827981183e-05,
      "loss": 0.3538,
      "step": 9930
    },
    {
      "epoch": 20.32719836400818,
      "grad_norm": 2.3463387489318848,
      "learning_rate": 7.969523419922275e-05,
      "loss": 0.3568,
      "step": 9940
    },
    {
      "epoch": 20.347648261758692,
      "grad_norm": 4.3646674156188965,
      "learning_rate": 7.967478011863367e-05,
      "loss": 0.3422,
      "step": 9950
    },
    {
      "epoch": 20.368098159509202,
      "grad_norm": 2.9911320209503174,
      "learning_rate": 7.965432603804459e-05,
      "loss": 0.3604,
      "step": 9960
    },
    {
      "epoch": 20.388548057259715,
      "grad_norm": 2.9754016399383545,
      "learning_rate": 7.963387195745551e-05,
      "loss": 0.3366,
      "step": 9970
    },
    {
      "epoch": 20.408997955010225,
      "grad_norm": 2.230154037475586,
      "learning_rate": 7.961341787686644e-05,
      "loss": 0.3516,
      "step": 9980
    },
    {
      "epoch": 20.429447852760735,
      "grad_norm": 3.0967445373535156,
      "learning_rate": 7.959296379627736e-05,
      "loss": 0.3664,
      "step": 9990
    },
    {
      "epoch": 20.449897750511248,
      "grad_norm": 3.673295497894287,
      "learning_rate": 7.957250971568828e-05,
      "loss": 0.3396,
      "step": 10000
    },
    {
      "epoch": 20.449897750511248,
      "eval_loss": 3.0223207473754883,
      "eval_runtime": 27.6135,
      "eval_samples_per_second": 11.661,
      "eval_steps_per_second": 0.978,
      "step": 10000
    },
    {
      "epoch": 20.470347648261757,
      "grad_norm": 2.9342334270477295,
      "learning_rate": 7.955205563509922e-05,
      "loss": 0.3828,
      "step": 10010
    },
    {
      "epoch": 20.49079754601227,
      "grad_norm": 2.464303970336914,
      "learning_rate": 7.953160155451012e-05,
      "loss": 0.3659,
      "step": 10020
    },
    {
      "epoch": 20.51124744376278,
      "grad_norm": 3.60752272605896,
      "learning_rate": 7.951114747392106e-05,
      "loss": 0.3152,
      "step": 10030
    },
    {
      "epoch": 20.531697341513294,
      "grad_norm": 3.10627818107605,
      "learning_rate": 7.949069339333197e-05,
      "loss": 0.3785,
      "step": 10040
    },
    {
      "epoch": 20.552147239263803,
      "grad_norm": 2.9633231163024902,
      "learning_rate": 7.94702393127429e-05,
      "loss": 0.3429,
      "step": 10050
    },
    {
      "epoch": 20.572597137014316,
      "grad_norm": 2.374152421951294,
      "learning_rate": 7.944978523215381e-05,
      "loss": 0.3445,
      "step": 10060
    },
    {
      "epoch": 20.593047034764826,
      "grad_norm": 3.332261323928833,
      "learning_rate": 7.942933115156475e-05,
      "loss": 0.3574,
      "step": 10070
    },
    {
      "epoch": 20.61349693251534,
      "grad_norm": 2.4825077056884766,
      "learning_rate": 7.940887707097566e-05,
      "loss": 0.364,
      "step": 10080
    },
    {
      "epoch": 20.63394683026585,
      "grad_norm": 5.260236740112305,
      "learning_rate": 7.938842299038659e-05,
      "loss": 0.3573,
      "step": 10090
    },
    {
      "epoch": 20.65439672801636,
      "grad_norm": 4.024746894836426,
      "learning_rate": 7.93679689097975e-05,
      "loss": 0.3628,
      "step": 10100
    },
    {
      "epoch": 20.65439672801636,
      "eval_loss": 3.022893190383911,
      "eval_runtime": 27.2483,
      "eval_samples_per_second": 11.817,
      "eval_steps_per_second": 0.991,
      "step": 10100
    },
    {
      "epoch": 20.67484662576687,
      "grad_norm": 1.8377952575683594,
      "learning_rate": 7.934751482920844e-05,
      "loss": 0.3389,
      "step": 10110
    },
    {
      "epoch": 20.69529652351738,
      "grad_norm": 2.1621971130371094,
      "learning_rate": 7.932706074861936e-05,
      "loss": 0.3692,
      "step": 10120
    },
    {
      "epoch": 20.715746421267895,
      "grad_norm": 4.41172981262207,
      "learning_rate": 7.930660666803028e-05,
      "loss": 0.3747,
      "step": 10130
    },
    {
      "epoch": 20.736196319018404,
      "grad_norm": 3.026583433151245,
      "learning_rate": 7.92861525874412e-05,
      "loss": 0.3467,
      "step": 10140
    },
    {
      "epoch": 20.756646216768917,
      "grad_norm": 2.8263299465179443,
      "learning_rate": 7.926569850685213e-05,
      "loss": 0.3472,
      "step": 10150
    },
    {
      "epoch": 20.777096114519427,
      "grad_norm": 2.3404152393341064,
      "learning_rate": 7.924524442626305e-05,
      "loss": 0.3377,
      "step": 10160
    },
    {
      "epoch": 20.79754601226994,
      "grad_norm": 2.362657308578491,
      "learning_rate": 7.922479034567396e-05,
      "loss": 0.3436,
      "step": 10170
    },
    {
      "epoch": 20.81799591002045,
      "grad_norm": 2.7537612915039062,
      "learning_rate": 7.920433626508489e-05,
      "loss": 0.3553,
      "step": 10180
    },
    {
      "epoch": 20.83844580777096,
      "grad_norm": 3.030719518661499,
      "learning_rate": 7.91838821844958e-05,
      "loss": 0.3542,
      "step": 10190
    },
    {
      "epoch": 20.858895705521473,
      "grad_norm": 3.030411958694458,
      "learning_rate": 7.916342810390674e-05,
      "loss": 0.3591,
      "step": 10200
    },
    {
      "epoch": 20.858895705521473,
      "eval_loss": 2.997009754180908,
      "eval_runtime": 27.2442,
      "eval_samples_per_second": 11.819,
      "eval_steps_per_second": 0.991,
      "step": 10200
    },
    {
      "epoch": 20.879345603271982,
      "grad_norm": 3.6346161365509033,
      "learning_rate": 7.914297402331764e-05,
      "loss": 0.3628,
      "step": 10210
    },
    {
      "epoch": 20.899795501022496,
      "grad_norm": 4.82500696182251,
      "learning_rate": 7.912251994272858e-05,
      "loss": 0.3616,
      "step": 10220
    },
    {
      "epoch": 20.920245398773005,
      "grad_norm": 2.381486415863037,
      "learning_rate": 7.910411127019841e-05,
      "loss": 0.3393,
      "step": 10230
    },
    {
      "epoch": 20.94069529652352,
      "grad_norm": 2.1818618774414062,
      "learning_rate": 7.908365718960933e-05,
      "loss": 0.3934,
      "step": 10240
    },
    {
      "epoch": 20.961145194274028,
      "grad_norm": 3.002825975418091,
      "learning_rate": 7.906320310902026e-05,
      "loss": 0.3322,
      "step": 10250
    },
    {
      "epoch": 20.98159509202454,
      "grad_norm": 3.1224586963653564,
      "learning_rate": 7.904274902843118e-05,
      "loss": 0.3727,
      "step": 10260
    },
    {
      "epoch": 21.00204498977505,
      "grad_norm": 1.7293498516082764,
      "learning_rate": 7.90222949478421e-05,
      "loss": 0.3244,
      "step": 10270
    },
    {
      "epoch": 21.02249488752556,
      "grad_norm": 2.549992561340332,
      "learning_rate": 7.900184086725302e-05,
      "loss": 0.3294,
      "step": 10280
    },
    {
      "epoch": 21.042944785276074,
      "grad_norm": 2.1177594661712646,
      "learning_rate": 7.898138678666394e-05,
      "loss": 0.3387,
      "step": 10290
    },
    {
      "epoch": 21.063394683026583,
      "grad_norm": 3.7148683071136475,
      "learning_rate": 7.896093270607487e-05,
      "loss": 0.3543,
      "step": 10300
    },
    {
      "epoch": 21.063394683026583,
      "eval_loss": 3.1152384281158447,
      "eval_runtime": 27.1452,
      "eval_samples_per_second": 11.862,
      "eval_steps_per_second": 0.995,
      "step": 10300
    },
    {
      "epoch": 21.083844580777097,
      "grad_norm": 2.576735019683838,
      "learning_rate": 7.894047862548579e-05,
      "loss": 0.3352,
      "step": 10310
    },
    {
      "epoch": 21.104294478527606,
      "grad_norm": 3.4460458755493164,
      "learning_rate": 7.892002454489671e-05,
      "loss": 0.3302,
      "step": 10320
    },
    {
      "epoch": 21.12474437627812,
      "grad_norm": 3.697988271713257,
      "learning_rate": 7.889957046430763e-05,
      "loss": 0.3344,
      "step": 10330
    },
    {
      "epoch": 21.14519427402863,
      "grad_norm": 3.99353289604187,
      "learning_rate": 7.887911638371855e-05,
      "loss": 0.336,
      "step": 10340
    },
    {
      "epoch": 21.165644171779142,
      "grad_norm": 2.116590976715088,
      "learning_rate": 7.885866230312948e-05,
      "loss": 0.3634,
      "step": 10350
    },
    {
      "epoch": 21.186094069529652,
      "grad_norm": 3.2856616973876953,
      "learning_rate": 7.88382082225404e-05,
      "loss": 0.3463,
      "step": 10360
    },
    {
      "epoch": 21.206543967280165,
      "grad_norm": 2.9953036308288574,
      "learning_rate": 7.881775414195132e-05,
      "loss": 0.3821,
      "step": 10370
    },
    {
      "epoch": 21.226993865030675,
      "grad_norm": 3.4578866958618164,
      "learning_rate": 7.879730006136224e-05,
      "loss": 0.3409,
      "step": 10380
    },
    {
      "epoch": 21.247443762781185,
      "grad_norm": 2.034628391265869,
      "learning_rate": 7.877684598077318e-05,
      "loss": 0.3307,
      "step": 10390
    },
    {
      "epoch": 21.267893660531698,
      "grad_norm": 3.3533122539520264,
      "learning_rate": 7.875639190018409e-05,
      "loss": 0.3439,
      "step": 10400
    },
    {
      "epoch": 21.267893660531698,
      "eval_loss": 3.0883917808532715,
      "eval_runtime": 27.2716,
      "eval_samples_per_second": 11.807,
      "eval_steps_per_second": 0.99,
      "step": 10400
    },
    {
      "epoch": 21.288343558282207,
      "grad_norm": 2.398141860961914,
      "learning_rate": 7.873593781959502e-05,
      "loss": 0.3553,
      "step": 10410
    },
    {
      "epoch": 21.30879345603272,
      "grad_norm": 3.0816009044647217,
      "learning_rate": 7.871548373900593e-05,
      "loss": 0.3483,
      "step": 10420
    },
    {
      "epoch": 21.32924335378323,
      "grad_norm": 2.734247922897339,
      "learning_rate": 7.869502965841687e-05,
      "loss": 0.3173,
      "step": 10430
    },
    {
      "epoch": 21.349693251533743,
      "grad_norm": 2.607762575149536,
      "learning_rate": 7.867457557782778e-05,
      "loss": 0.3333,
      "step": 10440
    },
    {
      "epoch": 21.370143149284253,
      "grad_norm": 2.0685274600982666,
      "learning_rate": 7.86541214972387e-05,
      "loss": 0.332,
      "step": 10450
    },
    {
      "epoch": 21.390593047034766,
      "grad_norm": 2.331803798675537,
      "learning_rate": 7.863366741664962e-05,
      "loss": 0.3363,
      "step": 10460
    },
    {
      "epoch": 21.411042944785276,
      "grad_norm": 2.2349250316619873,
      "learning_rate": 7.861321333606054e-05,
      "loss": 0.3503,
      "step": 10470
    },
    {
      "epoch": 21.43149284253579,
      "grad_norm": 2.9241771697998047,
      "learning_rate": 7.859275925547146e-05,
      "loss": 0.3354,
      "step": 10480
    },
    {
      "epoch": 21.4519427402863,
      "grad_norm": 2.1026318073272705,
      "learning_rate": 7.857230517488239e-05,
      "loss": 0.3216,
      "step": 10490
    },
    {
      "epoch": 21.47239263803681,
      "grad_norm": 3.517864465713501,
      "learning_rate": 7.855185109429332e-05,
      "loss": 0.3443,
      "step": 10500
    },
    {
      "epoch": 21.47239263803681,
      "eval_loss": 3.0530357360839844,
      "eval_runtime": 27.2093,
      "eval_samples_per_second": 11.834,
      "eval_steps_per_second": 0.992,
      "step": 10500
    },
    {
      "epoch": 21.49284253578732,
      "grad_norm": 3.717057704925537,
      "learning_rate": 7.853139701370423e-05,
      "loss": 0.3621,
      "step": 10510
    },
    {
      "epoch": 21.51329243353783,
      "grad_norm": 1.9311881065368652,
      "learning_rate": 7.851094293311517e-05,
      "loss": 0.3207,
      "step": 10520
    },
    {
      "epoch": 21.533742331288344,
      "grad_norm": 3.69256854057312,
      "learning_rate": 7.849048885252608e-05,
      "loss": 0.3472,
      "step": 10530
    },
    {
      "epoch": 21.554192229038854,
      "grad_norm": 2.952690839767456,
      "learning_rate": 7.847003477193701e-05,
      "loss": 0.3536,
      "step": 10540
    },
    {
      "epoch": 21.574642126789367,
      "grad_norm": 2.2073473930358887,
      "learning_rate": 7.844958069134792e-05,
      "loss": 0.3196,
      "step": 10550
    },
    {
      "epoch": 21.595092024539877,
      "grad_norm": 3.6270103454589844,
      "learning_rate": 7.842912661075885e-05,
      "loss": 0.3874,
      "step": 10560
    },
    {
      "epoch": 21.61554192229039,
      "grad_norm": 3.2111740112304688,
      "learning_rate": 7.840867253016976e-05,
      "loss": 0.3376,
      "step": 10570
    },
    {
      "epoch": 21.6359918200409,
      "grad_norm": 4.886534214019775,
      "learning_rate": 7.83882184495807e-05,
      "loss": 0.3599,
      "step": 10580
    },
    {
      "epoch": 21.65644171779141,
      "grad_norm": 2.624079704284668,
      "learning_rate": 7.836776436899161e-05,
      "loss": 0.3841,
      "step": 10590
    },
    {
      "epoch": 21.676891615541923,
      "grad_norm": 2.6974947452545166,
      "learning_rate": 7.834731028840254e-05,
      "loss": 0.3488,
      "step": 10600
    },
    {
      "epoch": 21.676891615541923,
      "eval_loss": 3.0367014408111572,
      "eval_runtime": 27.6437,
      "eval_samples_per_second": 11.648,
      "eval_steps_per_second": 0.977,
      "step": 10600
    },
    {
      "epoch": 21.697341513292432,
      "grad_norm": 2.1229655742645264,
      "learning_rate": 7.832685620781347e-05,
      "loss": 0.3245,
      "step": 10610
    },
    {
      "epoch": 21.717791411042946,
      "grad_norm": 2.610121965408325,
      "learning_rate": 7.830640212722439e-05,
      "loss": 0.3616,
      "step": 10620
    },
    {
      "epoch": 21.738241308793455,
      "grad_norm": 2.742974042892456,
      "learning_rate": 7.828594804663531e-05,
      "loss": 0.3621,
      "step": 10630
    },
    {
      "epoch": 21.75869120654397,
      "grad_norm": 2.243159055709839,
      "learning_rate": 7.826549396604623e-05,
      "loss": 0.3513,
      "step": 10640
    },
    {
      "epoch": 21.779141104294478,
      "grad_norm": 2.552602767944336,
      "learning_rate": 7.824503988545715e-05,
      "loss": 0.3482,
      "step": 10650
    },
    {
      "epoch": 21.79959100204499,
      "grad_norm": 3.879948616027832,
      "learning_rate": 7.822458580486808e-05,
      "loss": 0.3447,
      "step": 10660
    },
    {
      "epoch": 21.8200408997955,
      "grad_norm": 2.560502290725708,
      "learning_rate": 7.8204131724279e-05,
      "loss": 0.3294,
      "step": 10670
    },
    {
      "epoch": 21.84049079754601,
      "grad_norm": 4.0563740730285645,
      "learning_rate": 7.818367764368992e-05,
      "loss": 0.3707,
      "step": 10680
    },
    {
      "epoch": 21.860940695296524,
      "grad_norm": 2.5952038764953613,
      "learning_rate": 7.816322356310084e-05,
      "loss": 0.3634,
      "step": 10690
    },
    {
      "epoch": 21.881390593047033,
      "grad_norm": 2.4280214309692383,
      "learning_rate": 7.814276948251176e-05,
      "loss": 0.343,
      "step": 10700
    },
    {
      "epoch": 21.881390593047033,
      "eval_loss": 3.033639907836914,
      "eval_runtime": 27.4318,
      "eval_samples_per_second": 11.738,
      "eval_steps_per_second": 0.984,
      "step": 10700
    },
    {
      "epoch": 21.901840490797547,
      "grad_norm": 4.380861759185791,
      "learning_rate": 7.812231540192269e-05,
      "loss": 0.362,
      "step": 10710
    },
    {
      "epoch": 21.922290388548056,
      "grad_norm": 2.8218321800231934,
      "learning_rate": 7.810186132133361e-05,
      "loss": 0.3561,
      "step": 10720
    },
    {
      "epoch": 21.94274028629857,
      "grad_norm": 3.389566421508789,
      "learning_rate": 7.808140724074453e-05,
      "loss": 0.3746,
      "step": 10730
    },
    {
      "epoch": 21.96319018404908,
      "grad_norm": 2.8167130947113037,
      "learning_rate": 7.806095316015545e-05,
      "loss": 0.3568,
      "step": 10740
    },
    {
      "epoch": 21.983640081799592,
      "grad_norm": 2.7783658504486084,
      "learning_rate": 7.804049907956638e-05,
      "loss": 0.3607,
      "step": 10750
    },
    {
      "epoch": 22.004089979550102,
      "grad_norm": 3.3255937099456787,
      "learning_rate": 7.80200449989773e-05,
      "loss": 0.3578,
      "step": 10760
    },
    {
      "epoch": 22.024539877300615,
      "grad_norm": 2.289654016494751,
      "learning_rate": 7.799959091838822e-05,
      "loss": 0.3285,
      "step": 10770
    },
    {
      "epoch": 22.044989775051125,
      "grad_norm": 2.6773898601531982,
      "learning_rate": 7.797913683779916e-05,
      "loss": 0.3209,
      "step": 10780
    },
    {
      "epoch": 22.065439672801634,
      "grad_norm": 1.802452564239502,
      "learning_rate": 7.795868275721006e-05,
      "loss": 0.3274,
      "step": 10790
    },
    {
      "epoch": 22.085889570552148,
      "grad_norm": 3.150373935699463,
      "learning_rate": 7.7938228676621e-05,
      "loss": 0.3326,
      "step": 10800
    },
    {
      "epoch": 22.085889570552148,
      "eval_loss": 3.1169731616973877,
      "eval_runtime": 27.2093,
      "eval_samples_per_second": 11.834,
      "eval_steps_per_second": 0.992,
      "step": 10800
    },
    {
      "epoch": 22.106339468302657,
      "grad_norm": 3.5465445518493652,
      "learning_rate": 7.791777459603191e-05,
      "loss": 0.336,
      "step": 10810
    },
    {
      "epoch": 22.12678936605317,
      "grad_norm": 3.554176092147827,
      "learning_rate": 7.789732051544284e-05,
      "loss": 0.3677,
      "step": 10820
    },
    {
      "epoch": 22.14723926380368,
      "grad_norm": 3.9032208919525146,
      "learning_rate": 7.787686643485375e-05,
      "loss": 0.3509,
      "step": 10830
    },
    {
      "epoch": 22.167689161554193,
      "grad_norm": 3.6365554332733154,
      "learning_rate": 7.785641235426469e-05,
      "loss": 0.3387,
      "step": 10840
    },
    {
      "epoch": 22.188139059304703,
      "grad_norm": 2.3559834957122803,
      "learning_rate": 7.78359582736756e-05,
      "loss": 0.352,
      "step": 10850
    },
    {
      "epoch": 22.208588957055216,
      "grad_norm": 2.043445110321045,
      "learning_rate": 7.781550419308652e-05,
      "loss": 0.3544,
      "step": 10860
    },
    {
      "epoch": 22.229038854805726,
      "grad_norm": 3.8543179035186768,
      "learning_rate": 7.779505011249744e-05,
      "loss": 0.3125,
      "step": 10870
    },
    {
      "epoch": 22.249488752556235,
      "grad_norm": 2.276803970336914,
      "learning_rate": 7.777459603190836e-05,
      "loss": 0.3292,
      "step": 10880
    },
    {
      "epoch": 22.26993865030675,
      "grad_norm": 2.94427752494812,
      "learning_rate": 7.77541419513193e-05,
      "loss": 0.3256,
      "step": 10890
    },
    {
      "epoch": 22.29038854805726,
      "grad_norm": 3.487459897994995,
      "learning_rate": 7.773368787073021e-05,
      "loss": 0.308,
      "step": 10900
    },
    {
      "epoch": 22.29038854805726,
      "eval_loss": 3.106351852416992,
      "eval_runtime": 27.1964,
      "eval_samples_per_second": 11.84,
      "eval_steps_per_second": 0.993,
      "step": 10900
    },
    {
      "epoch": 22.31083844580777,
      "grad_norm": 3.136688709259033,
      "learning_rate": 7.771323379014114e-05,
      "loss": 0.3365,
      "step": 10910
    },
    {
      "epoch": 22.33128834355828,
      "grad_norm": 2.284672260284424,
      "learning_rate": 7.769277970955205e-05,
      "loss": 0.3165,
      "step": 10920
    },
    {
      "epoch": 22.351738241308794,
      "grad_norm": 2.289566993713379,
      "learning_rate": 7.767232562896299e-05,
      "loss": 0.3414,
      "step": 10930
    },
    {
      "epoch": 22.372188139059304,
      "grad_norm": 2.2468793392181396,
      "learning_rate": 7.76518715483739e-05,
      "loss": 0.3418,
      "step": 10940
    },
    {
      "epoch": 22.392638036809817,
      "grad_norm": 3.000157594680786,
      "learning_rate": 7.763141746778483e-05,
      "loss": 0.3404,
      "step": 10950
    },
    {
      "epoch": 22.413087934560327,
      "grad_norm": 2.0501859188079834,
      "learning_rate": 7.761096338719574e-05,
      "loss": 0.3465,
      "step": 10960
    },
    {
      "epoch": 22.43353783231084,
      "grad_norm": 2.3540425300598145,
      "learning_rate": 7.759050930660668e-05,
      "loss": 0.3374,
      "step": 10970
    },
    {
      "epoch": 22.45398773006135,
      "grad_norm": 2.5815250873565674,
      "learning_rate": 7.757005522601758e-05,
      "loss": 0.3308,
      "step": 10980
    },
    {
      "epoch": 22.47443762781186,
      "grad_norm": 2.8148393630981445,
      "learning_rate": 7.754960114542852e-05,
      "loss": 0.3267,
      "step": 10990
    },
    {
      "epoch": 22.494887525562373,
      "grad_norm": 2.411128520965576,
      "learning_rate": 7.752914706483944e-05,
      "loss": 0.3269,
      "step": 11000
    },
    {
      "epoch": 22.494887525562373,
      "eval_loss": 3.055882692337036,
      "eval_runtime": 27.2141,
      "eval_samples_per_second": 11.832,
      "eval_steps_per_second": 0.992,
      "step": 11000
    },
    {
      "epoch": 22.515337423312882,
      "grad_norm": 3.1984148025512695,
      "learning_rate": 7.750869298425036e-05,
      "loss": 0.3392,
      "step": 11010
    },
    {
      "epoch": 22.535787321063395,
      "grad_norm": 2.572331190109253,
      "learning_rate": 7.748823890366129e-05,
      "loss": 0.3541,
      "step": 11020
    },
    {
      "epoch": 22.556237218813905,
      "grad_norm": 2.367321729660034,
      "learning_rate": 7.746778482307221e-05,
      "loss": 0.3222,
      "step": 11030
    },
    {
      "epoch": 22.57668711656442,
      "grad_norm": 4.230431079864502,
      "learning_rate": 7.744733074248313e-05,
      "loss": 0.3488,
      "step": 11040
    },
    {
      "epoch": 22.597137014314928,
      "grad_norm": 3.078226089477539,
      "learning_rate": 7.742687666189405e-05,
      "loss": 0.3394,
      "step": 11050
    },
    {
      "epoch": 22.61758691206544,
      "grad_norm": 2.941037654876709,
      "learning_rate": 7.740642258130497e-05,
      "loss": 0.3265,
      "step": 11060
    },
    {
      "epoch": 22.63803680981595,
      "grad_norm": 3.8943159580230713,
      "learning_rate": 7.73859685007159e-05,
      "loss": 0.349,
      "step": 11070
    },
    {
      "epoch": 22.65848670756646,
      "grad_norm": 3.754079580307007,
      "learning_rate": 7.736551442012682e-05,
      "loss": 0.3117,
      "step": 11080
    },
    {
      "epoch": 22.678936605316974,
      "grad_norm": 2.8613977432250977,
      "learning_rate": 7.734506033953774e-05,
      "loss": 0.3675,
      "step": 11090
    },
    {
      "epoch": 22.699386503067483,
      "grad_norm": 2.6450533866882324,
      "learning_rate": 7.732460625894866e-05,
      "loss": 0.3401,
      "step": 11100
    },
    {
      "epoch": 22.699386503067483,
      "eval_loss": 3.034959554672241,
      "eval_runtime": 27.2259,
      "eval_samples_per_second": 11.827,
      "eval_steps_per_second": 0.992,
      "step": 11100
    },
    {
      "epoch": 22.719836400817996,
      "grad_norm": 3.302354097366333,
      "learning_rate": 7.730415217835959e-05,
      "loss": 0.3335,
      "step": 11110
    },
    {
      "epoch": 22.740286298568506,
      "grad_norm": 3.3802709579467773,
      "learning_rate": 7.728369809777051e-05,
      "loss": 0.3509,
      "step": 11120
    },
    {
      "epoch": 22.76073619631902,
      "grad_norm": 2.3504185676574707,
      "learning_rate": 7.726324401718143e-05,
      "loss": 0.3386,
      "step": 11130
    },
    {
      "epoch": 22.78118609406953,
      "grad_norm": 3.4461021423339844,
      "learning_rate": 7.724278993659235e-05,
      "loss": 0.4014,
      "step": 11140
    },
    {
      "epoch": 22.801635991820042,
      "grad_norm": 3.0564441680908203,
      "learning_rate": 7.722233585600329e-05,
      "loss": 0.3397,
      "step": 11150
    },
    {
      "epoch": 22.822085889570552,
      "grad_norm": 2.8221793174743652,
      "learning_rate": 7.72018817754142e-05,
      "loss": 0.3336,
      "step": 11160
    },
    {
      "epoch": 22.842535787321065,
      "grad_norm": 3.178511381149292,
      "learning_rate": 7.718142769482513e-05,
      "loss": 0.3253,
      "step": 11170
    },
    {
      "epoch": 22.862985685071575,
      "grad_norm": 1.9716144800186157,
      "learning_rate": 7.716097361423604e-05,
      "loss": 0.3299,
      "step": 11180
    },
    {
      "epoch": 22.883435582822084,
      "grad_norm": 2.9969356060028076,
      "learning_rate": 7.714051953364698e-05,
      "loss": 0.3405,
      "step": 11190
    },
    {
      "epoch": 22.903885480572598,
      "grad_norm": 3.2184934616088867,
      "learning_rate": 7.712006545305788e-05,
      "loss": 0.3455,
      "step": 11200
    },
    {
      "epoch": 22.903885480572598,
      "eval_loss": 3.0448412895202637,
      "eval_runtime": 27.1854,
      "eval_samples_per_second": 11.845,
      "eval_steps_per_second": 0.993,
      "step": 11200
    },
    {
      "epoch": 22.924335378323107,
      "grad_norm": 2.650590658187866,
      "learning_rate": 7.709961137246882e-05,
      "loss": 0.3437,
      "step": 11210
    },
    {
      "epoch": 22.94478527607362,
      "grad_norm": 3.2985684871673584,
      "learning_rate": 7.707915729187973e-05,
      "loss": 0.3617,
      "step": 11220
    },
    {
      "epoch": 22.96523517382413,
      "grad_norm": 4.357726573944092,
      "learning_rate": 7.705870321129066e-05,
      "loss": 0.347,
      "step": 11230
    },
    {
      "epoch": 22.985685071574643,
      "grad_norm": 4.117189407348633,
      "learning_rate": 7.703824913070157e-05,
      "loss": 0.3873,
      "step": 11240
    },
    {
      "epoch": 23.006134969325153,
      "grad_norm": 2.1977627277374268,
      "learning_rate": 7.70177950501125e-05,
      "loss": 0.3511,
      "step": 11250
    },
    {
      "epoch": 23.026584867075666,
      "grad_norm": 3.038632869720459,
      "learning_rate": 7.699734096952343e-05,
      "loss": 0.3235,
      "step": 11260
    },
    {
      "epoch": 23.047034764826176,
      "grad_norm": 2.0323925018310547,
      "learning_rate": 7.697688688893434e-05,
      "loss": 0.3237,
      "step": 11270
    },
    {
      "epoch": 23.067484662576685,
      "grad_norm": 2.000074863433838,
      "learning_rate": 7.695643280834527e-05,
      "loss": 0.3362,
      "step": 11280
    },
    {
      "epoch": 23.0879345603272,
      "grad_norm": 4.147541522979736,
      "learning_rate": 7.693597872775618e-05,
      "loss": 0.3275,
      "step": 11290
    },
    {
      "epoch": 23.10838445807771,
      "grad_norm": 2.142534017562866,
      "learning_rate": 7.691552464716712e-05,
      "loss": 0.3232,
      "step": 11300
    },
    {
      "epoch": 23.10838445807771,
      "eval_loss": 3.14406418800354,
      "eval_runtime": 27.2047,
      "eval_samples_per_second": 11.836,
      "eval_steps_per_second": 0.992,
      "step": 11300
    },
    {
      "epoch": 23.12883435582822,
      "grad_norm": 3.0581188201904297,
      "learning_rate": 7.689507056657803e-05,
      "loss": 0.3521,
      "step": 11310
    },
    {
      "epoch": 23.14928425357873,
      "grad_norm": 2.4487223625183105,
      "learning_rate": 7.687461648598896e-05,
      "loss": 0.3314,
      "step": 11320
    },
    {
      "epoch": 23.169734151329244,
      "grad_norm": 3.5283353328704834,
      "learning_rate": 7.685416240539987e-05,
      "loss": 0.336,
      "step": 11330
    },
    {
      "epoch": 23.190184049079754,
      "grad_norm": 2.615182399749756,
      "learning_rate": 7.683370832481081e-05,
      "loss": 0.3082,
      "step": 11340
    },
    {
      "epoch": 23.210633946830267,
      "grad_norm": 2.992166757583618,
      "learning_rate": 7.681325424422172e-05,
      "loss": 0.3403,
      "step": 11350
    },
    {
      "epoch": 23.231083844580777,
      "grad_norm": 1.6861681938171387,
      "learning_rate": 7.679280016363265e-05,
      "loss": 0.3277,
      "step": 11360
    },
    {
      "epoch": 23.25153374233129,
      "grad_norm": 2.57472562789917,
      "learning_rate": 7.677234608304357e-05,
      "loss": 0.3327,
      "step": 11370
    },
    {
      "epoch": 23.2719836400818,
      "grad_norm": 2.602912664413452,
      "learning_rate": 7.67518920024545e-05,
      "loss": 0.3181,
      "step": 11380
    },
    {
      "epoch": 23.29243353783231,
      "grad_norm": 2.756030559539795,
      "learning_rate": 7.673143792186542e-05,
      "loss": 0.3013,
      "step": 11390
    },
    {
      "epoch": 23.312883435582823,
      "grad_norm": 3.428504467010498,
      "learning_rate": 7.671098384127634e-05,
      "loss": 0.3112,
      "step": 11400
    },
    {
      "epoch": 23.312883435582823,
      "eval_loss": 3.118375539779663,
      "eval_runtime": 27.2703,
      "eval_samples_per_second": 11.808,
      "eval_steps_per_second": 0.99,
      "step": 11400
    },
    {
      "epoch": 23.333333333333332,
      "grad_norm": 3.010608434677124,
      "learning_rate": 7.669052976068726e-05,
      "loss": 0.3675,
      "step": 11410
    },
    {
      "epoch": 23.353783231083845,
      "grad_norm": 3.2087135314941406,
      "learning_rate": 7.667007568009818e-05,
      "loss": 0.3342,
      "step": 11420
    },
    {
      "epoch": 23.374233128834355,
      "grad_norm": 1.9414979219436646,
      "learning_rate": 7.66496215995091e-05,
      "loss": 0.3199,
      "step": 11430
    },
    {
      "epoch": 23.394683026584868,
      "grad_norm": 4.080502033233643,
      "learning_rate": 7.662916751892003e-05,
      "loss": 0.3223,
      "step": 11440
    },
    {
      "epoch": 23.415132924335378,
      "grad_norm": 2.006815195083618,
      "learning_rate": 7.660871343833095e-05,
      "loss": 0.3321,
      "step": 11450
    },
    {
      "epoch": 23.43558282208589,
      "grad_norm": 3.129502058029175,
      "learning_rate": 7.658825935774187e-05,
      "loss": 0.3204,
      "step": 11460
    },
    {
      "epoch": 23.4560327198364,
      "grad_norm": 1.9534456729888916,
      "learning_rate": 7.65678052771528e-05,
      "loss": 0.3102,
      "step": 11470
    },
    {
      "epoch": 23.47648261758691,
      "grad_norm": 3.8059256076812744,
      "learning_rate": 7.654735119656372e-05,
      "loss": 0.3629,
      "step": 11480
    },
    {
      "epoch": 23.496932515337424,
      "grad_norm": 3.055598735809326,
      "learning_rate": 7.652689711597464e-05,
      "loss": 0.3189,
      "step": 11490
    },
    {
      "epoch": 23.517382413087933,
      "grad_norm": 4.1729512214660645,
      "learning_rate": 7.650644303538556e-05,
      "loss": 0.3302,
      "step": 11500
    },
    {
      "epoch": 23.517382413087933,
      "eval_loss": 3.1705925464630127,
      "eval_runtime": 27.2366,
      "eval_samples_per_second": 11.822,
      "eval_steps_per_second": 0.991,
      "step": 11500
    },
    {
      "epoch": 23.537832310838446,
      "grad_norm": 2.0499002933502197,
      "learning_rate": 7.648598895479648e-05,
      "loss": 0.3435,
      "step": 11510
    },
    {
      "epoch": 23.558282208588956,
      "grad_norm": 3.782233238220215,
      "learning_rate": 7.64655348742074e-05,
      "loss": 0.3433,
      "step": 11520
    },
    {
      "epoch": 23.57873210633947,
      "grad_norm": 2.2484071254730225,
      "learning_rate": 7.644508079361833e-05,
      "loss": 0.3632,
      "step": 11530
    },
    {
      "epoch": 23.59918200408998,
      "grad_norm": 2.5658583641052246,
      "learning_rate": 7.642462671302926e-05,
      "loss": 0.3508,
      "step": 11540
    },
    {
      "epoch": 23.619631901840492,
      "grad_norm": 3.0618197917938232,
      "learning_rate": 7.640417263244017e-05,
      "loss": 0.3181,
      "step": 11550
    },
    {
      "epoch": 23.640081799591,
      "grad_norm": 2.815856695175171,
      "learning_rate": 7.638371855185111e-05,
      "loss": 0.346,
      "step": 11560
    },
    {
      "epoch": 23.660531697341515,
      "grad_norm": 3.174931764602661,
      "learning_rate": 7.636326447126202e-05,
      "loss": 0.3507,
      "step": 11570
    },
    {
      "epoch": 23.680981595092025,
      "grad_norm": 2.708348274230957,
      "learning_rate": 7.634281039067295e-05,
      "loss": 0.3522,
      "step": 11580
    },
    {
      "epoch": 23.701431492842534,
      "grad_norm": 3.116901397705078,
      "learning_rate": 7.632235631008386e-05,
      "loss": 0.3446,
      "step": 11590
    },
    {
      "epoch": 23.721881390593047,
      "grad_norm": 2.896268129348755,
      "learning_rate": 7.63019022294948e-05,
      "loss": 0.35,
      "step": 11600
    },
    {
      "epoch": 23.721881390593047,
      "eval_loss": 3.0846848487854004,
      "eval_runtime": 27.2732,
      "eval_samples_per_second": 11.806,
      "eval_steps_per_second": 0.99,
      "step": 11600
    },
    {
      "epoch": 23.742331288343557,
      "grad_norm": 2.6642720699310303,
      "learning_rate": 7.62814481489057e-05,
      "loss": 0.3137,
      "step": 11610
    },
    {
      "epoch": 23.76278118609407,
      "grad_norm": 2.861903667449951,
      "learning_rate": 7.626099406831664e-05,
      "loss": 0.351,
      "step": 11620
    },
    {
      "epoch": 23.78323108384458,
      "grad_norm": 4.761700630187988,
      "learning_rate": 7.624053998772755e-05,
      "loss": 0.3419,
      "step": 11630
    },
    {
      "epoch": 23.803680981595093,
      "grad_norm": 4.402482032775879,
      "learning_rate": 7.622008590713848e-05,
      "loss": 0.3842,
      "step": 11640
    },
    {
      "epoch": 23.824130879345603,
      "grad_norm": 1.6166800260543823,
      "learning_rate": 7.61996318265494e-05,
      "loss": 0.3432,
      "step": 11650
    },
    {
      "epoch": 23.844580777096116,
      "grad_norm": 2.740900754928589,
      "learning_rate": 7.617917774596032e-05,
      "loss": 0.327,
      "step": 11660
    },
    {
      "epoch": 23.865030674846626,
      "grad_norm": 3.597263813018799,
      "learning_rate": 7.615872366537125e-05,
      "loss": 0.3491,
      "step": 11670
    },
    {
      "epoch": 23.885480572597135,
      "grad_norm": 2.7609362602233887,
      "learning_rate": 7.613826958478216e-05,
      "loss": 0.3368,
      "step": 11680
    },
    {
      "epoch": 23.90593047034765,
      "grad_norm": 3.2330777645111084,
      "learning_rate": 7.61178155041931e-05,
      "loss": 0.3395,
      "step": 11690
    },
    {
      "epoch": 23.926380368098158,
      "grad_norm": 3.8278262615203857,
      "learning_rate": 7.6097361423604e-05,
      "loss": 0.3471,
      "step": 11700
    },
    {
      "epoch": 23.926380368098158,
      "eval_loss": 3.0937461853027344,
      "eval_runtime": 27.223,
      "eval_samples_per_second": 11.828,
      "eval_steps_per_second": 0.992,
      "step": 11700
    },
    {
      "epoch": 23.94683026584867,
      "grad_norm": 3.070516586303711,
      "learning_rate": 7.607690734301494e-05,
      "loss": 0.3532,
      "step": 11710
    },
    {
      "epoch": 23.96728016359918,
      "grad_norm": 2.338883638381958,
      "learning_rate": 7.605645326242585e-05,
      "loss": 0.3298,
      "step": 11720
    },
    {
      "epoch": 23.987730061349694,
      "grad_norm": 4.726072788238525,
      "learning_rate": 7.603599918183678e-05,
      "loss": 0.3471,
      "step": 11730
    },
    {
      "epoch": 24.008179959100204,
      "grad_norm": 2.276362895965576,
      "learning_rate": 7.601554510124769e-05,
      "loss": 0.3502,
      "step": 11740
    },
    {
      "epoch": 24.028629856850717,
      "grad_norm": 2.090425729751587,
      "learning_rate": 7.599509102065863e-05,
      "loss": 0.3412,
      "step": 11750
    },
    {
      "epoch": 24.049079754601227,
      "grad_norm": 2.489116907119751,
      "learning_rate": 7.597463694006955e-05,
      "loss": 0.3182,
      "step": 11760
    },
    {
      "epoch": 24.06952965235174,
      "grad_norm": 1.8021095991134644,
      "learning_rate": 7.595418285948047e-05,
      "loss": 0.3128,
      "step": 11770
    },
    {
      "epoch": 24.08997955010225,
      "grad_norm": 2.1769237518310547,
      "learning_rate": 7.59337287788914e-05,
      "loss": 0.3373,
      "step": 11780
    },
    {
      "epoch": 24.11042944785276,
      "grad_norm": 2.6791365146636963,
      "learning_rate": 7.591327469830232e-05,
      "loss": 0.3399,
      "step": 11790
    },
    {
      "epoch": 24.130879345603272,
      "grad_norm": 2.1304616928100586,
      "learning_rate": 7.589282061771324e-05,
      "loss": 0.3149,
      "step": 11800
    },
    {
      "epoch": 24.130879345603272,
      "eval_loss": 3.1510820388793945,
      "eval_runtime": 27.2159,
      "eval_samples_per_second": 11.831,
      "eval_steps_per_second": 0.992,
      "step": 11800
    },
    {
      "epoch": 24.151329243353782,
      "grad_norm": 2.3201801776885986,
      "learning_rate": 7.587236653712416e-05,
      "loss": 0.3263,
      "step": 11810
    },
    {
      "epoch": 24.171779141104295,
      "grad_norm": 1.8512684106826782,
      "learning_rate": 7.585191245653508e-05,
      "loss": 0.3364,
      "step": 11820
    },
    {
      "epoch": 24.192229038854805,
      "grad_norm": 3.8728151321411133,
      "learning_rate": 7.5831458375946e-05,
      "loss": 0.3218,
      "step": 11830
    },
    {
      "epoch": 24.212678936605318,
      "grad_norm": 1.9138308763504028,
      "learning_rate": 7.581100429535693e-05,
      "loss": 0.3388,
      "step": 11840
    },
    {
      "epoch": 24.233128834355828,
      "grad_norm": 4.135951042175293,
      "learning_rate": 7.579055021476785e-05,
      "loss": 0.3465,
      "step": 11850
    },
    {
      "epoch": 24.25357873210634,
      "grad_norm": 3.3032608032226562,
      "learning_rate": 7.577009613417877e-05,
      "loss": 0.3146,
      "step": 11860
    },
    {
      "epoch": 24.27402862985685,
      "grad_norm": 2.3472228050231934,
      "learning_rate": 7.574964205358969e-05,
      "loss": 0.3462,
      "step": 11870
    },
    {
      "epoch": 24.29447852760736,
      "grad_norm": 4.334001064300537,
      "learning_rate": 7.572918797300062e-05,
      "loss": 0.3297,
      "step": 11880
    },
    {
      "epoch": 24.314928425357873,
      "grad_norm": 3.3325307369232178,
      "learning_rate": 7.570873389241154e-05,
      "loss": 0.3211,
      "step": 11890
    },
    {
      "epoch": 24.335378323108383,
      "grad_norm": 2.4944674968719482,
      "learning_rate": 7.568827981182246e-05,
      "loss": 0.3213,
      "step": 11900
    },
    {
      "epoch": 24.335378323108383,
      "eval_loss": 3.1146152019500732,
      "eval_runtime": 27.2466,
      "eval_samples_per_second": 11.818,
      "eval_steps_per_second": 0.991,
      "step": 11900
    },
    {
      "epoch": 24.355828220858896,
      "grad_norm": 2.705221652984619,
      "learning_rate": 7.566782573123338e-05,
      "loss": 0.3113,
      "step": 11910
    },
    {
      "epoch": 24.376278118609406,
      "grad_norm": 1.7150344848632812,
      "learning_rate": 7.56473716506443e-05,
      "loss": 0.328,
      "step": 11920
    },
    {
      "epoch": 24.39672801635992,
      "grad_norm": 2.25962233543396,
      "learning_rate": 7.562691757005524e-05,
      "loss": 0.3025,
      "step": 11930
    },
    {
      "epoch": 24.41717791411043,
      "grad_norm": 2.3655824661254883,
      "learning_rate": 7.560646348946615e-05,
      "loss": 0.3204,
      "step": 11940
    },
    {
      "epoch": 24.437627811860942,
      "grad_norm": 2.8595094680786133,
      "learning_rate": 7.558600940887708e-05,
      "loss": 0.3284,
      "step": 11950
    },
    {
      "epoch": 24.45807770961145,
      "grad_norm": 2.723414659500122,
      "learning_rate": 7.556555532828799e-05,
      "loss": 0.3293,
      "step": 11960
    },
    {
      "epoch": 24.478527607361965,
      "grad_norm": 3.8304386138916016,
      "learning_rate": 7.554510124769893e-05,
      "loss": 0.3254,
      "step": 11970
    },
    {
      "epoch": 24.498977505112475,
      "grad_norm": 4.607007026672363,
      "learning_rate": 7.552464716710984e-05,
      "loss": 0.3309,
      "step": 11980
    },
    {
      "epoch": 24.519427402862984,
      "grad_norm": 3.464447259902954,
      "learning_rate": 7.550419308652077e-05,
      "loss": 0.3435,
      "step": 11990
    },
    {
      "epoch": 24.539877300613497,
      "grad_norm": 3.2723143100738525,
      "learning_rate": 7.548373900593168e-05,
      "loss": 0.3248,
      "step": 12000
    },
    {
      "epoch": 24.539877300613497,
      "eval_loss": 3.160057544708252,
      "eval_runtime": 27.2091,
      "eval_samples_per_second": 11.834,
      "eval_steps_per_second": 0.992,
      "step": 12000
    },
    {
      "epoch": 24.560327198364007,
      "grad_norm": 2.4204258918762207,
      "learning_rate": 7.546328492534262e-05,
      "loss": 0.3118,
      "step": 12010
    },
    {
      "epoch": 24.58077709611452,
      "grad_norm": 1.6275075674057007,
      "learning_rate": 7.544283084475352e-05,
      "loss": 0.3582,
      "step": 12020
    },
    {
      "epoch": 24.60122699386503,
      "grad_norm": 1.8394501209259033,
      "learning_rate": 7.542237676416446e-05,
      "loss": 0.3154,
      "step": 12030
    },
    {
      "epoch": 24.621676891615543,
      "grad_norm": 3.510732412338257,
      "learning_rate": 7.540192268357538e-05,
      "loss": 0.3561,
      "step": 12040
    },
    {
      "epoch": 24.642126789366053,
      "grad_norm": 3.112955331802368,
      "learning_rate": 7.53814686029863e-05,
      "loss": 0.3748,
      "step": 12050
    },
    {
      "epoch": 24.662576687116566,
      "grad_norm": 3.2727670669555664,
      "learning_rate": 7.536101452239723e-05,
      "loss": 0.3224,
      "step": 12060
    },
    {
      "epoch": 24.683026584867076,
      "grad_norm": 3.3444693088531494,
      "learning_rate": 7.534056044180814e-05,
      "loss": 0.3305,
      "step": 12070
    },
    {
      "epoch": 24.703476482617585,
      "grad_norm": 3.0944266319274902,
      "learning_rate": 7.532010636121907e-05,
      "loss": 0.3492,
      "step": 12080
    },
    {
      "epoch": 24.7239263803681,
      "grad_norm": 3.4787349700927734,
      "learning_rate": 7.529965228062998e-05,
      "loss": 0.368,
      "step": 12090
    },
    {
      "epoch": 24.744376278118608,
      "grad_norm": 4.007574558258057,
      "learning_rate": 7.527919820004092e-05,
      "loss": 0.3565,
      "step": 12100
    },
    {
      "epoch": 24.744376278118608,
      "eval_loss": 3.0764713287353516,
      "eval_runtime": 27.3195,
      "eval_samples_per_second": 11.786,
      "eval_steps_per_second": 0.988,
      "step": 12100
    },
    {
      "epoch": 24.76482617586912,
      "grad_norm": 3.475928783416748,
      "learning_rate": 7.525874411945182e-05,
      "loss": 0.3409,
      "step": 12110
    },
    {
      "epoch": 24.78527607361963,
      "grad_norm": 3.087031364440918,
      "learning_rate": 7.523829003886276e-05,
      "loss": 0.3192,
      "step": 12120
    },
    {
      "epoch": 24.805725971370144,
      "grad_norm": 2.4682865142822266,
      "learning_rate": 7.521783595827367e-05,
      "loss": 0.3322,
      "step": 12130
    },
    {
      "epoch": 24.826175869120654,
      "grad_norm": 2.4856064319610596,
      "learning_rate": 7.51973818776846e-05,
      "loss": 0.3305,
      "step": 12140
    },
    {
      "epoch": 24.846625766871167,
      "grad_norm": 2.539510488510132,
      "learning_rate": 7.517692779709553e-05,
      "loss": 0.3549,
      "step": 12150
    },
    {
      "epoch": 24.867075664621677,
      "grad_norm": 2.021484375,
      "learning_rate": 7.515647371650645e-05,
      "loss": 0.3471,
      "step": 12160
    },
    {
      "epoch": 24.88752556237219,
      "grad_norm": 2.368865489959717,
      "learning_rate": 7.513601963591737e-05,
      "loss": 0.3314,
      "step": 12170
    },
    {
      "epoch": 24.9079754601227,
      "grad_norm": 2.708162784576416,
      "learning_rate": 7.511556555532829e-05,
      "loss": 0.326,
      "step": 12180
    },
    {
      "epoch": 24.92842535787321,
      "grad_norm": 2.091916799545288,
      "learning_rate": 7.509511147473921e-05,
      "loss": 0.3469,
      "step": 12190
    },
    {
      "epoch": 24.948875255623722,
      "grad_norm": 2.8745555877685547,
      "learning_rate": 7.507465739415014e-05,
      "loss": 0.3246,
      "step": 12200
    },
    {
      "epoch": 24.948875255623722,
      "eval_loss": 3.076395034790039,
      "eval_runtime": 27.1834,
      "eval_samples_per_second": 11.845,
      "eval_steps_per_second": 0.993,
      "step": 12200
    },
    {
      "epoch": 24.969325153374232,
      "grad_norm": 2.784785032272339,
      "learning_rate": 7.505420331356106e-05,
      "loss": 0.3399,
      "step": 12210
    },
    {
      "epoch": 24.989775051124745,
      "grad_norm": 2.381446361541748,
      "learning_rate": 7.503374923297198e-05,
      "loss": 0.3352,
      "step": 12220
    },
    {
      "epoch": 25.010224948875255,
      "grad_norm": 2.192314624786377,
      "learning_rate": 7.50132951523829e-05,
      "loss": 0.299,
      "step": 12230
    },
    {
      "epoch": 25.030674846625768,
      "grad_norm": 2.435615062713623,
      "learning_rate": 7.499284107179382e-05,
      "loss": 0.3158,
      "step": 12240
    },
    {
      "epoch": 25.051124744376278,
      "grad_norm": 3.1073460578918457,
      "learning_rate": 7.497238699120475e-05,
      "loss": 0.3046,
      "step": 12250
    },
    {
      "epoch": 25.07157464212679,
      "grad_norm": 2.0487005710601807,
      "learning_rate": 7.495193291061567e-05,
      "loss": 0.3362,
      "step": 12260
    },
    {
      "epoch": 25.0920245398773,
      "grad_norm": 1.7697142362594604,
      "learning_rate": 7.493147883002659e-05,
      "loss": 0.3207,
      "step": 12270
    },
    {
      "epoch": 25.11247443762781,
      "grad_norm": 2.074293851852417,
      "learning_rate": 7.491102474943751e-05,
      "loss": 0.3092,
      "step": 12280
    },
    {
      "epoch": 25.132924335378323,
      "grad_norm": 1.7404494285583496,
      "learning_rate": 7.489057066884844e-05,
      "loss": 0.3208,
      "step": 12290
    },
    {
      "epoch": 25.153374233128833,
      "grad_norm": 3.8108582496643066,
      "learning_rate": 7.487011658825937e-05,
      "loss": 0.3307,
      "step": 12300
    },
    {
      "epoch": 25.153374233128833,
      "eval_loss": 3.1723241806030273,
      "eval_runtime": 27.2236,
      "eval_samples_per_second": 11.828,
      "eval_steps_per_second": 0.992,
      "step": 12300
    },
    {
      "epoch": 25.173824130879346,
      "grad_norm": 2.569950819015503,
      "learning_rate": 7.484966250767028e-05,
      "loss": 0.3199,
      "step": 12310
    },
    {
      "epoch": 25.194274028629856,
      "grad_norm": 1.436096429824829,
      "learning_rate": 7.482920842708122e-05,
      "loss": 0.3228,
      "step": 12320
    },
    {
      "epoch": 25.21472392638037,
      "grad_norm": 2.0681655406951904,
      "learning_rate": 7.480875434649212e-05,
      "loss": 0.3245,
      "step": 12330
    },
    {
      "epoch": 25.23517382413088,
      "grad_norm": 3.1766417026519775,
      "learning_rate": 7.478830026590306e-05,
      "loss": 0.3225,
      "step": 12340
    },
    {
      "epoch": 25.255623721881392,
      "grad_norm": 3.649296760559082,
      "learning_rate": 7.476989159337288e-05,
      "loss": 0.354,
      "step": 12350
    },
    {
      "epoch": 25.2760736196319,
      "grad_norm": 1.7865537405014038,
      "learning_rate": 7.47494375127838e-05,
      "loss": 0.3431,
      "step": 12360
    },
    {
      "epoch": 25.296523517382415,
      "grad_norm": 2.7050061225891113,
      "learning_rate": 7.472898343219472e-05,
      "loss": 0.3184,
      "step": 12370
    },
    {
      "epoch": 25.316973415132924,
      "grad_norm": 2.0734429359436035,
      "learning_rate": 7.470852935160564e-05,
      "loss": 0.3333,
      "step": 12380
    },
    {
      "epoch": 25.337423312883434,
      "grad_norm": 2.116586923599243,
      "learning_rate": 7.468807527101657e-05,
      "loss": 0.3274,
      "step": 12390
    },
    {
      "epoch": 25.357873210633947,
      "grad_norm": 4.1286091804504395,
      "learning_rate": 7.466762119042749e-05,
      "loss": 0.3221,
      "step": 12400
    },
    {
      "epoch": 25.357873210633947,
      "eval_loss": 3.155317783355713,
      "eval_runtime": 27.2244,
      "eval_samples_per_second": 11.828,
      "eval_steps_per_second": 0.992,
      "step": 12400
    },
    {
      "epoch": 25.378323108384457,
      "grad_norm": 2.605646848678589,
      "learning_rate": 7.464716710983841e-05,
      "loss": 0.3225,
      "step": 12410
    },
    {
      "epoch": 25.39877300613497,
      "grad_norm": 2.246401309967041,
      "learning_rate": 7.462671302924935e-05,
      "loss": 0.3502,
      "step": 12420
    },
    {
      "epoch": 25.41922290388548,
      "grad_norm": 2.9803669452667236,
      "learning_rate": 7.460625894866025e-05,
      "loss": 0.3283,
      "step": 12430
    },
    {
      "epoch": 25.439672801635993,
      "grad_norm": 2.124962091445923,
      "learning_rate": 7.458580486807119e-05,
      "loss": 0.3242,
      "step": 12440
    },
    {
      "epoch": 25.460122699386503,
      "grad_norm": 2.95550274848938,
      "learning_rate": 7.45653507874821e-05,
      "loss": 0.3269,
      "step": 12450
    },
    {
      "epoch": 25.480572597137016,
      "grad_norm": 2.8380274772644043,
      "learning_rate": 7.454489670689303e-05,
      "loss": 0.328,
      "step": 12460
    },
    {
      "epoch": 25.501022494887525,
      "grad_norm": 3.887129306793213,
      "learning_rate": 7.452444262630394e-05,
      "loss": 0.3507,
      "step": 12470
    },
    {
      "epoch": 25.521472392638035,
      "grad_norm": 2.8933212757110596,
      "learning_rate": 7.450398854571488e-05,
      "loss": 0.3178,
      "step": 12480
    },
    {
      "epoch": 25.54192229038855,
      "grad_norm": 3.4114437103271484,
      "learning_rate": 7.448353446512579e-05,
      "loss": 0.321,
      "step": 12490
    },
    {
      "epoch": 25.562372188139058,
      "grad_norm": 2.090590000152588,
      "learning_rate": 7.446308038453672e-05,
      "loss": 0.3046,
      "step": 12500
    },
    {
      "epoch": 25.562372188139058,
      "eval_loss": 3.1783785820007324,
      "eval_runtime": 27.2189,
      "eval_samples_per_second": 11.83,
      "eval_steps_per_second": 0.992,
      "step": 12500
    },
    {
      "epoch": 25.58282208588957,
      "grad_norm": 2.13720440864563,
      "learning_rate": 7.444262630394763e-05,
      "loss": 0.3008,
      "step": 12510
    },
    {
      "epoch": 25.60327198364008,
      "grad_norm": 2.538069248199463,
      "learning_rate": 7.442217222335857e-05,
      "loss": 0.3355,
      "step": 12520
    },
    {
      "epoch": 25.623721881390594,
      "grad_norm": 3.6777069568634033,
      "learning_rate": 7.440171814276949e-05,
      "loss": 0.3088,
      "step": 12530
    },
    {
      "epoch": 25.644171779141104,
      "grad_norm": 3.015916347503662,
      "learning_rate": 7.438126406218041e-05,
      "loss": 0.3729,
      "step": 12540
    },
    {
      "epoch": 25.664621676891617,
      "grad_norm": 2.414952039718628,
      "learning_rate": 7.436080998159133e-05,
      "loss": 0.3428,
      "step": 12550
    },
    {
      "epoch": 25.685071574642127,
      "grad_norm": 3.793855905532837,
      "learning_rate": 7.434035590100226e-05,
      "loss": 0.3487,
      "step": 12560
    },
    {
      "epoch": 25.70552147239264,
      "grad_norm": 2.0496182441711426,
      "learning_rate": 7.431990182041318e-05,
      "loss": 0.3559,
      "step": 12570
    },
    {
      "epoch": 25.72597137014315,
      "grad_norm": 2.5411295890808105,
      "learning_rate": 7.42994477398241e-05,
      "loss": 0.3138,
      "step": 12580
    },
    {
      "epoch": 25.74642126789366,
      "grad_norm": 3.083481550216675,
      "learning_rate": 7.427899365923502e-05,
      "loss": 0.3464,
      "step": 12590
    },
    {
      "epoch": 25.766871165644172,
      "grad_norm": 2.84078049659729,
      "learning_rate": 7.425853957864594e-05,
      "loss": 0.3265,
      "step": 12600
    },
    {
      "epoch": 25.766871165644172,
      "eval_loss": 3.1605496406555176,
      "eval_runtime": 27.2307,
      "eval_samples_per_second": 11.825,
      "eval_steps_per_second": 0.992,
      "step": 12600
    },
    {
      "epoch": 25.787321063394682,
      "grad_norm": 2.509511947631836,
      "learning_rate": 7.423808549805687e-05,
      "loss": 0.317,
      "step": 12610
    },
    {
      "epoch": 25.807770961145195,
      "grad_norm": 3.8097918033599854,
      "learning_rate": 7.421763141746779e-05,
      "loss": 0.3188,
      "step": 12620
    },
    {
      "epoch": 25.828220858895705,
      "grad_norm": 2.8661153316497803,
      "learning_rate": 7.419717733687871e-05,
      "loss": 0.3169,
      "step": 12630
    },
    {
      "epoch": 25.848670756646218,
      "grad_norm": 2.75776743888855,
      "learning_rate": 7.417672325628963e-05,
      "loss": 0.3315,
      "step": 12640
    },
    {
      "epoch": 25.869120654396728,
      "grad_norm": 3.1727654933929443,
      "learning_rate": 7.415626917570055e-05,
      "loss": 0.3273,
      "step": 12650
    },
    {
      "epoch": 25.88957055214724,
      "grad_norm": 3.6914782524108887,
      "learning_rate": 7.413581509511148e-05,
      "loss": 0.3247,
      "step": 12660
    },
    {
      "epoch": 25.91002044989775,
      "grad_norm": 5.195916175842285,
      "learning_rate": 7.41153610145224e-05,
      "loss": 0.326,
      "step": 12670
    },
    {
      "epoch": 25.93047034764826,
      "grad_norm": 2.531201124191284,
      "learning_rate": 7.409490693393333e-05,
      "loss": 0.3519,
      "step": 12680
    },
    {
      "epoch": 25.950920245398773,
      "grad_norm": 1.9576342105865479,
      "learning_rate": 7.407445285334424e-05,
      "loss": 0.3347,
      "step": 12690
    },
    {
      "epoch": 25.971370143149283,
      "grad_norm": 2.3400049209594727,
      "learning_rate": 7.405399877275518e-05,
      "loss": 0.357,
      "step": 12700
    },
    {
      "epoch": 25.971370143149283,
      "eval_loss": 3.084503412246704,
      "eval_runtime": 27.2282,
      "eval_samples_per_second": 11.826,
      "eval_steps_per_second": 0.992,
      "step": 12700
    },
    {
      "epoch": 25.991820040899796,
      "grad_norm": 1.8919482231140137,
      "learning_rate": 7.403354469216609e-05,
      "loss": 0.3246,
      "step": 12710
    },
    {
      "epoch": 26.012269938650306,
      "grad_norm": 1.9801512956619263,
      "learning_rate": 7.401309061157702e-05,
      "loss": 0.3077,
      "step": 12720
    },
    {
      "epoch": 26.03271983640082,
      "grad_norm": 1.8465538024902344,
      "learning_rate": 7.399263653098793e-05,
      "loss": 0.3087,
      "step": 12730
    },
    {
      "epoch": 26.05316973415133,
      "grad_norm": 3.235279083251953,
      "learning_rate": 7.397218245039887e-05,
      "loss": 0.3097,
      "step": 12740
    },
    {
      "epoch": 26.073619631901842,
      "grad_norm": 1.91995370388031,
      "learning_rate": 7.395172836980978e-05,
      "loss": 0.3169,
      "step": 12750
    },
    {
      "epoch": 26.09406952965235,
      "grad_norm": 2.251030445098877,
      "learning_rate": 7.39312742892207e-05,
      "loss": 0.2988,
      "step": 12760
    },
    {
      "epoch": 26.114519427402865,
      "grad_norm": 1.9441941976547241,
      "learning_rate": 7.391082020863162e-05,
      "loss": 0.3171,
      "step": 12770
    },
    {
      "epoch": 26.134969325153374,
      "grad_norm": 2.884214401245117,
      "learning_rate": 7.389036612804254e-05,
      "loss": 0.3162,
      "step": 12780
    },
    {
      "epoch": 26.155419222903884,
      "grad_norm": 1.8849539756774902,
      "learning_rate": 7.386991204745348e-05,
      "loss": 0.2816,
      "step": 12790
    },
    {
      "epoch": 26.175869120654397,
      "grad_norm": 3.1793863773345947,
      "learning_rate": 7.384945796686439e-05,
      "loss": 0.3114,
      "step": 12800
    },
    {
      "epoch": 26.175869120654397,
      "eval_loss": 3.1881608963012695,
      "eval_runtime": 27.2541,
      "eval_samples_per_second": 11.815,
      "eval_steps_per_second": 0.991,
      "step": 12800
    },
    {
      "epoch": 26.196319018404907,
      "grad_norm": 2.6963560581207275,
      "learning_rate": 7.382900388627532e-05,
      "loss": 0.3095,
      "step": 12810
    },
    {
      "epoch": 26.21676891615542,
      "grad_norm": 2.619354248046875,
      "learning_rate": 7.380854980568623e-05,
      "loss": 0.3445,
      "step": 12820
    },
    {
      "epoch": 26.23721881390593,
      "grad_norm": 2.354461908340454,
      "learning_rate": 7.378809572509717e-05,
      "loss": 0.336,
      "step": 12830
    },
    {
      "epoch": 26.257668711656443,
      "grad_norm": 1.658864974975586,
      "learning_rate": 7.376764164450807e-05,
      "loss": 0.2898,
      "step": 12840
    },
    {
      "epoch": 26.278118609406953,
      "grad_norm": 2.363842725753784,
      "learning_rate": 7.374718756391901e-05,
      "loss": 0.323,
      "step": 12850
    },
    {
      "epoch": 26.298568507157466,
      "grad_norm": 2.870000123977661,
      "learning_rate": 7.372673348332992e-05,
      "loss": 0.3216,
      "step": 12860
    },
    {
      "epoch": 26.319018404907975,
      "grad_norm": 2.149996280670166,
      "learning_rate": 7.370627940274085e-05,
      "loss": 0.3346,
      "step": 12870
    },
    {
      "epoch": 26.339468302658485,
      "grad_norm": 1.9201611280441284,
      "learning_rate": 7.368582532215176e-05,
      "loss": 0.3237,
      "step": 12880
    },
    {
      "epoch": 26.359918200409,
      "grad_norm": 3.188422918319702,
      "learning_rate": 7.36653712415627e-05,
      "loss": 0.3188,
      "step": 12890
    },
    {
      "epoch": 26.380368098159508,
      "grad_norm": 2.4364616870880127,
      "learning_rate": 7.364491716097362e-05,
      "loss": 0.3228,
      "step": 12900
    },
    {
      "epoch": 26.380368098159508,
      "eval_loss": 3.2072410583496094,
      "eval_runtime": 27.217,
      "eval_samples_per_second": 11.831,
      "eval_steps_per_second": 0.992,
      "step": 12900
    },
    {
      "epoch": 26.40081799591002,
      "grad_norm": 3.0041005611419678,
      "learning_rate": 7.362446308038454e-05,
      "loss": 0.3047,
      "step": 12910
    },
    {
      "epoch": 26.42126789366053,
      "grad_norm": 2.2252719402313232,
      "learning_rate": 7.360400899979547e-05,
      "loss": 0.3305,
      "step": 12920
    },
    {
      "epoch": 26.441717791411044,
      "grad_norm": 2.2016818523406982,
      "learning_rate": 7.358355491920639e-05,
      "loss": 0.3351,
      "step": 12930
    },
    {
      "epoch": 26.462167689161554,
      "grad_norm": 2.407402753829956,
      "learning_rate": 7.356310083861731e-05,
      "loss": 0.3209,
      "step": 12940
    },
    {
      "epoch": 26.482617586912067,
      "grad_norm": 2.76934814453125,
      "learning_rate": 7.354264675802823e-05,
      "loss": 0.3244,
      "step": 12950
    },
    {
      "epoch": 26.503067484662576,
      "grad_norm": 2.459092617034912,
      "learning_rate": 7.352219267743915e-05,
      "loss": 0.3117,
      "step": 12960
    },
    {
      "epoch": 26.52351738241309,
      "grad_norm": 2.1064071655273438,
      "learning_rate": 7.350173859685008e-05,
      "loss": 0.3345,
      "step": 12970
    },
    {
      "epoch": 26.5439672801636,
      "grad_norm": 1.5528104305267334,
      "learning_rate": 7.3481284516261e-05,
      "loss": 0.3162,
      "step": 12980
    },
    {
      "epoch": 26.56441717791411,
      "grad_norm": 2.489147663116455,
      "learning_rate": 7.346083043567192e-05,
      "loss": 0.3074,
      "step": 12990
    },
    {
      "epoch": 26.584867075664622,
      "grad_norm": 2.809519052505493,
      "learning_rate": 7.344037635508284e-05,
      "loss": 0.3325,
      "step": 13000
    },
    {
      "epoch": 26.584867075664622,
      "eval_loss": 3.171149253845215,
      "eval_runtime": 27.6108,
      "eval_samples_per_second": 11.662,
      "eval_steps_per_second": 0.978,
      "step": 13000
    },
    {
      "epoch": 26.605316973415132,
      "grad_norm": 3.342833995819092,
      "learning_rate": 7.341992227449376e-05,
      "loss": 0.3243,
      "step": 13010
    },
    {
      "epoch": 26.625766871165645,
      "grad_norm": 3.108409881591797,
      "learning_rate": 7.339946819390469e-05,
      "loss": 0.3233,
      "step": 13020
    },
    {
      "epoch": 26.646216768916155,
      "grad_norm": 2.7247958183288574,
      "learning_rate": 7.337901411331561e-05,
      "loss": 0.3127,
      "step": 13030
    },
    {
      "epoch": 26.666666666666668,
      "grad_norm": 6.530012607574463,
      "learning_rate": 7.335856003272653e-05,
      "loss": 0.3024,
      "step": 13040
    },
    {
      "epoch": 26.687116564417177,
      "grad_norm": 2.2768263816833496,
      "learning_rate": 7.333810595213745e-05,
      "loss": 0.3224,
      "step": 13050
    },
    {
      "epoch": 26.70756646216769,
      "grad_norm": 3.686816930770874,
      "learning_rate": 7.331765187154837e-05,
      "loss": 0.3829,
      "step": 13060
    },
    {
      "epoch": 26.7280163599182,
      "grad_norm": 3.0597641468048096,
      "learning_rate": 7.329719779095931e-05,
      "loss": 0.3243,
      "step": 13070
    },
    {
      "epoch": 26.74846625766871,
      "grad_norm": 2.274718999862671,
      "learning_rate": 7.327674371037022e-05,
      "loss": 0.3304,
      "step": 13080
    },
    {
      "epoch": 26.768916155419223,
      "grad_norm": 3.635294198989868,
      "learning_rate": 7.325628962978115e-05,
      "loss": 0.3492,
      "step": 13090
    },
    {
      "epoch": 26.789366053169733,
      "grad_norm": 3.698840618133545,
      "learning_rate": 7.323583554919206e-05,
      "loss": 0.3219,
      "step": 13100
    },
    {
      "epoch": 26.789366053169733,
      "eval_loss": 3.1682305335998535,
      "eval_runtime": 27.7139,
      "eval_samples_per_second": 11.619,
      "eval_steps_per_second": 0.974,
      "step": 13100
    },
    {
      "epoch": 26.809815950920246,
      "grad_norm": 3.243562698364258,
      "learning_rate": 7.3215381468603e-05,
      "loss": 0.3162,
      "step": 13110
    },
    {
      "epoch": 26.830265848670756,
      "grad_norm": 4.707015037536621,
      "learning_rate": 7.319492738801391e-05,
      "loss": 0.3429,
      "step": 13120
    },
    {
      "epoch": 26.85071574642127,
      "grad_norm": 2.6166577339172363,
      "learning_rate": 7.317447330742484e-05,
      "loss": 0.3101,
      "step": 13130
    },
    {
      "epoch": 26.87116564417178,
      "grad_norm": 2.136246681213379,
      "learning_rate": 7.315401922683575e-05,
      "loss": 0.3263,
      "step": 13140
    },
    {
      "epoch": 26.89161554192229,
      "grad_norm": 2.7007617950439453,
      "learning_rate": 7.313356514624667e-05,
      "loss": 0.3529,
      "step": 13150
    },
    {
      "epoch": 26.9120654396728,
      "grad_norm": 3.3245086669921875,
      "learning_rate": 7.31131110656576e-05,
      "loss": 0.3395,
      "step": 13160
    },
    {
      "epoch": 26.93251533742331,
      "grad_norm": 2.1055386066436768,
      "learning_rate": 7.309265698506852e-05,
      "loss": 0.3028,
      "step": 13170
    },
    {
      "epoch": 26.952965235173824,
      "grad_norm": 2.517228126525879,
      "learning_rate": 7.307220290447945e-05,
      "loss": 0.3381,
      "step": 13180
    },
    {
      "epoch": 26.973415132924334,
      "grad_norm": 2.8724803924560547,
      "learning_rate": 7.305174882389036e-05,
      "loss": 0.3552,
      "step": 13190
    },
    {
      "epoch": 26.993865030674847,
      "grad_norm": 1.7156941890716553,
      "learning_rate": 7.30312947433013e-05,
      "loss": 0.3343,
      "step": 13200
    },
    {
      "epoch": 26.993865030674847,
      "eval_loss": 3.2048325538635254,
      "eval_runtime": 27.204,
      "eval_samples_per_second": 11.837,
      "eval_steps_per_second": 0.993,
      "step": 13200
    },
    {
      "epoch": 27.014314928425357,
      "grad_norm": 1.886185884475708,
      "learning_rate": 7.30108406627122e-05,
      "loss": 0.3368,
      "step": 13210
    },
    {
      "epoch": 27.03476482617587,
      "grad_norm": 3.3300106525421143,
      "learning_rate": 7.299038658212314e-05,
      "loss": 0.3148,
      "step": 13220
    },
    {
      "epoch": 27.05521472392638,
      "grad_norm": 3.019473075866699,
      "learning_rate": 7.296993250153405e-05,
      "loss": 0.3268,
      "step": 13230
    },
    {
      "epoch": 27.075664621676893,
      "grad_norm": 2.166722297668457,
      "learning_rate": 7.294947842094499e-05,
      "loss": 0.3141,
      "step": 13240
    },
    {
      "epoch": 27.096114519427402,
      "grad_norm": 1.5054517984390259,
      "learning_rate": 7.29290243403559e-05,
      "loss": 0.3316,
      "step": 13250
    },
    {
      "epoch": 27.116564417177916,
      "grad_norm": 2.5486974716186523,
      "learning_rate": 7.290857025976683e-05,
      "loss": 0.3134,
      "step": 13260
    },
    {
      "epoch": 27.137014314928425,
      "grad_norm": 2.709676742553711,
      "learning_rate": 7.288811617917774e-05,
      "loss": 0.3442,
      "step": 13270
    },
    {
      "epoch": 27.157464212678935,
      "grad_norm": 2.3929176330566406,
      "learning_rate": 7.286766209858868e-05,
      "loss": 0.3125,
      "step": 13280
    },
    {
      "epoch": 27.177914110429448,
      "grad_norm": 2.1136972904205322,
      "learning_rate": 7.28472080179996e-05,
      "loss": 0.2994,
      "step": 13290
    },
    {
      "epoch": 27.198364008179958,
      "grad_norm": 3.295245409011841,
      "learning_rate": 7.282675393741052e-05,
      "loss": 0.3304,
      "step": 13300
    },
    {
      "epoch": 27.198364008179958,
      "eval_loss": 3.2743759155273438,
      "eval_runtime": 27.3364,
      "eval_samples_per_second": 11.779,
      "eval_steps_per_second": 0.988,
      "step": 13300
    },
    {
      "epoch": 27.21881390593047,
      "grad_norm": 1.6947662830352783,
      "learning_rate": 7.280629985682144e-05,
      "loss": 0.3169,
      "step": 13310
    },
    {
      "epoch": 27.23926380368098,
      "grad_norm": 2.602895975112915,
      "learning_rate": 7.278584577623236e-05,
      "loss": 0.3075,
      "step": 13320
    },
    {
      "epoch": 27.259713701431494,
      "grad_norm": 2.016197443008423,
      "learning_rate": 7.276539169564329e-05,
      "loss": 0.2936,
      "step": 13330
    },
    {
      "epoch": 27.280163599182004,
      "grad_norm": 2.7081685066223145,
      "learning_rate": 7.274493761505421e-05,
      "loss": 0.3031,
      "step": 13340
    },
    {
      "epoch": 27.300613496932517,
      "grad_norm": 2.9608981609344482,
      "learning_rate": 7.272448353446513e-05,
      "loss": 0.3358,
      "step": 13350
    },
    {
      "epoch": 27.321063394683026,
      "grad_norm": 1.7232112884521484,
      "learning_rate": 7.270402945387605e-05,
      "loss": 0.2915,
      "step": 13360
    },
    {
      "epoch": 27.34151329243354,
      "grad_norm": 2.5864179134368896,
      "learning_rate": 7.268357537328697e-05,
      "loss": 0.3286,
      "step": 13370
    },
    {
      "epoch": 27.36196319018405,
      "grad_norm": 2.356966495513916,
      "learning_rate": 7.26631212926979e-05,
      "loss": 0.3365,
      "step": 13380
    },
    {
      "epoch": 27.38241308793456,
      "grad_norm": 2.0689985752105713,
      "learning_rate": 7.264266721210882e-05,
      "loss": 0.319,
      "step": 13390
    },
    {
      "epoch": 27.402862985685072,
      "grad_norm": 2.6099867820739746,
      "learning_rate": 7.262221313151974e-05,
      "loss": 0.3187,
      "step": 13400
    },
    {
      "epoch": 27.402862985685072,
      "eval_loss": 3.2380383014678955,
      "eval_runtime": 27.4035,
      "eval_samples_per_second": 11.75,
      "eval_steps_per_second": 0.985,
      "step": 13400
    },
    {
      "epoch": 27.42331288343558,
      "grad_norm": 3.0637013912200928,
      "learning_rate": 7.260175905093066e-05,
      "loss": 0.3176,
      "step": 13410
    },
    {
      "epoch": 27.443762781186095,
      "grad_norm": 3.0859663486480713,
      "learning_rate": 7.258130497034158e-05,
      "loss": 0.307,
      "step": 13420
    },
    {
      "epoch": 27.464212678936605,
      "grad_norm": 2.818092107772827,
      "learning_rate": 7.256085088975251e-05,
      "loss": 0.315,
      "step": 13430
    },
    {
      "epoch": 27.484662576687118,
      "grad_norm": 3.0194942951202393,
      "learning_rate": 7.254039680916343e-05,
      "loss": 0.3555,
      "step": 13440
    },
    {
      "epoch": 27.505112474437627,
      "grad_norm": 3.079730749130249,
      "learning_rate": 7.251994272857435e-05,
      "loss": 0.3394,
      "step": 13450
    },
    {
      "epoch": 27.52556237218814,
      "grad_norm": 2.804906129837036,
      "learning_rate": 7.249948864798529e-05,
      "loss": 0.3103,
      "step": 13460
    },
    {
      "epoch": 27.54601226993865,
      "grad_norm": 2.5178420543670654,
      "learning_rate": 7.24790345673962e-05,
      "loss": 0.3306,
      "step": 13470
    },
    {
      "epoch": 27.56646216768916,
      "grad_norm": 2.091611623764038,
      "learning_rate": 7.245858048680713e-05,
      "loss": 0.3141,
      "step": 13480
    },
    {
      "epoch": 27.586912065439673,
      "grad_norm": 1.949163794517517,
      "learning_rate": 7.243812640621804e-05,
      "loss": 0.3558,
      "step": 13490
    },
    {
      "epoch": 27.607361963190183,
      "grad_norm": 2.8318111896514893,
      "learning_rate": 7.241767232562898e-05,
      "loss": 0.3143,
      "step": 13500
    },
    {
      "epoch": 27.607361963190183,
      "eval_loss": 3.197802782058716,
      "eval_runtime": 27.2895,
      "eval_samples_per_second": 11.799,
      "eval_steps_per_second": 0.989,
      "step": 13500
    },
    {
      "epoch": 27.627811860940696,
      "grad_norm": 4.0506463050842285,
      "learning_rate": 7.239721824503988e-05,
      "loss": 0.3369,
      "step": 13510
    },
    {
      "epoch": 27.648261758691206,
      "grad_norm": 4.2800374031066895,
      "learning_rate": 7.237676416445082e-05,
      "loss": 0.3069,
      "step": 13520
    },
    {
      "epoch": 27.66871165644172,
      "grad_norm": 2.6280124187469482,
      "learning_rate": 7.235631008386173e-05,
      "loss": 0.3329,
      "step": 13530
    },
    {
      "epoch": 27.68916155419223,
      "grad_norm": 2.6377711296081543,
      "learning_rate": 7.233585600327266e-05,
      "loss": 0.3076,
      "step": 13540
    },
    {
      "epoch": 27.70961145194274,
      "grad_norm": 2.845714569091797,
      "learning_rate": 7.231540192268357e-05,
      "loss": 0.3215,
      "step": 13550
    },
    {
      "epoch": 27.73006134969325,
      "grad_norm": 3.048523426055908,
      "learning_rate": 7.22949478420945e-05,
      "loss": 0.3246,
      "step": 13560
    },
    {
      "epoch": 27.75051124744376,
      "grad_norm": 2.528937816619873,
      "learning_rate": 7.227449376150543e-05,
      "loss": 0.3382,
      "step": 13570
    },
    {
      "epoch": 27.770961145194274,
      "grad_norm": 2.8947887420654297,
      "learning_rate": 7.225403968091634e-05,
      "loss": 0.309,
      "step": 13580
    },
    {
      "epoch": 27.791411042944784,
      "grad_norm": 3.193251371383667,
      "learning_rate": 7.223358560032727e-05,
      "loss": 0.3404,
      "step": 13590
    },
    {
      "epoch": 27.811860940695297,
      "grad_norm": 3.640808343887329,
      "learning_rate": 7.221313151973818e-05,
      "loss": 0.3058,
      "step": 13600
    },
    {
      "epoch": 27.811860940695297,
      "eval_loss": 3.17876935005188,
      "eval_runtime": 27.309,
      "eval_samples_per_second": 11.791,
      "eval_steps_per_second": 0.989,
      "step": 13600
    },
    {
      "epoch": 27.832310838445807,
      "grad_norm": 3.956667900085449,
      "learning_rate": 7.219267743914912e-05,
      "loss": 0.3243,
      "step": 13610
    },
    {
      "epoch": 27.85276073619632,
      "grad_norm": 4.199090480804443,
      "learning_rate": 7.217222335856003e-05,
      "loss": 0.3377,
      "step": 13620
    },
    {
      "epoch": 27.87321063394683,
      "grad_norm": 2.210981845855713,
      "learning_rate": 7.215176927797096e-05,
      "loss": 0.3091,
      "step": 13630
    },
    {
      "epoch": 27.893660531697343,
      "grad_norm": 2.6727170944213867,
      "learning_rate": 7.213131519738187e-05,
      "loss": 0.312,
      "step": 13640
    },
    {
      "epoch": 27.914110429447852,
      "grad_norm": 2.0125839710235596,
      "learning_rate": 7.211086111679281e-05,
      "loss": 0.2921,
      "step": 13650
    },
    {
      "epoch": 27.934560327198366,
      "grad_norm": 2.95418119430542,
      "learning_rate": 7.209040703620372e-05,
      "loss": 0.3473,
      "step": 13660
    },
    {
      "epoch": 27.955010224948875,
      "grad_norm": 1.8880574703216553,
      "learning_rate": 7.206995295561465e-05,
      "loss": 0.344,
      "step": 13670
    },
    {
      "epoch": 27.975460122699385,
      "grad_norm": 3.435020685195923,
      "learning_rate": 7.204949887502557e-05,
      "loss": 0.3313,
      "step": 13680
    },
    {
      "epoch": 27.995910020449898,
      "grad_norm": 1.7283285856246948,
      "learning_rate": 7.20290447944365e-05,
      "loss": 0.3177,
      "step": 13690
    },
    {
      "epoch": 28.016359918200408,
      "grad_norm": 1.6385326385498047,
      "learning_rate": 7.200859071384742e-05,
      "loss": 0.3126,
      "step": 13700
    },
    {
      "epoch": 28.016359918200408,
      "eval_loss": 3.1969921588897705,
      "eval_runtime": 27.3835,
      "eval_samples_per_second": 11.759,
      "eval_steps_per_second": 0.986,
      "step": 13700
    },
    {
      "epoch": 28.03680981595092,
      "grad_norm": 1.9979909658432007,
      "learning_rate": 7.198813663325834e-05,
      "loss": 0.3048,
      "step": 13710
    },
    {
      "epoch": 28.05725971370143,
      "grad_norm": 2.4721827507019043,
      "learning_rate": 7.196768255266926e-05,
      "loss": 0.2828,
      "step": 13720
    },
    {
      "epoch": 28.077709611451944,
      "grad_norm": 3.3587424755096436,
      "learning_rate": 7.194722847208018e-05,
      "loss": 0.3146,
      "step": 13730
    },
    {
      "epoch": 28.098159509202453,
      "grad_norm": 3.5544803142547607,
      "learning_rate": 7.19267743914911e-05,
      "loss": 0.3116,
      "step": 13740
    },
    {
      "epoch": 28.118609406952967,
      "grad_norm": 1.8671096563339233,
      "learning_rate": 7.190632031090203e-05,
      "loss": 0.3372,
      "step": 13750
    },
    {
      "epoch": 28.139059304703476,
      "grad_norm": 1.4303330183029175,
      "learning_rate": 7.188586623031295e-05,
      "loss": 0.309,
      "step": 13760
    },
    {
      "epoch": 28.15950920245399,
      "grad_norm": 1.5836317539215088,
      "learning_rate": 7.186541214972387e-05,
      "loss": 0.3178,
      "step": 13770
    },
    {
      "epoch": 28.1799591002045,
      "grad_norm": 3.2661867141723633,
      "learning_rate": 7.18449580691348e-05,
      "loss": 0.3314,
      "step": 13780
    },
    {
      "epoch": 28.20040899795501,
      "grad_norm": 2.555309534072876,
      "learning_rate": 7.182450398854572e-05,
      "loss": 0.3127,
      "step": 13790
    },
    {
      "epoch": 28.220858895705522,
      "grad_norm": 1.5149850845336914,
      "learning_rate": 7.180404990795664e-05,
      "loss": 0.337,
      "step": 13800
    },
    {
      "epoch": 28.220858895705522,
      "eval_loss": 3.2440683841705322,
      "eval_runtime": 27.2722,
      "eval_samples_per_second": 11.807,
      "eval_steps_per_second": 0.99,
      "step": 13800
    },
    {
      "epoch": 28.24130879345603,
      "grad_norm": 2.7214837074279785,
      "learning_rate": 7.178359582736756e-05,
      "loss": 0.317,
      "step": 13810
    },
    {
      "epoch": 28.261758691206545,
      "grad_norm": 3.618070125579834,
      "learning_rate": 7.176314174677848e-05,
      "loss": 0.3311,
      "step": 13820
    },
    {
      "epoch": 28.282208588957054,
      "grad_norm": 1.9879995584487915,
      "learning_rate": 7.174268766618942e-05,
      "loss": 0.3393,
      "step": 13830
    },
    {
      "epoch": 28.302658486707568,
      "grad_norm": 2.1351640224456787,
      "learning_rate": 7.172223358560033e-05,
      "loss": 0.2976,
      "step": 13840
    },
    {
      "epoch": 28.323108384458077,
      "grad_norm": 2.151258707046509,
      "learning_rate": 7.170177950501126e-05,
      "loss": 0.2838,
      "step": 13850
    },
    {
      "epoch": 28.34355828220859,
      "grad_norm": 3.4960885047912598,
      "learning_rate": 7.168132542442217e-05,
      "loss": 0.3308,
      "step": 13860
    },
    {
      "epoch": 28.3640081799591,
      "grad_norm": 2.7156283855438232,
      "learning_rate": 7.166087134383311e-05,
      "loss": 0.2858,
      "step": 13870
    },
    {
      "epoch": 28.38445807770961,
      "grad_norm": 2.687917947769165,
      "learning_rate": 7.164041726324402e-05,
      "loss": 0.3188,
      "step": 13880
    },
    {
      "epoch": 28.404907975460123,
      "grad_norm": 3.127581834793091,
      "learning_rate": 7.161996318265495e-05,
      "loss": 0.3174,
      "step": 13890
    },
    {
      "epoch": 28.425357873210633,
      "grad_norm": 2.204619884490967,
      "learning_rate": 7.159950910206586e-05,
      "loss": 0.3032,
      "step": 13900
    },
    {
      "epoch": 28.425357873210633,
      "eval_loss": 3.2749173641204834,
      "eval_runtime": 27.5143,
      "eval_samples_per_second": 11.703,
      "eval_steps_per_second": 0.981,
      "step": 13900
    },
    {
      "epoch": 28.445807770961146,
      "grad_norm": 1.74588143825531,
      "learning_rate": 7.15790550214768e-05,
      "loss": 0.3347,
      "step": 13910
    },
    {
      "epoch": 28.466257668711656,
      "grad_norm": 1.8936320543289185,
      "learning_rate": 7.15586009408877e-05,
      "loss": 0.2925,
      "step": 13920
    },
    {
      "epoch": 28.48670756646217,
      "grad_norm": 2.3888344764709473,
      "learning_rate": 7.153814686029864e-05,
      "loss": 0.31,
      "step": 13930
    },
    {
      "epoch": 28.50715746421268,
      "grad_norm": 1.7738418579101562,
      "learning_rate": 7.151769277970956e-05,
      "loss": 0.3148,
      "step": 13940
    },
    {
      "epoch": 28.52760736196319,
      "grad_norm": 2.2715492248535156,
      "learning_rate": 7.149723869912048e-05,
      "loss": 0.3329,
      "step": 13950
    },
    {
      "epoch": 28.5480572597137,
      "grad_norm": 2.407041072845459,
      "learning_rate": 7.14767846185314e-05,
      "loss": 0.3313,
      "step": 13960
    },
    {
      "epoch": 28.56850715746421,
      "grad_norm": 2.704808235168457,
      "learning_rate": 7.145633053794231e-05,
      "loss": 0.3214,
      "step": 13970
    },
    {
      "epoch": 28.588957055214724,
      "grad_norm": 3.3833563327789307,
      "learning_rate": 7.143587645735325e-05,
      "loss": 0.3127,
      "step": 13980
    },
    {
      "epoch": 28.609406952965234,
      "grad_norm": 3.0467398166656494,
      "learning_rate": 7.141542237676416e-05,
      "loss": 0.3276,
      "step": 13990
    },
    {
      "epoch": 28.629856850715747,
      "grad_norm": 3.483241081237793,
      "learning_rate": 7.13949682961751e-05,
      "loss": 0.3284,
      "step": 14000
    },
    {
      "epoch": 28.629856850715747,
      "eval_loss": 3.2216029167175293,
      "eval_runtime": 27.3234,
      "eval_samples_per_second": 11.785,
      "eval_steps_per_second": 0.988,
      "step": 14000
    },
    {
      "epoch": 28.650306748466257,
      "grad_norm": 2.6540112495422363,
      "learning_rate": 7.1374514215586e-05,
      "loss": 0.3213,
      "step": 14010
    },
    {
      "epoch": 28.67075664621677,
      "grad_norm": 2.3440394401550293,
      "learning_rate": 7.135406013499694e-05,
      "loss": 0.3365,
      "step": 14020
    },
    {
      "epoch": 28.69120654396728,
      "grad_norm": 2.8215296268463135,
      "learning_rate": 7.133360605440785e-05,
      "loss": 0.3055,
      "step": 14030
    },
    {
      "epoch": 28.711656441717793,
      "grad_norm": 2.065586566925049,
      "learning_rate": 7.131315197381878e-05,
      "loss": 0.2929,
      "step": 14040
    },
    {
      "epoch": 28.732106339468302,
      "grad_norm": 3.130856990814209,
      "learning_rate": 7.12926978932297e-05,
      "loss": 0.335,
      "step": 14050
    },
    {
      "epoch": 28.752556237218815,
      "grad_norm": 3.4935922622680664,
      "learning_rate": 7.127224381264063e-05,
      "loss": 0.3448,
      "step": 14060
    },
    {
      "epoch": 28.773006134969325,
      "grad_norm": 2.6587183475494385,
      "learning_rate": 7.125178973205155e-05,
      "loss": 0.2948,
      "step": 14070
    },
    {
      "epoch": 28.793456032719835,
      "grad_norm": 1.5330259799957275,
      "learning_rate": 7.123133565146247e-05,
      "loss": 0.3266,
      "step": 14080
    },
    {
      "epoch": 28.813905930470348,
      "grad_norm": 2.489122152328491,
      "learning_rate": 7.12108815708734e-05,
      "loss": 0.3282,
      "step": 14090
    },
    {
      "epoch": 28.834355828220858,
      "grad_norm": 2.1615631580352783,
      "learning_rate": 7.119042749028432e-05,
      "loss": 0.3356,
      "step": 14100
    },
    {
      "epoch": 28.834355828220858,
      "eval_loss": 3.251805543899536,
      "eval_runtime": 27.3295,
      "eval_samples_per_second": 11.782,
      "eval_steps_per_second": 0.988,
      "step": 14100
    },
    {
      "epoch": 28.85480572597137,
      "grad_norm": 2.1741812229156494,
      "learning_rate": 7.116997340969524e-05,
      "loss": 0.3034,
      "step": 14110
    },
    {
      "epoch": 28.87525562372188,
      "grad_norm": 3.282090187072754,
      "learning_rate": 7.114951932910616e-05,
      "loss": 0.3402,
      "step": 14120
    },
    {
      "epoch": 28.895705521472394,
      "grad_norm": 1.8213231563568115,
      "learning_rate": 7.112906524851708e-05,
      "loss": 0.3121,
      "step": 14130
    },
    {
      "epoch": 28.916155419222903,
      "grad_norm": 1.953340768814087,
      "learning_rate": 7.1108611167928e-05,
      "loss": 0.2972,
      "step": 14140
    },
    {
      "epoch": 28.936605316973417,
      "grad_norm": 2.700347423553467,
      "learning_rate": 7.108815708733893e-05,
      "loss": 0.3322,
      "step": 14150
    },
    {
      "epoch": 28.957055214723926,
      "grad_norm": 2.324061632156372,
      "learning_rate": 7.106770300674985e-05,
      "loss": 0.315,
      "step": 14160
    },
    {
      "epoch": 28.97750511247444,
      "grad_norm": 2.4071404933929443,
      "learning_rate": 7.104724892616077e-05,
      "loss": 0.3504,
      "step": 14170
    },
    {
      "epoch": 28.99795501022495,
      "grad_norm": 2.4602248668670654,
      "learning_rate": 7.102679484557169e-05,
      "loss": 0.2983,
      "step": 14180
    },
    {
      "epoch": 29.01840490797546,
      "grad_norm": 2.2942092418670654,
      "learning_rate": 7.100634076498261e-05,
      "loss": 0.3128,
      "step": 14190
    },
    {
      "epoch": 29.038854805725972,
      "grad_norm": 3.134361505508423,
      "learning_rate": 7.098588668439354e-05,
      "loss": 0.3148,
      "step": 14200
    },
    {
      "epoch": 29.038854805725972,
      "eval_loss": 3.3697774410247803,
      "eval_runtime": 27.2758,
      "eval_samples_per_second": 11.805,
      "eval_steps_per_second": 0.99,
      "step": 14200
    },
    {
      "epoch": 29.05930470347648,
      "grad_norm": 1.9428950548171997,
      "learning_rate": 7.096543260380446e-05,
      "loss": 0.2983,
      "step": 14210
    },
    {
      "epoch": 29.079754601226995,
      "grad_norm": 2.196969985961914,
      "learning_rate": 7.09449785232154e-05,
      "loss": 0.3024,
      "step": 14220
    },
    {
      "epoch": 29.100204498977504,
      "grad_norm": 1.9062528610229492,
      "learning_rate": 7.09245244426263e-05,
      "loss": 0.2931,
      "step": 14230
    },
    {
      "epoch": 29.120654396728018,
      "grad_norm": 1.8356932401657104,
      "learning_rate": 7.090407036203724e-05,
      "loss": 0.3119,
      "step": 14240
    },
    {
      "epoch": 29.141104294478527,
      "grad_norm": 3.5177180767059326,
      "learning_rate": 7.088361628144815e-05,
      "loss": 0.3107,
      "step": 14250
    },
    {
      "epoch": 29.16155419222904,
      "grad_norm": 1.783626914024353,
      "learning_rate": 7.086316220085908e-05,
      "loss": 0.3283,
      "step": 14260
    },
    {
      "epoch": 29.18200408997955,
      "grad_norm": 3.303901195526123,
      "learning_rate": 7.084270812026999e-05,
      "loss": 0.3046,
      "step": 14270
    },
    {
      "epoch": 29.20245398773006,
      "grad_norm": 2.0630855560302734,
      "learning_rate": 7.082225403968093e-05,
      "loss": 0.3164,
      "step": 14280
    },
    {
      "epoch": 29.222903885480573,
      "grad_norm": 2.997105360031128,
      "learning_rate": 7.080179995909184e-05,
      "loss": 0.2987,
      "step": 14290
    },
    {
      "epoch": 29.243353783231083,
      "grad_norm": 2.310720443725586,
      "learning_rate": 7.078134587850277e-05,
      "loss": 0.3056,
      "step": 14300
    },
    {
      "epoch": 29.243353783231083,
      "eval_loss": 3.2839486598968506,
      "eval_runtime": 27.2989,
      "eval_samples_per_second": 11.795,
      "eval_steps_per_second": 0.989,
      "step": 14300
    },
    {
      "epoch": 29.263803680981596,
      "grad_norm": 2.341341733932495,
      "learning_rate": 7.076089179791368e-05,
      "loss": 0.3178,
      "step": 14310
    },
    {
      "epoch": 29.284253578732105,
      "grad_norm": 2.2743680477142334,
      "learning_rate": 7.074043771732462e-05,
      "loss": 0.3382,
      "step": 14320
    },
    {
      "epoch": 29.30470347648262,
      "grad_norm": 1.8324172496795654,
      "learning_rate": 7.071998363673554e-05,
      "loss": 0.3334,
      "step": 14330
    },
    {
      "epoch": 29.32515337423313,
      "grad_norm": 3.4432876110076904,
      "learning_rate": 7.069952955614646e-05,
      "loss": 0.3521,
      "step": 14340
    },
    {
      "epoch": 29.34560327198364,
      "grad_norm": 2.4876887798309326,
      "learning_rate": 7.067907547555738e-05,
      "loss": 0.3033,
      "step": 14350
    },
    {
      "epoch": 29.36605316973415,
      "grad_norm": 2.787170886993408,
      "learning_rate": 7.066066680302721e-05,
      "loss": 0.3182,
      "step": 14360
    },
    {
      "epoch": 29.38650306748466,
      "grad_norm": 2.232076406478882,
      "learning_rate": 7.064021272243812e-05,
      "loss": 0.2931,
      "step": 14370
    },
    {
      "epoch": 29.406952965235174,
      "grad_norm": 2.5082709789276123,
      "learning_rate": 7.061975864184906e-05,
      "loss": 0.3032,
      "step": 14380
    },
    {
      "epoch": 29.427402862985684,
      "grad_norm": 2.1063547134399414,
      "learning_rate": 7.059930456125997e-05,
      "loss": 0.3133,
      "step": 14390
    },
    {
      "epoch": 29.447852760736197,
      "grad_norm": 2.5875446796417236,
      "learning_rate": 7.05788504806709e-05,
      "loss": 0.3505,
      "step": 14400
    },
    {
      "epoch": 29.447852760736197,
      "eval_loss": 3.3499042987823486,
      "eval_runtime": 27.3059,
      "eval_samples_per_second": 11.792,
      "eval_steps_per_second": 0.989,
      "step": 14400
    },
    {
      "epoch": 29.468302658486706,
      "grad_norm": 3.23559308052063,
      "learning_rate": 7.055839640008181e-05,
      "loss": 0.31,
      "step": 14410
    },
    {
      "epoch": 29.48875255623722,
      "grad_norm": 1.922808051109314,
      "learning_rate": 7.053794231949275e-05,
      "loss": 0.3131,
      "step": 14420
    },
    {
      "epoch": 29.50920245398773,
      "grad_norm": 1.7271784543991089,
      "learning_rate": 7.051748823890367e-05,
      "loss": 0.3118,
      "step": 14430
    },
    {
      "epoch": 29.529652351738243,
      "grad_norm": 2.9238641262054443,
      "learning_rate": 7.049703415831459e-05,
      "loss": 0.3124,
      "step": 14440
    },
    {
      "epoch": 29.550102249488752,
      "grad_norm": 3.039217472076416,
      "learning_rate": 7.047658007772551e-05,
      "loss": 0.3467,
      "step": 14450
    },
    {
      "epoch": 29.570552147239265,
      "grad_norm": 2.740865707397461,
      "learning_rate": 7.045612599713643e-05,
      "loss": 0.3367,
      "step": 14460
    },
    {
      "epoch": 29.591002044989775,
      "grad_norm": 2.465554714202881,
      "learning_rate": 7.043567191654736e-05,
      "loss": 0.3149,
      "step": 14470
    },
    {
      "epoch": 29.611451942740285,
      "grad_norm": 2.666969060897827,
      "learning_rate": 7.041521783595828e-05,
      "loss": 0.2991,
      "step": 14480
    },
    {
      "epoch": 29.631901840490798,
      "grad_norm": 3.0062968730926514,
      "learning_rate": 7.03947637553692e-05,
      "loss": 0.2831,
      "step": 14490
    },
    {
      "epoch": 29.652351738241308,
      "grad_norm": 2.217991590499878,
      "learning_rate": 7.037430967478012e-05,
      "loss": 0.3146,
      "step": 14500
    },
    {
      "epoch": 29.652351738241308,
      "eval_loss": 3.2935595512390137,
      "eval_runtime": 27.2843,
      "eval_samples_per_second": 11.802,
      "eval_steps_per_second": 0.99,
      "step": 14500
    },
    {
      "epoch": 29.67280163599182,
      "grad_norm": 3.002224922180176,
      "learning_rate": 7.035385559419105e-05,
      "loss": 0.3024,
      "step": 14510
    },
    {
      "epoch": 29.69325153374233,
      "grad_norm": 3.624965190887451,
      "learning_rate": 7.033340151360197e-05,
      "loss": 0.338,
      "step": 14520
    },
    {
      "epoch": 29.713701431492844,
      "grad_norm": 2.7593331336975098,
      "learning_rate": 7.031294743301289e-05,
      "loss": 0.3287,
      "step": 14530
    },
    {
      "epoch": 29.734151329243353,
      "grad_norm": 1.4952809810638428,
      "learning_rate": 7.029249335242381e-05,
      "loss": 0.3304,
      "step": 14540
    },
    {
      "epoch": 29.754601226993866,
      "grad_norm": 1.971596598625183,
      "learning_rate": 7.027203927183473e-05,
      "loss": 0.3316,
      "step": 14550
    },
    {
      "epoch": 29.775051124744376,
      "grad_norm": 1.9574487209320068,
      "learning_rate": 7.025158519124566e-05,
      "loss": 0.2976,
      "step": 14560
    },
    {
      "epoch": 29.79550102249489,
      "grad_norm": 2.4323418140411377,
      "learning_rate": 7.023113111065658e-05,
      "loss": 0.3195,
      "step": 14570
    },
    {
      "epoch": 29.8159509202454,
      "grad_norm": 1.9671746492385864,
      "learning_rate": 7.02106770300675e-05,
      "loss": 0.3202,
      "step": 14580
    },
    {
      "epoch": 29.83640081799591,
      "grad_norm": 3.241607189178467,
      "learning_rate": 7.019022294947842e-05,
      "loss": 0.3041,
      "step": 14590
    },
    {
      "epoch": 29.856850715746422,
      "grad_norm": 1.4623521566390991,
      "learning_rate": 7.016976886888936e-05,
      "loss": 0.3067,
      "step": 14600
    },
    {
      "epoch": 29.856850715746422,
      "eval_loss": 3.2043840885162354,
      "eval_runtime": 27.2628,
      "eval_samples_per_second": 11.811,
      "eval_steps_per_second": 0.99,
      "step": 14600
    },
    {
      "epoch": 29.87730061349693,
      "grad_norm": 1.805137038230896,
      "learning_rate": 7.014931478830027e-05,
      "loss": 0.3171,
      "step": 14610
    },
    {
      "epoch": 29.897750511247445,
      "grad_norm": 2.825538158416748,
      "learning_rate": 7.01288607077112e-05,
      "loss": 0.3475,
      "step": 14620
    },
    {
      "epoch": 29.918200408997954,
      "grad_norm": 3.3570263385772705,
      "learning_rate": 7.010840662712211e-05,
      "loss": 0.3344,
      "step": 14630
    },
    {
      "epoch": 29.938650306748468,
      "grad_norm": 1.4924834966659546,
      "learning_rate": 7.008795254653305e-05,
      "loss": 0.3087,
      "step": 14640
    },
    {
      "epoch": 29.959100204498977,
      "grad_norm": 3.45550274848938,
      "learning_rate": 7.006749846594395e-05,
      "loss": 0.3,
      "step": 14650
    },
    {
      "epoch": 29.97955010224949,
      "grad_norm": 2.3775243759155273,
      "learning_rate": 7.004704438535488e-05,
      "loss": 0.3278,
      "step": 14660
    },
    {
      "epoch": 30.0,
      "grad_norm": 4.217578887939453,
      "learning_rate": 7.00265903047658e-05,
      "loss": 0.2953,
      "step": 14670
    },
    {
      "epoch": 30.02044989775051,
      "grad_norm": 1.8788925409317017,
      "learning_rate": 7.000613622417672e-05,
      "loss": 0.2898,
      "step": 14680
    },
    {
      "epoch": 30.040899795501023,
      "grad_norm": 1.5601985454559326,
      "learning_rate": 6.998568214358764e-05,
      "loss": 0.301,
      "step": 14690
    },
    {
      "epoch": 30.061349693251532,
      "grad_norm": 2.4476475715637207,
      "learning_rate": 6.996522806299857e-05,
      "loss": 0.3148,
      "step": 14700
    },
    {
      "epoch": 30.061349693251532,
      "eval_loss": 3.3609111309051514,
      "eval_runtime": 27.3122,
      "eval_samples_per_second": 11.79,
      "eval_steps_per_second": 0.989,
      "step": 14700
    },
    {
      "epoch": 30.081799591002046,
      "grad_norm": 1.5396162271499634,
      "learning_rate": 6.99447739824095e-05,
      "loss": 0.3089,
      "step": 14710
    },
    {
      "epoch": 30.102249488752555,
      "grad_norm": 2.6228668689727783,
      "learning_rate": 6.992431990182041e-05,
      "loss": 0.2941,
      "step": 14720
    },
    {
      "epoch": 30.12269938650307,
      "grad_norm": 1.7207481861114502,
      "learning_rate": 6.990386582123135e-05,
      "loss": 0.3083,
      "step": 14730
    },
    {
      "epoch": 30.143149284253578,
      "grad_norm": 1.6525604724884033,
      "learning_rate": 6.988341174064225e-05,
      "loss": 0.3337,
      "step": 14740
    },
    {
      "epoch": 30.16359918200409,
      "grad_norm": 1.8175078630447388,
      "learning_rate": 6.986295766005319e-05,
      "loss": 0.3061,
      "step": 14750
    },
    {
      "epoch": 30.1840490797546,
      "grad_norm": 2.406247615814209,
      "learning_rate": 6.98425035794641e-05,
      "loss": 0.3287,
      "step": 14760
    },
    {
      "epoch": 30.20449897750511,
      "grad_norm": 1.6492894887924194,
      "learning_rate": 6.982204949887503e-05,
      "loss": 0.2858,
      "step": 14770
    },
    {
      "epoch": 30.224948875255624,
      "grad_norm": 1.9821312427520752,
      "learning_rate": 6.980159541828594e-05,
      "loss": 0.33,
      "step": 14780
    },
    {
      "epoch": 30.245398773006134,
      "grad_norm": 2.067875623703003,
      "learning_rate": 6.978114133769688e-05,
      "loss": 0.2851,
      "step": 14790
    },
    {
      "epoch": 30.265848670756647,
      "grad_norm": 2.4906139373779297,
      "learning_rate": 6.976068725710779e-05,
      "loss": 0.3109,
      "step": 14800
    },
    {
      "epoch": 30.265848670756647,
      "eval_loss": 3.274324417114258,
      "eval_runtime": 27.2829,
      "eval_samples_per_second": 11.802,
      "eval_steps_per_second": 0.99,
      "step": 14800
    },
    {
      "epoch": 30.286298568507156,
      "grad_norm": 1.875338077545166,
      "learning_rate": 6.974023317651872e-05,
      "loss": 0.301,
      "step": 14810
    },
    {
      "epoch": 30.30674846625767,
      "grad_norm": 2.5659780502319336,
      "learning_rate": 6.971977909592964e-05,
      "loss": 0.3305,
      "step": 14820
    },
    {
      "epoch": 30.32719836400818,
      "grad_norm": 1.882694959640503,
      "learning_rate": 6.969932501534057e-05,
      "loss": 0.2899,
      "step": 14830
    },
    {
      "epoch": 30.347648261758692,
      "grad_norm": 2.2563962936401367,
      "learning_rate": 6.967887093475149e-05,
      "loss": 0.3209,
      "step": 14840
    },
    {
      "epoch": 30.368098159509202,
      "grad_norm": 1.99636971950531,
      "learning_rate": 6.965841685416241e-05,
      "loss": 0.3049,
      "step": 14850
    },
    {
      "epoch": 30.388548057259715,
      "grad_norm": 2.878737211227417,
      "learning_rate": 6.963796277357333e-05,
      "loss": 0.3473,
      "step": 14860
    },
    {
      "epoch": 30.408997955010225,
      "grad_norm": 2.6070480346679688,
      "learning_rate": 6.961750869298426e-05,
      "loss": 0.3126,
      "step": 14870
    },
    {
      "epoch": 30.429447852760735,
      "grad_norm": 3.9456052780151367,
      "learning_rate": 6.959705461239518e-05,
      "loss": 0.3401,
      "step": 14880
    },
    {
      "epoch": 30.449897750511248,
      "grad_norm": 1.8715909719467163,
      "learning_rate": 6.95766005318061e-05,
      "loss": 0.3145,
      "step": 14890
    },
    {
      "epoch": 30.470347648261757,
      "grad_norm": 2.343290328979492,
      "learning_rate": 6.955614645121702e-05,
      "loss": 0.2858,
      "step": 14900
    },
    {
      "epoch": 30.470347648261757,
      "eval_loss": 3.273245334625244,
      "eval_runtime": 27.3179,
      "eval_samples_per_second": 11.787,
      "eval_steps_per_second": 0.988,
      "step": 14900
    },
    {
      "epoch": 30.49079754601227,
      "grad_norm": 2.0600597858428955,
      "learning_rate": 6.953569237062794e-05,
      "loss": 0.338,
      "step": 14910
    },
    {
      "epoch": 30.51124744376278,
      "grad_norm": 1.5325403213500977,
      "learning_rate": 6.951523829003887e-05,
      "loss": 0.319,
      "step": 14920
    },
    {
      "epoch": 30.531697341513294,
      "grad_norm": 2.786245584487915,
      "learning_rate": 6.949478420944979e-05,
      "loss": 0.3231,
      "step": 14930
    },
    {
      "epoch": 30.552147239263803,
      "grad_norm": 3.5859920978546143,
      "learning_rate": 6.947433012886071e-05,
      "loss": 0.3307,
      "step": 14940
    },
    {
      "epoch": 30.572597137014316,
      "grad_norm": 2.672694683074951,
      "learning_rate": 6.945387604827163e-05,
      "loss": 0.2944,
      "step": 14950
    },
    {
      "epoch": 30.593047034764826,
      "grad_norm": 1.8767622709274292,
      "learning_rate": 6.943342196768255e-05,
      "loss": 0.2899,
      "step": 14960
    },
    {
      "epoch": 30.61349693251534,
      "grad_norm": 2.9673359394073486,
      "learning_rate": 6.941296788709348e-05,
      "loss": 0.3311,
      "step": 14970
    },
    {
      "epoch": 30.63394683026585,
      "grad_norm": 2.7572200298309326,
      "learning_rate": 6.93925138065044e-05,
      "loss": 0.3337,
      "step": 14980
    },
    {
      "epoch": 30.65439672801636,
      "grad_norm": 3.0546815395355225,
      "learning_rate": 6.937205972591533e-05,
      "loss": 0.3545,
      "step": 14990
    },
    {
      "epoch": 30.67484662576687,
      "grad_norm": 2.538581609725952,
      "learning_rate": 6.935160564532624e-05,
      "loss": 0.308,
      "step": 15000
    },
    {
      "epoch": 30.67484662576687,
      "eval_loss": 3.2746407985687256,
      "eval_runtime": 27.3335,
      "eval_samples_per_second": 11.78,
      "eval_steps_per_second": 0.988,
      "step": 15000
    },
    {
      "epoch": 30.69529652351738,
      "grad_norm": 1.8510897159576416,
      "learning_rate": 6.933115156473718e-05,
      "loss": 0.3229,
      "step": 15010
    },
    {
      "epoch": 30.715746421267895,
      "grad_norm": 3.276650905609131,
      "learning_rate": 6.931069748414809e-05,
      "loss": 0.3385,
      "step": 15020
    },
    {
      "epoch": 30.736196319018404,
      "grad_norm": 2.119588613510132,
      "learning_rate": 6.929024340355902e-05,
      "loss": 0.2966,
      "step": 15030
    },
    {
      "epoch": 30.756646216768917,
      "grad_norm": 2.131845712661743,
      "learning_rate": 6.926978932296993e-05,
      "loss": 0.3074,
      "step": 15040
    },
    {
      "epoch": 30.777096114519427,
      "grad_norm": 2.2560267448425293,
      "learning_rate": 6.924933524238085e-05,
      "loss": 0.3303,
      "step": 15050
    },
    {
      "epoch": 30.79754601226994,
      "grad_norm": 2.9902217388153076,
      "learning_rate": 6.922888116179178e-05,
      "loss": 0.3264,
      "step": 15060
    },
    {
      "epoch": 30.81799591002045,
      "grad_norm": 1.8068859577178955,
      "learning_rate": 6.92084270812027e-05,
      "loss": 0.3056,
      "step": 15070
    },
    {
      "epoch": 30.83844580777096,
      "grad_norm": 2.4833903312683105,
      "learning_rate": 6.918797300061362e-05,
      "loss": 0.3262,
      "step": 15080
    },
    {
      "epoch": 30.858895705521473,
      "grad_norm": 1.802615761756897,
      "learning_rate": 6.916751892002454e-05,
      "loss": 0.337,
      "step": 15090
    },
    {
      "epoch": 30.879345603271982,
      "grad_norm": 2.0525360107421875,
      "learning_rate": 6.914706483943548e-05,
      "loss": 0.3008,
      "step": 15100
    },
    {
      "epoch": 30.879345603271982,
      "eval_loss": 3.296037197113037,
      "eval_runtime": 27.3248,
      "eval_samples_per_second": 11.784,
      "eval_steps_per_second": 0.988,
      "step": 15100
    },
    {
      "epoch": 30.899795501022496,
      "grad_norm": 1.5422052145004272,
      "learning_rate": 6.912661075884639e-05,
      "loss": 0.3215,
      "step": 15110
    },
    {
      "epoch": 30.920245398773005,
      "grad_norm": 2.599287748336792,
      "learning_rate": 6.910615667825732e-05,
      "loss": 0.3304,
      "step": 15120
    },
    {
      "epoch": 30.94069529652352,
      "grad_norm": 2.359346389770508,
      "learning_rate": 6.908570259766823e-05,
      "loss": 0.3148,
      "step": 15130
    },
    {
      "epoch": 30.961145194274028,
      "grad_norm": 2.138897180557251,
      "learning_rate": 6.906524851707917e-05,
      "loss": 0.3364,
      "step": 15140
    },
    {
      "epoch": 30.98159509202454,
      "grad_norm": 2.250875949859619,
      "learning_rate": 6.904479443649007e-05,
      "loss": 0.327,
      "step": 15150
    },
    {
      "epoch": 31.00204498977505,
      "grad_norm": 2.042013168334961,
      "learning_rate": 6.902434035590101e-05,
      "loss": 0.2828,
      "step": 15160
    },
    {
      "epoch": 31.02249488752556,
      "grad_norm": 2.4996719360351562,
      "learning_rate": 6.900388627531192e-05,
      "loss": 0.3101,
      "step": 15170
    },
    {
      "epoch": 31.042944785276074,
      "grad_norm": 2.16802978515625,
      "learning_rate": 6.898343219472285e-05,
      "loss": 0.2981,
      "step": 15180
    },
    {
      "epoch": 31.063394683026583,
      "grad_norm": 2.1051604747772217,
      "learning_rate": 6.896297811413376e-05,
      "loss": 0.3054,
      "step": 15190
    },
    {
      "epoch": 31.083844580777097,
      "grad_norm": 1.6511573791503906,
      "learning_rate": 6.89425240335447e-05,
      "loss": 0.3146,
      "step": 15200
    },
    {
      "epoch": 31.083844580777097,
      "eval_loss": 3.341449022293091,
      "eval_runtime": 27.304,
      "eval_samples_per_second": 11.793,
      "eval_steps_per_second": 0.989,
      "step": 15200
    },
    {
      "epoch": 31.104294478527606,
      "grad_norm": 1.69313383102417,
      "learning_rate": 6.892206995295562e-05,
      "loss": 0.3197,
      "step": 15210
    },
    {
      "epoch": 31.12474437627812,
      "grad_norm": 1.558118224143982,
      "learning_rate": 6.890161587236654e-05,
      "loss": 0.2797,
      "step": 15220
    },
    {
      "epoch": 31.14519427402863,
      "grad_norm": 3.667715072631836,
      "learning_rate": 6.888116179177746e-05,
      "loss": 0.2971,
      "step": 15230
    },
    {
      "epoch": 31.165644171779142,
      "grad_norm": 2.1720457077026367,
      "learning_rate": 6.886070771118839e-05,
      "loss": 0.298,
      "step": 15240
    },
    {
      "epoch": 31.186094069529652,
      "grad_norm": 2.252763032913208,
      "learning_rate": 6.884025363059931e-05,
      "loss": 0.2938,
      "step": 15250
    },
    {
      "epoch": 31.206543967280165,
      "grad_norm": 3.2896177768707275,
      "learning_rate": 6.881979955001023e-05,
      "loss": 0.331,
      "step": 15260
    },
    {
      "epoch": 31.226993865030675,
      "grad_norm": 1.890499234199524,
      "learning_rate": 6.879934546942115e-05,
      "loss": 0.3219,
      "step": 15270
    },
    {
      "epoch": 31.247443762781185,
      "grad_norm": 1.8016259670257568,
      "learning_rate": 6.877889138883208e-05,
      "loss": 0.3008,
      "step": 15280
    },
    {
      "epoch": 31.267893660531698,
      "grad_norm": 2.2394661903381348,
      "learning_rate": 6.8758437308243e-05,
      "loss": 0.3092,
      "step": 15290
    },
    {
      "epoch": 31.288343558282207,
      "grad_norm": 2.565465211868286,
      "learning_rate": 6.873798322765392e-05,
      "loss": 0.3361,
      "step": 15300
    },
    {
      "epoch": 31.288343558282207,
      "eval_loss": 3.3344688415527344,
      "eval_runtime": 27.2206,
      "eval_samples_per_second": 11.829,
      "eval_steps_per_second": 0.992,
      "step": 15300
    },
    {
      "epoch": 31.30879345603272,
      "grad_norm": 2.990311861038208,
      "learning_rate": 6.871752914706484e-05,
      "loss": 0.3178,
      "step": 15310
    },
    {
      "epoch": 31.32924335378323,
      "grad_norm": 1.9985038042068481,
      "learning_rate": 6.869707506647576e-05,
      "loss": 0.3031,
      "step": 15320
    },
    {
      "epoch": 31.349693251533743,
      "grad_norm": 1.7247254848480225,
      "learning_rate": 6.867662098588669e-05,
      "loss": 0.2911,
      "step": 15330
    },
    {
      "epoch": 31.370143149284253,
      "grad_norm": 3.687455415725708,
      "learning_rate": 6.865616690529761e-05,
      "loss": 0.3224,
      "step": 15340
    },
    {
      "epoch": 31.390593047034766,
      "grad_norm": 2.8227739334106445,
      "learning_rate": 6.863571282470853e-05,
      "loss": 0.3302,
      "step": 15350
    },
    {
      "epoch": 31.411042944785276,
      "grad_norm": 2.618565559387207,
      "learning_rate": 6.861525874411947e-05,
      "loss": 0.3162,
      "step": 15360
    },
    {
      "epoch": 31.43149284253579,
      "grad_norm": 1.8015398979187012,
      "learning_rate": 6.859480466353037e-05,
      "loss": 0.2953,
      "step": 15370
    },
    {
      "epoch": 31.4519427402863,
      "grad_norm": 1.775985836982727,
      "learning_rate": 6.857435058294131e-05,
      "loss": 0.3078,
      "step": 15380
    },
    {
      "epoch": 31.47239263803681,
      "grad_norm": 2.3949460983276367,
      "learning_rate": 6.855389650235222e-05,
      "loss": 0.3102,
      "step": 15390
    },
    {
      "epoch": 31.49284253578732,
      "grad_norm": 3.2688348293304443,
      "learning_rate": 6.853344242176315e-05,
      "loss": 0.3118,
      "step": 15400
    },
    {
      "epoch": 31.49284253578732,
      "eval_loss": 3.3055639266967773,
      "eval_runtime": 27.5662,
      "eval_samples_per_second": 11.681,
      "eval_steps_per_second": 0.979,
      "step": 15400
    },
    {
      "epoch": 31.51329243353783,
      "grad_norm": 2.3993000984191895,
      "learning_rate": 6.851298834117406e-05,
      "loss": 0.3063,
      "step": 15410
    },
    {
      "epoch": 31.533742331288344,
      "grad_norm": 3.4498484134674072,
      "learning_rate": 6.8492534260585e-05,
      "loss": 0.3133,
      "step": 15420
    },
    {
      "epoch": 31.554192229038854,
      "grad_norm": 2.3597817420959473,
      "learning_rate": 6.847208017999591e-05,
      "loss": 0.3029,
      "step": 15430
    },
    {
      "epoch": 31.574642126789367,
      "grad_norm": 2.5222458839416504,
      "learning_rate": 6.845162609940684e-05,
      "loss": 0.3347,
      "step": 15440
    },
    {
      "epoch": 31.595092024539877,
      "grad_norm": 1.8741072416305542,
      "learning_rate": 6.843117201881775e-05,
      "loss": 0.3064,
      "step": 15450
    },
    {
      "epoch": 31.61554192229039,
      "grad_norm": 2.526005983352661,
      "learning_rate": 6.841071793822867e-05,
      "loss": 0.31,
      "step": 15460
    },
    {
      "epoch": 31.6359918200409,
      "grad_norm": 2.283266305923462,
      "learning_rate": 6.839026385763961e-05,
      "loss": 0.3376,
      "step": 15470
    },
    {
      "epoch": 31.65644171779141,
      "grad_norm": 2.526967763900757,
      "learning_rate": 6.836980977705052e-05,
      "loss": 0.3346,
      "step": 15480
    },
    {
      "epoch": 31.676891615541923,
      "grad_norm": 2.7820889949798584,
      "learning_rate": 6.834935569646145e-05,
      "loss": 0.3025,
      "step": 15490
    },
    {
      "epoch": 31.697341513292432,
      "grad_norm": 1.6835033893585205,
      "learning_rate": 6.832890161587236e-05,
      "loss": 0.2943,
      "step": 15500
    },
    {
      "epoch": 31.697341513292432,
      "eval_loss": 3.2965047359466553,
      "eval_runtime": 27.4138,
      "eval_samples_per_second": 11.746,
      "eval_steps_per_second": 0.985,
      "step": 15500
    },
    {
      "epoch": 31.717791411042946,
      "grad_norm": 2.1245644092559814,
      "learning_rate": 6.83084475352833e-05,
      "loss": 0.3204,
      "step": 15510
    },
    {
      "epoch": 31.738241308793455,
      "grad_norm": 2.015333890914917,
      "learning_rate": 6.82879934546942e-05,
      "loss": 0.3334,
      "step": 15520
    },
    {
      "epoch": 31.75869120654397,
      "grad_norm": 1.7873265743255615,
      "learning_rate": 6.826753937410514e-05,
      "loss": 0.2859,
      "step": 15530
    },
    {
      "epoch": 31.779141104294478,
      "grad_norm": 1.4089175462722778,
      "learning_rate": 6.824708529351605e-05,
      "loss": 0.3146,
      "step": 15540
    },
    {
      "epoch": 31.79959100204499,
      "grad_norm": 2.649918794631958,
      "learning_rate": 6.822663121292699e-05,
      "loss": 0.32,
      "step": 15550
    },
    {
      "epoch": 31.8200408997955,
      "grad_norm": 2.6084508895874023,
      "learning_rate": 6.82061771323379e-05,
      "loss": 0.312,
      "step": 15560
    },
    {
      "epoch": 31.84049079754601,
      "grad_norm": 1.6347718238830566,
      "learning_rate": 6.818572305174883e-05,
      "loss": 0.3021,
      "step": 15570
    },
    {
      "epoch": 31.860940695296524,
      "grad_norm": 2.016008138656616,
      "learning_rate": 6.816526897115975e-05,
      "loss": 0.2952,
      "step": 15580
    },
    {
      "epoch": 31.881390593047033,
      "grad_norm": 1.9234610795974731,
      "learning_rate": 6.814481489057067e-05,
      "loss": 0.2969,
      "step": 15590
    },
    {
      "epoch": 31.901840490797547,
      "grad_norm": 2.0570809841156006,
      "learning_rate": 6.81243608099816e-05,
      "loss": 0.2989,
      "step": 15600
    },
    {
      "epoch": 31.901840490797547,
      "eval_loss": 3.3182880878448486,
      "eval_runtime": 27.4075,
      "eval_samples_per_second": 11.749,
      "eval_steps_per_second": 0.985,
      "step": 15600
    },
    {
      "epoch": 31.922290388548056,
      "grad_norm": 1.8562161922454834,
      "learning_rate": 6.810390672939252e-05,
      "loss": 0.323,
      "step": 15610
    },
    {
      "epoch": 31.94274028629857,
      "grad_norm": 2.8777947425842285,
      "learning_rate": 6.808345264880344e-05,
      "loss": 0.3275,
      "step": 15620
    },
    {
      "epoch": 31.96319018404908,
      "grad_norm": 3.776677370071411,
      "learning_rate": 6.806299856821436e-05,
      "loss": 0.3341,
      "step": 15630
    },
    {
      "epoch": 31.983640081799592,
      "grad_norm": 2.472134590148926,
      "learning_rate": 6.804254448762529e-05,
      "loss": 0.3133,
      "step": 15640
    },
    {
      "epoch": 32.0040899795501,
      "grad_norm": 1.480150580406189,
      "learning_rate": 6.802209040703621e-05,
      "loss": 0.3238,
      "step": 15650
    },
    {
      "epoch": 32.02453987730061,
      "grad_norm": 1.3901690244674683,
      "learning_rate": 6.800163632644713e-05,
      "loss": 0.2857,
      "step": 15660
    },
    {
      "epoch": 32.04498977505112,
      "grad_norm": 1.811247706413269,
      "learning_rate": 6.798118224585805e-05,
      "loss": 0.296,
      "step": 15670
    },
    {
      "epoch": 32.06543967280164,
      "grad_norm": 1.695563554763794,
      "learning_rate": 6.796072816526897e-05,
      "loss": 0.2919,
      "step": 15680
    },
    {
      "epoch": 32.08588957055215,
      "grad_norm": 1.2950881719589233,
      "learning_rate": 6.79402740846799e-05,
      "loss": 0.296,
      "step": 15690
    },
    {
      "epoch": 32.10633946830266,
      "grad_norm": 1.8198484182357788,
      "learning_rate": 6.791982000409082e-05,
      "loss": 0.308,
      "step": 15700
    },
    {
      "epoch": 32.10633946830266,
      "eval_loss": 3.4241344928741455,
      "eval_runtime": 27.2855,
      "eval_samples_per_second": 11.801,
      "eval_steps_per_second": 0.99,
      "step": 15700
    },
    {
      "epoch": 32.12678936605317,
      "grad_norm": 3.1508359909057617,
      "learning_rate": 6.789936592350174e-05,
      "loss": 0.3016,
      "step": 15710
    },
    {
      "epoch": 32.147239263803684,
      "grad_norm": 3.0071122646331787,
      "learning_rate": 6.787891184291266e-05,
      "loss": 0.2842,
      "step": 15720
    },
    {
      "epoch": 32.16768916155419,
      "grad_norm": 2.1584208011627197,
      "learning_rate": 6.785845776232358e-05,
      "loss": 0.2937,
      "step": 15730
    },
    {
      "epoch": 32.1881390593047,
      "grad_norm": 2.000274658203125,
      "learning_rate": 6.78380036817345e-05,
      "loss": 0.2984,
      "step": 15740
    },
    {
      "epoch": 32.20858895705521,
      "grad_norm": 1.1766083240509033,
      "learning_rate": 6.781754960114544e-05,
      "loss": 0.31,
      "step": 15750
    },
    {
      "epoch": 32.22903885480573,
      "grad_norm": 1.6834439039230347,
      "learning_rate": 6.779709552055635e-05,
      "loss": 0.3141,
      "step": 15760
    },
    {
      "epoch": 32.24948875255624,
      "grad_norm": 2.36953067779541,
      "learning_rate": 6.777664143996729e-05,
      "loss": 0.3104,
      "step": 15770
    },
    {
      "epoch": 32.26993865030675,
      "grad_norm": 3.1097404956817627,
      "learning_rate": 6.77561873593782e-05,
      "loss": 0.3333,
      "step": 15780
    },
    {
      "epoch": 32.29038854805726,
      "grad_norm": 2.63909649848938,
      "learning_rate": 6.773573327878913e-05,
      "loss": 0.2952,
      "step": 15790
    },
    {
      "epoch": 32.31083844580777,
      "grad_norm": 2.1248369216918945,
      "learning_rate": 6.771527919820004e-05,
      "loss": 0.3016,
      "step": 15800
    },
    {
      "epoch": 32.31083844580777,
      "eval_loss": 3.3977506160736084,
      "eval_runtime": 27.259,
      "eval_samples_per_second": 11.813,
      "eval_steps_per_second": 0.99,
      "step": 15800
    },
    {
      "epoch": 32.331288343558285,
      "grad_norm": 2.637666702270508,
      "learning_rate": 6.769482511761097e-05,
      "loss": 0.315,
      "step": 15810
    },
    {
      "epoch": 32.351738241308794,
      "grad_norm": 1.6759735345840454,
      "learning_rate": 6.767437103702188e-05,
      "loss": 0.3064,
      "step": 15820
    },
    {
      "epoch": 32.372188139059304,
      "grad_norm": 1.9995172023773193,
      "learning_rate": 6.765391695643282e-05,
      "loss": 0.2808,
      "step": 15830
    },
    {
      "epoch": 32.392638036809814,
      "grad_norm": 1.8091785907745361,
      "learning_rate": 6.763346287584373e-05,
      "loss": 0.2913,
      "step": 15840
    },
    {
      "epoch": 32.41308793456033,
      "grad_norm": 1.7411752939224243,
      "learning_rate": 6.761300879525466e-05,
      "loss": 0.3048,
      "step": 15850
    },
    {
      "epoch": 32.43353783231084,
      "grad_norm": 1.4091087579727173,
      "learning_rate": 6.759255471466559e-05,
      "loss": 0.3154,
      "step": 15860
    },
    {
      "epoch": 32.45398773006135,
      "grad_norm": 2.12398362159729,
      "learning_rate": 6.75721006340765e-05,
      "loss": 0.3254,
      "step": 15870
    },
    {
      "epoch": 32.47443762781186,
      "grad_norm": 4.194114685058594,
      "learning_rate": 6.755164655348743e-05,
      "loss": 0.3182,
      "step": 15880
    },
    {
      "epoch": 32.49488752556237,
      "grad_norm": 2.1167798042297363,
      "learning_rate": 6.753119247289834e-05,
      "loss": 0.2856,
      "step": 15890
    },
    {
      "epoch": 32.515337423312886,
      "grad_norm": 2.112247943878174,
      "learning_rate": 6.751073839230927e-05,
      "loss": 0.3188,
      "step": 15900
    },
    {
      "epoch": 32.515337423312886,
      "eval_loss": 3.325862169265747,
      "eval_runtime": 27.3005,
      "eval_samples_per_second": 11.795,
      "eval_steps_per_second": 0.989,
      "step": 15900
    },
    {
      "epoch": 32.535787321063395,
      "grad_norm": 2.401386260986328,
      "learning_rate": 6.749028431172018e-05,
      "loss": 0.303,
      "step": 15910
    },
    {
      "epoch": 32.556237218813905,
      "grad_norm": 1.390943169593811,
      "learning_rate": 6.746983023113112e-05,
      "loss": 0.2961,
      "step": 15920
    },
    {
      "epoch": 32.576687116564415,
      "grad_norm": 1.4952723979949951,
      "learning_rate": 6.744937615054203e-05,
      "loss": 0.3014,
      "step": 15930
    },
    {
      "epoch": 32.59713701431493,
      "grad_norm": 3.152683734893799,
      "learning_rate": 6.742892206995296e-05,
      "loss": 0.35,
      "step": 15940
    },
    {
      "epoch": 32.61758691206544,
      "grad_norm": 3.6355926990509033,
      "learning_rate": 6.740846798936387e-05,
      "loss": 0.3233,
      "step": 15950
    },
    {
      "epoch": 32.63803680981595,
      "grad_norm": 2.482576608657837,
      "learning_rate": 6.73880139087748e-05,
      "loss": 0.2934,
      "step": 15960
    },
    {
      "epoch": 32.65848670756646,
      "grad_norm": 3.5347509384155273,
      "learning_rate": 6.736755982818573e-05,
      "loss": 0.3299,
      "step": 15970
    },
    {
      "epoch": 32.67893660531697,
      "grad_norm": 2.613068103790283,
      "learning_rate": 6.734710574759665e-05,
      "loss": 0.3454,
      "step": 15980
    },
    {
      "epoch": 32.69938650306749,
      "grad_norm": 3.7495288848876953,
      "learning_rate": 6.732665166700757e-05,
      "loss": 0.3202,
      "step": 15990
    },
    {
      "epoch": 32.719836400818,
      "grad_norm": 2.2791929244995117,
      "learning_rate": 6.73061975864185e-05,
      "loss": 0.316,
      "step": 16000
    },
    {
      "epoch": 32.719836400818,
      "eval_loss": 3.311662197113037,
      "eval_runtime": 27.3488,
      "eval_samples_per_second": 11.774,
      "eval_steps_per_second": 0.987,
      "step": 16000
    },
    {
      "epoch": 32.740286298568506,
      "grad_norm": 2.0471179485321045,
      "learning_rate": 6.728574350582942e-05,
      "loss": 0.3232,
      "step": 16010
    },
    {
      "epoch": 32.760736196319016,
      "grad_norm": 2.5374178886413574,
      "learning_rate": 6.726528942524034e-05,
      "loss": 0.321,
      "step": 16020
    },
    {
      "epoch": 32.78118609406953,
      "grad_norm": 1.8571690320968628,
      "learning_rate": 6.724483534465126e-05,
      "loss": 0.3094,
      "step": 16030
    },
    {
      "epoch": 32.80163599182004,
      "grad_norm": 2.380387783050537,
      "learning_rate": 6.722438126406218e-05,
      "loss": 0.2984,
      "step": 16040
    },
    {
      "epoch": 32.82208588957055,
      "grad_norm": 2.812241315841675,
      "learning_rate": 6.72039271834731e-05,
      "loss": 0.3191,
      "step": 16050
    },
    {
      "epoch": 32.84253578732106,
      "grad_norm": 2.5595874786376953,
      "learning_rate": 6.718347310288403e-05,
      "loss": 0.3144,
      "step": 16060
    },
    {
      "epoch": 32.86298568507158,
      "grad_norm": 1.5196869373321533,
      "learning_rate": 6.716301902229495e-05,
      "loss": 0.3196,
      "step": 16070
    },
    {
      "epoch": 32.88343558282209,
      "grad_norm": 2.8758888244628906,
      "learning_rate": 6.714256494170587e-05,
      "loss": 0.36,
      "step": 16080
    },
    {
      "epoch": 32.9038854805726,
      "grad_norm": 2.01993989944458,
      "learning_rate": 6.71221108611168e-05,
      "loss": 0.3072,
      "step": 16090
    },
    {
      "epoch": 32.92433537832311,
      "grad_norm": 2.7604939937591553,
      "learning_rate": 6.710165678052772e-05,
      "loss": 0.3166,
      "step": 16100
    },
    {
      "epoch": 32.92433537832311,
      "eval_loss": 3.274138927459717,
      "eval_runtime": 27.3605,
      "eval_samples_per_second": 11.769,
      "eval_steps_per_second": 0.987,
      "step": 16100
    },
    {
      "epoch": 32.94478527607362,
      "grad_norm": 2.6935720443725586,
      "learning_rate": 6.708120269993864e-05,
      "loss": 0.2953,
      "step": 16110
    },
    {
      "epoch": 32.965235173824134,
      "grad_norm": 1.9886530637741089,
      "learning_rate": 6.706074861934956e-05,
      "loss": 0.3127,
      "step": 16120
    },
    {
      "epoch": 32.98568507157464,
      "grad_norm": 2.5146100521087646,
      "learning_rate": 6.704029453876048e-05,
      "loss": 0.2998,
      "step": 16130
    },
    {
      "epoch": 33.00613496932515,
      "grad_norm": 1.5712816715240479,
      "learning_rate": 6.701984045817142e-05,
      "loss": 0.309,
      "step": 16140
    },
    {
      "epoch": 33.02658486707566,
      "grad_norm": 1.6837540864944458,
      "learning_rate": 6.699938637758233e-05,
      "loss": 0.3106,
      "step": 16150
    },
    {
      "epoch": 33.04703476482618,
      "grad_norm": 2.775002956390381,
      "learning_rate": 6.697893229699326e-05,
      "loss": 0.3092,
      "step": 16160
    },
    {
      "epoch": 33.06748466257669,
      "grad_norm": 2.350473165512085,
      "learning_rate": 6.695847821640417e-05,
      "loss": 0.3033,
      "step": 16170
    },
    {
      "epoch": 33.0879345603272,
      "grad_norm": 2.344730854034424,
      "learning_rate": 6.69380241358151e-05,
      "loss": 0.282,
      "step": 16180
    },
    {
      "epoch": 33.10838445807771,
      "grad_norm": 1.7273389101028442,
      "learning_rate": 6.691757005522602e-05,
      "loss": 0.2939,
      "step": 16190
    },
    {
      "epoch": 33.12883435582822,
      "grad_norm": 3.0189285278320312,
      "learning_rate": 6.689711597463695e-05,
      "loss": 0.2998,
      "step": 16200
    },
    {
      "epoch": 33.12883435582822,
      "eval_loss": 3.3760933876037598,
      "eval_runtime": 27.3224,
      "eval_samples_per_second": 11.785,
      "eval_steps_per_second": 0.988,
      "step": 16200
    },
    {
      "epoch": 33.149284253578735,
      "grad_norm": 1.6173089742660522,
      "learning_rate": 6.687666189404786e-05,
      "loss": 0.2861,
      "step": 16210
    },
    {
      "epoch": 33.169734151329244,
      "grad_norm": 2.405107021331787,
      "learning_rate": 6.68562078134588e-05,
      "loss": 0.3095,
      "step": 16220
    },
    {
      "epoch": 33.190184049079754,
      "grad_norm": 1.9259780645370483,
      "learning_rate": 6.68357537328697e-05,
      "loss": 0.2949,
      "step": 16230
    },
    {
      "epoch": 33.210633946830264,
      "grad_norm": 2.4465630054473877,
      "learning_rate": 6.681529965228064e-05,
      "loss": 0.3078,
      "step": 16240
    },
    {
      "epoch": 33.23108384458078,
      "grad_norm": 1.5141509771347046,
      "learning_rate": 6.679484557169156e-05,
      "loss": 0.3094,
      "step": 16250
    },
    {
      "epoch": 33.25153374233129,
      "grad_norm": 2.258706569671631,
      "learning_rate": 6.677439149110247e-05,
      "loss": 0.31,
      "step": 16260
    },
    {
      "epoch": 33.2719836400818,
      "grad_norm": 4.0637617111206055,
      "learning_rate": 6.67539374105134e-05,
      "loss": 0.2968,
      "step": 16270
    },
    {
      "epoch": 33.29243353783231,
      "grad_norm": 2.0691440105438232,
      "learning_rate": 6.673348332992431e-05,
      "loss": 0.2862,
      "step": 16280
    },
    {
      "epoch": 33.31288343558282,
      "grad_norm": 2.3550407886505127,
      "learning_rate": 6.671302924933525e-05,
      "loss": 0.338,
      "step": 16290
    },
    {
      "epoch": 33.333333333333336,
      "grad_norm": 1.860762357711792,
      "learning_rate": 6.669257516874616e-05,
      "loss": 0.2883,
      "step": 16300
    },
    {
      "epoch": 33.333333333333336,
      "eval_loss": 3.3641557693481445,
      "eval_runtime": 27.2678,
      "eval_samples_per_second": 11.809,
      "eval_steps_per_second": 0.99,
      "step": 16300
    },
    {
      "epoch": 33.353783231083845,
      "grad_norm": 1.75689697265625,
      "learning_rate": 6.66721210881571e-05,
      "loss": 0.3267,
      "step": 16310
    },
    {
      "epoch": 33.374233128834355,
      "grad_norm": 1.7058366537094116,
      "learning_rate": 6.6651667007568e-05,
      "loss": 0.2906,
      "step": 16320
    },
    {
      "epoch": 33.394683026584865,
      "grad_norm": 2.260981798171997,
      "learning_rate": 6.663121292697894e-05,
      "loss": 0.28,
      "step": 16330
    },
    {
      "epoch": 33.41513292433538,
      "grad_norm": 2.5317492485046387,
      "learning_rate": 6.661075884638985e-05,
      "loss": 0.3177,
      "step": 16340
    },
    {
      "epoch": 33.43558282208589,
      "grad_norm": 2.2482802867889404,
      "learning_rate": 6.659030476580078e-05,
      "loss": 0.3081,
      "step": 16350
    },
    {
      "epoch": 33.4560327198364,
      "grad_norm": 2.213287115097046,
      "learning_rate": 6.65698506852117e-05,
      "loss": 0.3049,
      "step": 16360
    },
    {
      "epoch": 33.47648261758691,
      "grad_norm": 1.7601383924484253,
      "learning_rate": 6.654939660462263e-05,
      "loss": 0.3135,
      "step": 16370
    },
    {
      "epoch": 33.49693251533742,
      "grad_norm": 1.846533179283142,
      "learning_rate": 6.652894252403355e-05,
      "loss": 0.2984,
      "step": 16380
    },
    {
      "epoch": 33.51738241308794,
      "grad_norm": 1.2434803247451782,
      "learning_rate": 6.650848844344447e-05,
      "loss": 0.3073,
      "step": 16390
    },
    {
      "epoch": 33.537832310838446,
      "grad_norm": 2.44242000579834,
      "learning_rate": 6.64880343628554e-05,
      "loss": 0.3066,
      "step": 16400
    },
    {
      "epoch": 33.537832310838446,
      "eval_loss": 3.3777413368225098,
      "eval_runtime": 27.3237,
      "eval_samples_per_second": 11.785,
      "eval_steps_per_second": 0.988,
      "step": 16400
    },
    {
      "epoch": 33.558282208588956,
      "grad_norm": 1.2605247497558594,
      "learning_rate": 6.646758028226632e-05,
      "loss": 0.3077,
      "step": 16410
    },
    {
      "epoch": 33.578732106339466,
      "grad_norm": 2.322145462036133,
      "learning_rate": 6.644712620167724e-05,
      "loss": 0.3149,
      "step": 16420
    },
    {
      "epoch": 33.59918200408998,
      "grad_norm": 2.3751094341278076,
      "learning_rate": 6.642667212108816e-05,
      "loss": 0.3152,
      "step": 16430
    },
    {
      "epoch": 33.61963190184049,
      "grad_norm": 2.977325677871704,
      "learning_rate": 6.640621804049908e-05,
      "loss": 0.3002,
      "step": 16440
    },
    {
      "epoch": 33.640081799591,
      "grad_norm": 2.287759304046631,
      "learning_rate": 6.638576395991e-05,
      "loss": 0.3239,
      "step": 16450
    },
    {
      "epoch": 33.66053169734151,
      "grad_norm": 2.0419270992279053,
      "learning_rate": 6.636530987932093e-05,
      "loss": 0.2987,
      "step": 16460
    },
    {
      "epoch": 33.68098159509202,
      "grad_norm": 1.5310205221176147,
      "learning_rate": 6.634485579873185e-05,
      "loss": 0.2732,
      "step": 16470
    },
    {
      "epoch": 33.70143149284254,
      "grad_norm": 2.2437961101531982,
      "learning_rate": 6.632440171814277e-05,
      "loss": 0.3085,
      "step": 16480
    },
    {
      "epoch": 33.72188139059305,
      "grad_norm": 2.5096945762634277,
      "learning_rate": 6.630394763755369e-05,
      "loss": 0.3238,
      "step": 16490
    },
    {
      "epoch": 33.74233128834356,
      "grad_norm": 1.6869466304779053,
      "learning_rate": 6.628349355696461e-05,
      "loss": 0.3222,
      "step": 16500
    },
    {
      "epoch": 33.74233128834356,
      "eval_loss": 3.326322555541992,
      "eval_runtime": 27.2791,
      "eval_samples_per_second": 11.804,
      "eval_steps_per_second": 0.99,
      "step": 16500
    }
  ],
  "logging_steps": 10,
  "max_steps": 48900,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 100,
  "save_steps": 100,
  "total_flos": 1.5056052643316367e+19,
  "train_batch_size": 12,
  "trial_name": null,
  "trial_params": null
}
